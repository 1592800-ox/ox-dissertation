{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting PRIDICT model...\n",
      "Using device: cuda\n",
      "Predicting fold 1...\n",
      "Fold 1 RMSE: 2.693588939344827\n",
      "Fold 1 Pearson: 0.747362196085111, Spearman: 0.7490703853739952\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Predicting fold 2...\n",
      "Fold 2 RMSE: 2.736295388107088\n",
      "Fold 2 Pearson: 0.7498616372258863, Spearman: 0.7480239296296531\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Predicting fold 3...\n",
      "Fold 3 RMSE: 2.697875033793436\n",
      "Fold 3 Pearson: 0.741404630047823, Spearman: 0.7397628911818587\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Predicting fold 4...\n",
      "Fold 4 RMSE: 2.814560904067043\n",
      "Fold 4 Pearson: 0.7274250700126887, Spearman: 0.737252963173282\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Predicting fold 5...\n",
      "Fold 5 RMSE: 2.780026540973377\n",
      "Fold 5 Pearson: 0.7300936395216261, Spearman: 0.7393439812967181\n",
      "74\n",
      "Fold 1 Pearson: 0.7315584671638726, Spearman: 0.7321458624361683\n",
      "74\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Fold 2 Pearson: 0.7281871108135605, Spearman: 0.7283528144830904\n",
      "74\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Fold 3 Pearson: 0.7154100086993811, Spearman: 0.7228440973867954\n",
      "74\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Fold 4 Pearson: 0.7334742626576388, Spearman: 0.7330035402205085\n",
      "74\n",
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "Fold 5 Pearson: 0.7266761861574775, Spearman: 0.7252544363184362\n"
     ]
    }
   ],
   "source": [
    "# load the pridict, deepprime and conventional ML models\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import skorch\n",
    "\n",
    "from models.deepprime import predict_deep_prime\n",
    "from models.pridict import predict_pridict\n",
    "from models.conventional_ml_models import MLP\n",
    "from collections import defaultdict\n",
    "\n",
    "# suppress warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "\n",
    "dataf = 'dp-hek293t-pe2'\n",
    "\n",
    "data_dp = f'dp-{dataf}.csv'\n",
    "data_pd = f'pd-{dataf}.csv'\n",
    "\n",
    "prediction_pd, _ = predict_pridict(data_pd, num_features=24, device='cuda' if torch.cuda.is_available() else 'cpu', dropout=0)\n",
    "prediction_dp, _ = predict_deep_prime(data_dp, num_features=24, dropout=0)\n",
    "\n",
    "prediction_mlp = defaultdict(list)\n",
    "prediction_rf = defaultdict(list)\n",
    "prediction_xgb = defaultdict(list)\n",
    "prediction_ridge = defaultdict(list)\n",
    "prediction_lasso = defaultdict(list)\n",
    "\n",
    "data = pd.read_csv(f'models/data/conventional-ml/ml-{dataf}.csv')\n",
    "for i in range(5):\n",
    "    fold = i + 1\n",
    "    # load the test data\n",
    "    X_test = data[data['fold'] == i].iloc[:, :24].values\n",
    "    y_test = data[data['fold'] == i].iloc[:, -2].values\n",
    "    # load the models\n",
    "    with open(f'models/trained-models/conventional-ml/random_forest-{dataf}-fold-{fold}.pkl', 'rb') as f:\n",
    "        rf = pickle.load(f)\n",
    "    with open(f'models/trained-models/conventional-ml/xgboost-{dataf}-fold-{fold}.pkl', 'rb') as f:\n",
    "        xgb = pickle.load(f)\n",
    "    with open(f'models/trained-models/conventional-ml/ridge-{dataf}-fold-{fold}.pkl', 'rb') as f:\n",
    "        ridge = pickle.load(f)\n",
    "    with open(f'models/trained-models/conventional-ml/lasso-{dataf}-fold-{fold}.pkl', 'rb') as f:\n",
    "        lasso = pickle.load(f)\n",
    "    mlp_model = skorch.NeuralNetRegressor(\n",
    "            module=MLP,\n",
    "            device='cuda',\n",
    "            module__hidden_layer_sizes = (64, 64,),\n",
    "        )\n",
    "    mlp_model.initialize()\n",
    "    mlp_model.load_params(f_params=f'models/trained-models/conventional-ml/mlp-{dataf}-fold-{fold}.pkl')\n",
    "\n",
    "    prediction_rf[i] = rf.predict(X_test)\n",
    "    prediction_xgb[i] = xgb.predict(X_test)\n",
    "    prediction_ridge[i] = ridge.predict(X_test)\n",
    "    prediction_lasso[i] = lasso.predict(X_test)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "    prediction_mlp[i] = mlp_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated\n",
      "DeepPrime: 7.966364765419128\n",
      "Pridict: 7.534081612683751\n",
      "Random Forest: 11.592164981507011\n",
      "XGBoost: 8.915411581313538\n",
      "Ridge: 12.75532162963164\n",
      "Lasso: 12.764637179538392\n",
      "MLP: 9.094953108494588\n",
      "DeepPrime: 0.7266448200087834\n",
      "Pridict: 0.7389845223299198\n",
      "Random Forest: 0.5460940078538321\n",
      "XGBoost: 0.6784569526021045\n",
      "Ridge: 0.4772411780527162\n",
      "Lasso: 0.476662174828017\n",
      "MLP: 0.6704486256032288\n"
     ]
    }
   ],
   "source": [
    "# concatenate the predictions for each fold into a single array\n",
    "prediction_pd_list = np.concatenate([prediction_pd[fold].flatten() for fold in range(5)])\n",
    "prediction_dp_list = np.concatenate([prediction_dp[fold].flatten() for fold in range(5)])\n",
    "prediction_rf_list = np.concatenate([prediction_rf[fold] for fold in range(5)])\n",
    "prediction_xgb_list = np.concatenate([prediction_xgb[fold] for fold in range(5)])\n",
    "prediction_ridge_list = np.concatenate([prediction_ridge[fold] for fold in range(5)])\n",
    "prediction_lasso_list = np.concatenate([prediction_lasso[fold] for fold in range(5)])\n",
    "prediction_mlp_list = np.concatenate([prediction_mlp[fold].flatten() for fold in range(5)])\n",
    "\n",
    "print('Concatenated')\n",
    "\n",
    "# calculate the squared error from the predictions\n",
    "y_test = np.concatenate([data[data['fold'] == i].iloc[:, -2].values for i in range(5)])\n",
    "mse_dp = (y_test - prediction_dp_list)**2\n",
    "mse_pd = (y_test - prediction_pd_list)**2\n",
    "mse_rf = (y_test - prediction_rf_list)**2\n",
    "mse_xgb = (y_test - prediction_xgb_list)**2\n",
    "mse_ridge = (y_test - prediction_ridge_list)**2\n",
    "mse_lasso = (y_test - prediction_lasso_list)**2\n",
    "mse_mlp = (y_test - prediction_mlp_list)**2\n",
    "\n",
    "# print the mse of each model\n",
    "print('DeepPrime:', np.sum(mse_dp) / len(mse_dp))\n",
    "print('Pridict:', np.sum(mse_pd) / len(mse_pd))\n",
    "print('Random Forest:', np.sum(mse_rf) / len(mse_rf))\n",
    "print('XGBoost:', np.sum(mse_xgb) / len(mse_xgb))\n",
    "print('Ridge:', np.sum(mse_ridge) / len(mse_ridge))\n",
    "print('Lasso:', np.sum(mse_lasso) / len(mse_lasso))\n",
    "print('MLP:', np.sum(mse_mlp) / len(mse_mlp))\n",
    "\n",
    "# print the pearson correlation coefficient between model predictions and true values\n",
    "from scipy.stats import pearsonr\n",
    "print('DeepPrime:', pearsonr(y_test, prediction_dp_list)[0])\n",
    "print('Pridict:', pearsonr(y_test, prediction_pd_list)[0])\n",
    "print('Random Forest:', pearsonr(y_test, prediction_rf_list)[0])\n",
    "print('XGBoost:', pearsonr(y_test, prediction_xgb_list)[0])\n",
    "print('Ridge:', pearsonr(y_test, prediction_ridge_list)[0])\n",
    "print('Lasso:', pearsonr(y_test, prediction_lasso_list)[0])\n",
    "print('MLP:', pearsonr(y_test, prediction_mlp_list)[0])\n",
    "\n",
    "# normalize the squared error\n",
    "mse_dp = mse_dp / np.sum(mse_dp)\n",
    "mse_pd = mse_pd / np.sum(mse_pd)\n",
    "mse_rf = mse_rf / np.sum(mse_rf)\n",
    "mse_xgb = mse_xgb / np.sum(mse_xgb)\n",
    "mse_ridge = mse_ridge / np.sum(mse_ridge)\n",
    "mse_lasso = mse_lasso / np.sum(mse_lasso)\n",
    "mse_mlp = mse_mlp / np.sum(mse_mlp)\n",
    "\n",
    "\n",
    "# plot the smoothened error using a moving average\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w\n",
    "\n",
    "# downsample the data to improve visualization\n",
    "x = np.arange(len(mse_dp))\n",
    "downsample = 100\n",
    "x = x[::downsample]\n",
    "mse_dp = mse_dp[::downsample]\n",
    "mse_pd = mse_pd[::downsample]\n",
    "mse_rf = mse_rf[::downsample]\n",
    "mse_xgb = mse_xgb[::downsample]\n",
    "mse_ridge = mse_ridge[::downsample]\n",
    "mse_lasso = mse_lasso[::downsample]\n",
    "mse_mlp = mse_mlp[::downsample]\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(8, 4.5))\n",
    "window = 1000\n",
    "# update x to match the length of the moving average\n",
    "x = x[:-(window - 1)]\n",
    "axes.plot(x, moving_average(mse_dp, window), label='DeepPrime')\n",
    "axes.plot(x, moving_average(mse_pd, window), label='Pridict')\n",
    "axes.plot(x, moving_average(mse_rf, window), label='Random Forest')\n",
    "axes.plot(x, moving_average(mse_xgb, window), label='XGBoost')\n",
    "axes.plot(x, moving_average(mse_ridge, window), label='Ridge')\n",
    "axes.plot(x, moving_average(mse_lasso, window), label='Lasso')\n",
    "axes.plot(x, moving_average(mse_mlp, window), label='MLP')\n",
    "# legend of two rows\n",
    "axes.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=4)\n",
    "\n",
    "# set x and y labels\n",
    "axes.set_xlabel('Data Index')\n",
    "axes.set_ylabel('Normalized Squared Error')\n",
    "\n",
    "\n",
    "# reduce thickness and alpha of the lines\n",
    "for line in plt.gca().lines:\n",
    "    line.set_linewidth(1)\n",
    "    line.set_alpha(0.5)\n",
    "\n",
    "# remove the top and right spines\n",
    "axes.spines['top'].set_visible(False)\n",
    "axes.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('dissertation', 'figures', f'error_comparison_{dataf}.png'), dpi=300)\n",
    "\n",
    "# calculate the pearson correlation coefficient between each error and plot in heatmap\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "mse_dict = {\n",
    "    'DeepPrime': mse_dp,\n",
    "    'Pridict': mse_pd,\n",
    "    'Random Forest': mse_rf,\n",
    "    'XGBoost': mse_xgb,\n",
    "    'Ridge': mse_ridge,\n",
    "    'Lasso': mse_lasso,\n",
    "    'MLP': mse_mlp,\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5, 5.5))\n",
    "\n",
    "correlation_matrix = np.zeros((len(mse_dict), len(mse_dict)))\n",
    "for i, mse in enumerate(mse_dict.values()):\n",
    "    for j, mse2 in enumerate(mse_dict.values()):\n",
    "        correlation_matrix[i, j] = pearsonr(mse, mse2)[0]\n",
    "\n",
    "# heat map with cbar in range 0 to 1, horizontal and on top of the plot\n",
    "sns.heatmap(correlation_matrix, ax=axes, cbar_kws={'location': 'top', 'pad': 0.05}, vmin=0, vmax=1, cmap='coolwarm', annot=True)\n",
    "\n",
    "# set cbar limit\n",
    "# cbar = axes.collections[0].colorbar\n",
    "# cbar.set_ticks([0, 0.5, 1])\n",
    "plt.xticks(np.arange(len(mse_dict)) + 0.5, mse_dict.keys(), rotation=45)\n",
    "plt.yticks(np.arange(len(mse_dict)) + 0.5, mse_dict.keys(), rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('dissertation', 'figures', f'error_correlation_{dataf}_pearson.png'), dpi=300)\n",
    "\n",
    "fig, axes = plt.subplots(1, 1, figsize=(5, 5.5))\n",
    "\n",
    "correlation_matrix = np.zeros((len(mse_dict), len(mse_dict)))\n",
    "for i, mse in enumerate(mse_dict.values()):\n",
    "    for j, mse2 in enumerate(mse_dict.values()):\n",
    "        # spearman correlation\n",
    "        correlation_matrix[i, j] = spearmanr(mse, mse2)[0]\n",
    "\n",
    "# heat map with cbar in range 0 to 1, horizontal and on top of the plot\n",
    "sns.heatmap(correlation_matrix, ax=axes, cbar_kws={'location': 'top', 'pad': 0.05}, vmin=0, vmax=1, cmap='coolwarm', annot=True)\n",
    "\n",
    "plt.xticks(np.arange(len(mse_dict)) + 0.5, mse_dict.keys(), rotation=45)\n",
    "plt.yticks(np.arange(len(mse_dict)) + 0.5, mse_dict.keys(), rotation=0)\n",
    "\n",
    "# save the plots\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join('dissertation', 'figures', f'error_correlation_{dataf}_spearman.png'), dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
