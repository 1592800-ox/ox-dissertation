# plot both the pearson and spearman correlation performance
# each figure contains the performance of the model on the different datasets
import pandas as pd
import numpy as np
from os.path import join as pjoin
import matplotlib.pyplot as plt
import seaborn as sns
import ast
import scipy

performance_pearson = pd.read_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-pearson.csv'), index_col=0)
performance_spearman = pd.read_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-spearman.csv'), index_col=0)
f_size = 14

adjustment_shorthands = {
    'weighted-mse': '   WMSE',
    'quantile-transform': '     QT',
    'original': '     OG',
    'log': '     LA',
    'undersample': '     US'
}

# convert all list strings to list
import ast

performance_pearson = performance_pearson.map(lambda x: ast.literal_eval(x))
performance_spearman = performance_spearman.map(lambda x: ast.literal_eval(x))

for i, data in enumerate(['dp-dp-hek293t-pe2', 'dp-pd-hek293t-pe2', 'dp-pd-k562-pe2', 'dp-pd-k562mlh1d-pe2', 'dp-pd-adv-pe2']):
    # plot the performance of the model on the different datasets
    fig, ax = plt.subplots(1, 2, figsize=(10, 1.8), width_ratios=(1.2, 1))
    cell_data_pearson = performance_pearson.loc[data]
    # into a dataframe of two columns, adjustment and performance
    cell_data_pearson = pd.DataFrame(np.array(cell_data_pearson.tolist()).T, columns=['original', 'log', 'undersample'])
    
    cell_data_spearman = performance_spearman.loc[data]
    cell_data_spearman = pd.DataFrame(np.array(cell_data_spearman.tolist()).T, columns=['original', 'log', 'undersample'])
    
    for ind, performance in enumerate([performance_pearson, performance_spearman]):
        # plot the mean of each adjustment as barplot
        # plot stripplot of the performance of each fold on top
        # of the barplot
        cell_data = cell_data_pearson if ind == 0 else cell_data_spearman
        sns.barplot(data=cell_data, ax=ax[ind], palette=iter(sns.color_palette('icefire', 3)),alpha=0.5, orient='h', errorbar=None)
        sns.stripplot(data=cell_data, ax=ax[ind], palette=iter(sns.color_palette('icefire', 3)), size=5, jitter=True, orient='h')
        # ax[ind].set_title('Pearson' if ind == 0 else 'Spearman')
        metric = 'Pearson' if ind == 0 else 'Spearman'
        ax[ind].set_xlabel(f'{metric}', fontsize=f_size)
        # ax[ind].set_ylabel('Adjustment')
        
        # fix y axis to 0 to 1
        ax[ind].set_xlim(0, 1)
        
        # remove top and right spines
        ax[ind].spines['top'].set_visible(False)
        if ind == 0:
            ax[ind].spines['left'].set_visible(False)
        else:
            ax[ind].spines['right'].set_visible(False)
            
        # test the significance between each adjustment with the original
        # using the paired t-test
        original = cell_data['original']
        for adj in cell_data.columns:
            if adj != 'original':
                if np.mean(cell_data[adj]) > np.mean(cell_data['original']):
                    t_stat, p_val = scipy.stats.ttest_rel(cell_data[adj], original)
                    if p_val < 0.05:
                        print(f'{data} {metric} {adjustment_shorthands[adj]}: {p_val}')
    
    ax[0].set_yticks(range(len(cell_data.columns)))
    ax[0].set_yticklabels([adjustment_shorthands[adj] for adj in cell_data.columns])
    # ax 1 should have no y labels
    ax[1].set_yticklabels([])
    # flip the x axis of ax 0
    ax[0].invert_xaxis()
    # move the y axis of ax 0 to the right
    ax[0].yaxis.tick_right()
    
    # change the font of x tick labels
    ax[0].tick_params(axis='both', which='major', labelsize=f_size)
    ax[1].tick_params(axis='both', which='major', labelsize=f_size)
        
    plt.tight_layout()
    
    # save the figure
    data_name = '-'.join(data.split('-')[1:3])
    plt.savefig(pjoin('dissertation/figures', f'adjustment-deepprime-{data_name}-performance.png'), dpi=300)