{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 5\n",
      "Training Random Forest\n",
      "Fold 2 of 5\n",
      "Training Random Forest\n",
      "Fold 3 of 5\n",
      "Training Random Forest\n",
      "Fold 4 of 5\n",
      "Training Random Forest\n",
      "Fold 5 of 5\n",
      "Training Random Forest\n"
     ]
    }
   ],
   "source": [
    "# test the effects of undersampling\n",
    "\n",
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import collections\n",
    "from utils.stats_utils import get_pearson_and_spearman_correlation\n",
    "from utils.data_utils import k_fold_cross_validation_split\n",
    "from models.conventional_ml_models import lasso_regression, ridge_regression, mlp, xgboost, random_forest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import skorch\n",
    "from models.conventional_ml_models import MLP\n",
    "import os\n",
    "\n",
    "# datas = ['ml-dp-hek293t-pe2.csv', 'ml-pd-hek293t-pe2.csv', 'ml-pd-adv-pe2.csv', 'ml-pd-k562-pe2.csv', 'ml-pd-k562mlh1d-pe2.csv']\n",
    "datas = ['ml-pd-k562mlh1dn-pe2.csv']\n",
    "\n",
    "performance = {}\n",
    "\n",
    "def undersample(features, target):\n",
    "    # sample 10% of the training data with editing efficiency of less than 10\n",
    "    indices = np.where(target < 10)[0]\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.choice(indices, int(len(indices) * 0.1), replace=False)\n",
    "    features = np.delete(features, indices, axis=0)\n",
    "    target = np.delete(target, indices, axis=0)\n",
    "    return features, target\n",
    "\n",
    "for data in datas:\n",
    "    dataset = pd.read_csv(pjoin('models', 'data', 'conventional-ml', data))\n",
    "    cell_line = '-'.join(data.split('-')[1:3]).split('.')[0]\n",
    "    data_source = '-'.join(data.split('-')[1:]).split('.')[0]\n",
    "\n",
    "    # 5 fold cross validation\n",
    "    fold = 5\n",
    "\n",
    "    features = dataset.iloc[:, :24].values\n",
    "    target = dataset.iloc[:, -2].values\n",
    "\n",
    "    # standardize the features\n",
    "    # scaler = StandardScaler()\n",
    "    # features = scaler.fit_transform(features)\n",
    "\n",
    "    correlations = collections.defaultdict(list)\n",
    "    \n",
    "    for i in range(0, fold):\n",
    "        print(f'Fold {i+1} of {fold}')\n",
    "        train_features = features[dataset['fold'] != i]\n",
    "        train_target = target[dataset['fold'] != i]\n",
    "        \n",
    "        # ============================\n",
    "        # Lasso\n",
    "        # ============================\n",
    "        # print('Training Lasso')\n",
    "        # lasso_model = lasso_regression()\n",
    "        # lasso_model.fit(train_features, train_target)\n",
    "        # # pickle the model\n",
    "        # pickle.dump(lasso_model, open(pjoin('models', 'trained-models', 'conventional-ml', f'lasso-{data_source}-fold-{i+1}.pkl'), 'wb'))\n",
    "\n",
    "        # ============================\n",
    "        # Ridge\n",
    "        # ============================\n",
    "        # print('Training Ridge')\n",
    "        # ridge_model = ridge_regression()\n",
    "        # ridge_model.fit(train_features, train_target)\n",
    "        # # pickle the model\n",
    "        # pickle.dump(ridge_model, open(pjoin('models', 'trained-models', 'conventional-ml', f'ridge-{data_source}-fold-{i+1}.pkl'), 'wb'))\n",
    "\n",
    "        # ============================\n",
    "        # xgboost\n",
    "        # ============================\n",
    "        # print('Training XGBoost')\n",
    "        # xgboost_model = xgboost()\n",
    "        # xgboost_model.fit(train_features, train_target)\n",
    "        # # pickle the model\n",
    "        # pickle.dump(xgboost_model, open(pjoin('models', 'trained-models', 'conventional-ml', f'xgboost-{data_source}-fold-{i+1}.pkl'), 'wb'))\n",
    "\n",
    "        # ============================\n",
    "        # random forest\n",
    "        # ============================\n",
    "        print('Training Random Forest')\n",
    "        rf_model = random_forest()\n",
    "        rf_model.fit(train_features, train_target)\n",
    "        # pickle the model\n",
    "        pickle.dump(rf_model, open(pjoin('models', 'trained-models', 'conventional-ml', f'random_forest-{data_source}-fold-{i+1}.pkl'), 'wb'))\n",
    "        \n",
    "        # ============================\n",
    "        # MLP\n",
    "        # ============================\n",
    "        \n",
    "        # print('Training MLP')\n",
    "        # mlp_model = skorch.NeuralNetRegressor(\n",
    "        #     module=MLP,\n",
    "        #     criterion=torch.nn.MSELoss,\n",
    "        #     optimizer=torch.optim.Adam,\n",
    "        #     max_epochs=200,\n",
    "        #     module__activation='relu',\n",
    "        #     lr=0.005,\n",
    "        #     device='cuda',\n",
    "        #     batch_size=2048,\n",
    "        #     train_split=skorch.dataset.ValidSplit(cv=5),\n",
    "        #     module__hidden_layer_sizes = (64, 64,),\n",
    "        #     # early stopping\n",
    "        #     callbacks=[\n",
    "        #         skorch.callbacks.EarlyStopping(patience=20),\n",
    "        #         skorch.callbacks.Checkpoint(monitor='valid_loss_best', f_pickle=None, f_criterion=None, f_optimizer=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}-optimizer.pkl'), f_history=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}-history.json'), f_params=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}.pkl'), event_name='event_cp'),\n",
    "        #         skorch.callbacks.LRScheduler(policy=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts, monitor='valid_loss', T_0=20, T_mult=1),\n",
    "        #     ]\n",
    "        # )\n",
    "        # # convert features and target to float32\n",
    "        # train_features = train_features.astype(np.float32)\n",
    "        # train_target = train_target.astype(np.float32)\n",
    "        # # add a dimension to the target\n",
    "        # train_target = train_target[:, np.newaxis]\n",
    "        # mlp_model.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 5\n",
      "Lasso: Pearson: 0.4782546737741159, Spearman: 0.6244751703334932\n",
      "Ridge: Pearson: 0.4789450204905127, Spearman: 0.6239472097543418\n",
      "XGBoost: Pearson: 0.6830840206020848, Spearman: 0.706669166061669\n",
      "Random Forest: Pearson: 0.5466548093027793, Spearman: 0.6554852669039746\n",
      "MLP: Pearson: 0.6712391188685414, Spearman: 0.7209518796241547\n",
      "-----------------------------------\n",
      "Fold 2 of 5\n",
      "Lasso: Pearson: 0.4807923014055205, Spearman: 0.6297044764571451\n",
      "Ridge: Pearson: 0.48130391067032485, Spearman: 0.6289742059308001\n",
      "XGBoost: Pearson: 0.6829044476969314, Spearman: 0.7094211294557947\n",
      "Random Forest: Pearson: 0.546970061533267, Spearman: 0.6544914971241744\n",
      "MLP: Pearson: 0.6771810414120725, Spearman: 0.7258806513582833\n",
      "-----------------------------------\n",
      "Fold 3 of 5\n",
      "Lasso: Pearson: 0.47356089776311816, Spearman: 0.6221165666282918\n",
      "Ridge: Pearson: 0.4742996513221558, Spearman: 0.6216773455303238\n",
      "XGBoost: Pearson: 0.671449961652932, Spearman: 0.7050814856518144\n",
      "Random Forest: Pearson: 0.5411373529802663, Spearman: 0.6518294238197161\n",
      "MLP: Pearson: 0.6656166738255057, Spearman: 0.7190423276457876\n",
      "-----------------------------------\n",
      "Fold 4 of 5\n",
      "Lasso: Pearson: 0.47894073747931154, Spearman: 0.626401688773485\n",
      "Ridge: Pearson: 0.4795455430633675, Spearman: 0.6258696825916983\n",
      "XGBoost: Pearson: 0.6821915586043362, Spearman: 0.70946011669987\n",
      "Random Forest: Pearson: 0.5488055127595046, Spearman: 0.656441706117315\n",
      "MLP: Pearson: 0.6722534178250972, Spearman: 0.723834918008195\n",
      "-----------------------------------\n",
      "Fold 5 of 5\n",
      "Lasso: Pearson: 0.4721823770988343, Spearman: 0.6193970544060275\n",
      "Ridge: Pearson: 0.4725281311275008, Spearman: 0.6186936706534059\n",
      "XGBoost: Pearson: 0.6730389541666517, Spearman: 0.7047716045248319\n",
      "Random Forest: Pearson: 0.5472577624660829, Spearman: 0.6528822468681181\n",
      "MLP: Pearson: 0.6662116165395873, Spearman: 0.7163447363959918\n",
      "-----------------------------------\n",
      "defaultdict(<class 'list'>, {'Lasso': [(0.4782546737741159, 0.6244751703334932), (0.4807923014055205, 0.6297044764571451), (0.47356089776311816, 0.6221165666282918), (0.47894073747931154, 0.626401688773485), (0.4721823770988343, 0.6193970544060275)], 'Ridge': [(0.4789450204905127, 0.6239472097543418), (0.48130391067032485, 0.6289742059308001), (0.4742996513221558, 0.6216773455303238), (0.4795455430633675, 0.6258696825916983), (0.4725281311275008, 0.6186936706534059)], 'XGBoost': [(0.6830840206020848, 0.706669166061669), (0.6829044476969314, 0.7094211294557947), (0.671449961652932, 0.7050814856518144), (0.6821915586043362, 0.70946011669987), (0.6730389541666517, 0.7047716045248319)], 'RF': [(0.5466548093027793, 0.6554852669039746), (0.546970061533267, 0.6544914971241744), (0.5411373529802663, 0.6518294238197161), (0.5488055127595046, 0.656441706117315), (0.5472577624660829, 0.6528822468681181)], 'MLP': [(0.6712391188685414, 0.7209518796241547), (0.6771810414120725, 0.7258806513582833), (0.6656166738255057, 0.7190423276457876), (0.6722534178250972, 0.723834918008195), (0.6662116165395873, 0.7163447363959918)]})\n",
      "Fold 1 of 5\n",
      "Lasso: Pearson: 0.724790636564807, Spearman: 0.8039598704866452\n",
      "Ridge: Pearson: 0.7220312484811661, Spearman: 0.805095498746808\n",
      "XGBoost: Pearson: 0.8378764602839108, Spearman: 0.8451805337172772\n",
      "Random Forest: Pearson: 0.8042300882229417, Spearman: 0.825077982956248\n",
      "MLP: Pearson: 0.7896703547920899, Spearman: 0.8114409015294082\n",
      "-----------------------------------\n",
      "Fold 2 of 5\n",
      "Lasso: Pearson: 0.7282782925799367, Spearman: 0.8044270759762765\n",
      "Ridge: Pearson: 0.7263760928718654, Spearman: 0.8058532365457343\n",
      "XGBoost: Pearson: 0.8353596274267526, Spearman: 0.8349987989043167\n",
      "Random Forest: Pearson: 0.8062662313029267, Spearman: 0.8194875412986099\n",
      "MLP: Pearson: 0.8022651649070878, Spearman: 0.8210361092180941\n",
      "-----------------------------------\n",
      "Fold 3 of 5\n",
      "Lasso: Pearson: 0.7257480771060346, Spearman: 0.7956732887601885\n",
      "Ridge: Pearson: 0.7235790047982503, Spearman: 0.7967852191367243\n",
      "XGBoost: Pearson: 0.8369248862912875, Spearman: 0.8375444314678939\n",
      "Random Forest: Pearson: 0.8069054630894009, Spearman: 0.816293166829528\n",
      "MLP: Pearson: 0.800825182096703, Spearman: 0.8174458317228185\n",
      "-----------------------------------\n",
      "Fold 4 of 5\n",
      "Lasso: Pearson: 0.7259140653902575, Spearman: 0.7933009249978304\n",
      "Ridge: Pearson: 0.7249397292705906, Spearman: 0.7957330085110981\n",
      "XGBoost: Pearson: 0.8289903442244276, Spearman: 0.8397381742402042\n",
      "Random Forest: Pearson: 0.8049823834510376, Spearman: 0.8243455883847272\n",
      "MLP: Pearson: 0.7881551660880418, Spearman: 0.8180081451893032\n",
      "-----------------------------------\n",
      "Fold 5 of 5\n",
      "Lasso: Pearson: 0.7279307199687216, Spearman: 0.8008283433756517\n",
      "Ridge: Pearson: 0.7265118452495115, Spearman: 0.8031848973095914\n",
      "XGBoost: Pearson: 0.8327318930457699, Spearman: 0.8396830158704464\n",
      "Random Forest: Pearson: 0.8021940622119947, Spearman: 0.8185911821223871\n",
      "MLP: Pearson: 0.8100364626005772, Spearman: 0.835838576733305\n",
      "-----------------------------------\n",
      "defaultdict(<class 'list'>, {'Lasso': [(0.724790636564807, 0.8039598704866452), (0.7282782925799367, 0.8044270759762765), (0.7257480771060346, 0.7956732887601885), (0.7259140653902575, 0.7933009249978304), (0.7279307199687216, 0.8008283433756517)], 'Ridge': [(0.7220312484811661, 0.805095498746808), (0.7263760928718654, 0.8058532365457343), (0.7235790047982503, 0.7967852191367243), (0.7249397292705906, 0.7957330085110981), (0.7265118452495115, 0.8031848973095914)], 'XGBoost': [(0.8378764602839108, 0.8451805337172772), (0.8353596274267526, 0.8349987989043167), (0.8369248862912875, 0.8375444314678939), (0.8289903442244276, 0.8397381742402042), (0.8327318930457699, 0.8396830158704464)], 'RF': [(0.8042300882229417, 0.825077982956248), (0.8062662313029267, 0.8194875412986099), (0.8069054630894009, 0.816293166829528), (0.8049823834510376, 0.8243455883847272), (0.8021940622119947, 0.8185911821223871)], 'MLP': [(0.7896703547920899, 0.8114409015294082), (0.8022651649070878, 0.8210361092180941), (0.800825182096703, 0.8174458317228185), (0.7881551660880418, 0.8180081451893032), (0.8100364626005772, 0.835838576733305)]})\n",
      "Fold 1 of 5\n",
      "Lasso: Pearson: 0.36745300186967644, Spearman: 0.5476771442956996\n",
      "Ridge: Pearson: 0.3672233256356153, Spearman: 0.5462378498826761\n",
      "XGBoost: Pearson: 0.38339222387891025, Spearman: 0.48465272040360124\n",
      "Random Forest: Pearson: 0.37036294883296106, Spearman: 0.527431317593599\n",
      "MLP: Pearson: 0.4237459550994734, Spearman: 0.5691885790343904\n",
      "-----------------------------------\n",
      "Fold 2 of 5\n",
      "Lasso: Pearson: 0.4003498445900121, Spearman: 0.540180130298842\n",
      "Ridge: Pearson: 0.3985353703218082, Spearman: 0.5376329198435676\n",
      "XGBoost: Pearson: 0.43502990207129716, Spearman: 0.4809804477516603\n",
      "Random Forest: Pearson: 0.42836196373813457, Spearman: 0.5455154814063944\n",
      "MLP: Pearson: 0.46351584291964304, Spearman: 0.5594465142295497\n",
      "-----------------------------------\n",
      "Fold 3 of 5\n",
      "Lasso: Pearson: 0.3640159597368552, Spearman: 0.5407541716629055\n",
      "Ridge: Pearson: 0.3626758348434779, Spearman: 0.5384638912086234\n",
      "XGBoost: Pearson: 0.376425409829848, Spearman: 0.4796020010278425\n",
      "Random Forest: Pearson: 0.41150974796874695, Spearman: 0.5453842695181746\n",
      "MLP: Pearson: 0.44441999381130304, Spearman: 0.5643066675470357\n",
      "-----------------------------------\n",
      "Fold 4 of 5\n",
      "Lasso: Pearson: 0.3727054122156826, Spearman: 0.5453541602219653\n",
      "Ridge: Pearson: 0.3715398898316056, Spearman: 0.5426378567426215\n",
      "XGBoost: Pearson: 0.42687592181021056, Spearman: 0.48595018347933133\n",
      "Random Forest: Pearson: 0.40098038895711646, Spearman: 0.5337594239491166\n",
      "MLP: Pearson: 0.42072433389186314, Spearman: 0.5053600991001914\n",
      "-----------------------------------\n",
      "Fold 5 of 5\n",
      "Lasso: Pearson: 0.3809254171328932, Spearman: 0.5456444243676306\n",
      "Ridge: Pearson: 0.380640318159774, Spearman: 0.5441439032189994\n",
      "XGBoost: Pearson: 0.4605034003346023, Spearman: 0.5000992397095559\n",
      "Random Forest: Pearson: 0.436068787021133, Spearman: 0.5554185590118424\n",
      "MLP: Pearson: 0.46484532289071345, Spearman: 0.5371780620347911\n",
      "-----------------------------------\n",
      "defaultdict(<class 'list'>, {'Lasso': [(0.36745300186967644, 0.5476771442956996), (0.4003498445900121, 0.540180130298842), (0.3640159597368552, 0.5407541716629055), (0.3727054122156826, 0.5453541602219653), (0.3809254171328932, 0.5456444243676306)], 'Ridge': [(0.3672233256356153, 0.5462378498826761), (0.3985353703218082, 0.5376329198435676), (0.3626758348434779, 0.5384638912086234), (0.3715398898316056, 0.5426378567426215), (0.380640318159774, 0.5441439032189994)], 'XGBoost': [(0.38339222387891025, 0.48465272040360124), (0.43502990207129716, 0.4809804477516603), (0.376425409829848, 0.4796020010278425), (0.42687592181021056, 0.48595018347933133), (0.4605034003346023, 0.5000992397095559)], 'RF': [(0.37036294883296106, 0.527431317593599), (0.42836196373813457, 0.5455154814063944), (0.41150974796874695, 0.5453842695181746), (0.40098038895711646, 0.5337594239491166), (0.436068787021133, 0.5554185590118424)], 'MLP': [(0.4237459550994734, 0.5691885790343904), (0.46351584291964304, 0.5594465142295497), (0.44441999381130304, 0.5643066675470357), (0.42072433389186314, 0.5053600991001914), (0.46484532289071345, 0.5371780620347911)]})\n",
      "Fold 1 of 5\n",
      "Lasso: Pearson: 0.4111335839660726, Spearman: 0.6178659146511041\n",
      "Ridge: Pearson: 0.407086701617713, Spearman: 0.6193746923038693\n",
      "XGBoost: Pearson: 0.5097523890082232, Spearman: 0.5882427674071459\n",
      "Random Forest: Pearson: 0.4564191212489246, Spearman: 0.6283397284941571\n",
      "MLP: Pearson: 0.49986166088899503, Spearman: 0.6403626258241213\n",
      "-----------------------------------\n",
      "Fold 2 of 5\n",
      "Lasso: Pearson: 0.4122712223209479, Spearman: 0.5993648911736513\n",
      "Ridge: Pearson: 0.41062988211104984, Spearman: 0.6030855728286515\n",
      "XGBoost: Pearson: 0.5015575657675804, Spearman: 0.5623386888301011\n",
      "Random Forest: Pearson: 0.4418957843516608, Spearman: 0.606021748616398\n",
      "MLP: Pearson: 0.4883646260382269, Spearman: 0.643796587360076\n",
      "-----------------------------------\n",
      "Fold 3 of 5\n",
      "Lasso: Pearson: 0.4099424742317089, Spearman: 0.5876232618379194\n",
      "Ridge: Pearson: 0.40735670135901864, Spearman: 0.5870743550595273\n",
      "XGBoost: Pearson: 0.5039342939229747, Spearman: 0.5687833252368449\n",
      "Random Forest: Pearson: 0.4594838698963256, Spearman: 0.6152002525872107\n",
      "MLP: Pearson: 0.5073924414618254, Spearman: 0.6208866580502753\n",
      "-----------------------------------\n",
      "Fold 4 of 5\n",
      "Lasso: Pearson: 0.4175710874385664, Spearman: 0.6138896793878017\n",
      "Ridge: Pearson: 0.4152956545659633, Spearman: 0.6144941494343557\n",
      "XGBoost: Pearson: 0.5166265855659722, Spearman: 0.5866170199415788\n",
      "Random Forest: Pearson: 0.4543357344345661, Spearman: 0.624272736214282\n",
      "MLP: Pearson: 0.505574975806466, Spearman: 0.6505013560422249\n",
      "-----------------------------------\n",
      "Fold 5 of 5\n",
      "Lasso: Pearson: 0.42926272784138325, Spearman: 0.6025378624319644\n",
      "Ridge: Pearson: 0.42674996525503567, Spearman: 0.6035587183775795\n",
      "XGBoost: Pearson: 0.519108968775433, Spearman: 0.5652244585080799\n",
      "Random Forest: Pearson: 0.487030921455113, Spearman: 0.6135172137350812\n",
      "MLP: Pearson: 0.5091439066449509, Spearman: 0.6292443771334431\n",
      "-----------------------------------\n",
      "defaultdict(<class 'list'>, {'Lasso': [(0.4111335839660726, 0.6178659146511041), (0.4122712223209479, 0.5993648911736513), (0.4099424742317089, 0.5876232618379194), (0.4175710874385664, 0.6138896793878017), (0.42926272784138325, 0.6025378624319644)], 'Ridge': [(0.407086701617713, 0.6193746923038693), (0.41062988211104984, 0.6030855728286515), (0.40735670135901864, 0.5870743550595273), (0.4152956545659633, 0.6144941494343557), (0.42674996525503567, 0.6035587183775795)], 'XGBoost': [(0.5097523890082232, 0.5882427674071459), (0.5015575657675804, 0.5623386888301011), (0.5039342939229747, 0.5687833252368449), (0.5166265855659722, 0.5866170199415788), (0.519108968775433, 0.5652244585080799)], 'RF': [(0.4564191212489246, 0.6283397284941571), (0.4418957843516608, 0.606021748616398), (0.4594838698963256, 0.6152002525872107), (0.4543357344345661, 0.624272736214282), (0.487030921455113, 0.6135172137350812)], 'MLP': [(0.49986166088899503, 0.6403626258241213), (0.4883646260382269, 0.643796587360076), (0.5073924414618254, 0.6208866580502753), (0.505574975806466, 0.6505013560422249), (0.5091439066449509, 0.6292443771334431)]})\n",
      "Fold 1 of 5\n",
      "Lasso: Pearson: 0.6427924482156209, Spearman: 0.7668328295929295\n",
      "Ridge: Pearson: 0.6390666404381897, Spearman: 0.7681778460977907\n",
      "XGBoost: Pearson: 0.7620425633891599, Spearman: 0.7867172499809815\n",
      "Random Forest: Pearson: 0.7612894319420733, Spearman: 0.8085143605130621\n",
      "MLP: Pearson: 0.7328897904505509, Spearman: 0.8005037264022796\n",
      "-----------------------------------\n",
      "Fold 2 of 5\n",
      "Lasso: Pearson: 0.6418611871003391, Spearman: 0.7598134392254309\n",
      "Ridge: Pearson: 0.6399177205058783, Spearman: 0.7630640082925502\n",
      "XGBoost: Pearson: 0.7515730027991785, Spearman: 0.7803812169320737\n",
      "Random Forest: Pearson: 0.7454621739539296, Spearman: 0.8025165107781557\n",
      "MLP: Pearson: 0.7355368672051207, Spearman: 0.8003229807624755\n",
      "-----------------------------------\n",
      "Fold 3 of 5\n",
      "Lasso: Pearson: 0.636708633243112, Spearman: 0.7503062486800075\n",
      "Ridge: Pearson: 0.6331347297997418, Spearman: 0.7515757431901908\n",
      "XGBoost: Pearson: 0.7507139866900435, Spearman: 0.7839430751819146\n",
      "Random Forest: Pearson: 0.7558355382320336, Spearman: 0.796699575951708\n",
      "MLP: Pearson: 0.7402769340662806, Spearman: 0.8009605359609188\n",
      "-----------------------------------\n",
      "Fold 4 of 5\n",
      "Lasso: Pearson: 0.636751990727804, Spearman: 0.7537884508714223\n",
      "Ridge: Pearson: 0.6351780915966699, Spearman: 0.7572411284825266\n",
      "XGBoost: Pearson: 0.755187751649025, Spearman: 0.7855363077091572\n",
      "Random Forest: Pearson: 0.7517390149842391, Spearman: 0.8078823981431482\n",
      "MLP: Pearson: 0.7235407435924842, Spearman: 0.796287253339956\n",
      "-----------------------------------\n",
      "Fold 5 of 5\n",
      "Lasso: Pearson: 0.6419187147095116, Spearman: 0.7605493958558593\n",
      "Ridge: Pearson: 0.6398721344019058, Spearman: 0.7648572242602495\n",
      "XGBoost: Pearson: 0.7536395179977126, Spearman: 0.7841015733919285\n",
      "Random Forest: Pearson: 0.7540219094742785, Spearman: 0.803257540829103\n",
      "MLP: Pearson: 0.7352631259104633, Spearman: 0.7946806573445144\n",
      "-----------------------------------\n",
      "defaultdict(<class 'list'>, {'Lasso': [(0.6427924482156209, 0.7668328295929295), (0.6418611871003391, 0.7598134392254309), (0.636708633243112, 0.7503062486800075), (0.636751990727804, 0.7537884508714223), (0.6419187147095116, 0.7605493958558593)], 'Ridge': [(0.6390666404381897, 0.7681778460977907), (0.6399177205058783, 0.7630640082925502), (0.6331347297997418, 0.7515757431901908), (0.6351780915966699, 0.7572411284825266), (0.6398721344019058, 0.7648572242602495)], 'XGBoost': [(0.7620425633891599, 0.7867172499809815), (0.7515730027991785, 0.7803812169320737), (0.7507139866900435, 0.7839430751819146), (0.755187751649025, 0.7855363077091572), (0.7536395179977126, 0.7841015733919285)], 'RF': [(0.7612894319420733, 0.8085143605130621), (0.7454621739539296, 0.8025165107781557), (0.7558355382320336, 0.796699575951708), (0.7517390149842391, 0.8078823981431482), (0.7540219094742785, 0.803257540829103)], 'MLP': [(0.7328897904505509, 0.8005037264022796), (0.7355368672051207, 0.8003229807624755), (0.7402769340662806, 0.8009605359609188), (0.7235407435924842, 0.796287253339956), (0.7352631259104633, 0.7946806573445144)]})\n",
      "                                                dp-hek293t  \\\n",
      "Lasso    [(0.4782546737741159, 0.6244751703334932), (0....   \n",
      "Ridge    [(0.4789450204905127, 0.6239472097543418), (0....   \n",
      "XGBoost  [(0.6830840206020848, 0.706669166061669), (0.6...   \n",
      "RF       [(0.5466548093027793, 0.6554852669039746), (0....   \n",
      "MLP      [(0.6712391188685414, 0.7209518796241547), (0....   \n",
      "\n",
      "                                                pd-hek293t  \\\n",
      "Lasso    [(0.724790636564807, 0.8039598704866452), (0.7...   \n",
      "Ridge    [(0.7220312484811661, 0.805095498746808), (0.7...   \n",
      "XGBoost  [(0.8378764602839108, 0.8451805337172772), (0....   \n",
      "RF       [(0.8042300882229417, 0.825077982956248), (0.8...   \n",
      "MLP      [(0.7896703547920899, 0.8114409015294082), (0....   \n",
      "\n",
      "                                                    pd-adv  \\\n",
      "Lasso    [(0.36745300186967644, 0.5476771442956996), (0...   \n",
      "Ridge    [(0.3672233256356153, 0.5462378498826761), (0....   \n",
      "XGBoost  [(0.38339222387891025, 0.48465272040360124), (...   \n",
      "RF       [(0.37036294883296106, 0.527431317593599), (0....   \n",
      "MLP      [(0.4237459550994734, 0.5691885790343904), (0....   \n",
      "\n",
      "                                                   pd-k562  \\\n",
      "Lasso    [(0.4111335839660726, 0.6178659146511041), (0....   \n",
      "Ridge    [(0.407086701617713, 0.6193746923038693), (0.4...   \n",
      "XGBoost  [(0.5097523890082232, 0.5882427674071459), (0....   \n",
      "RF       [(0.4564191212489246, 0.6283397284941571), (0....   \n",
      "MLP      [(0.49986166088899503, 0.6403626258241213), (0...   \n",
      "\n",
      "                                             pd-k562mlh1dn  \n",
      "Lasso    [(0.6427924482156209, 0.7668328295929295), (0....  \n",
      "Ridge    [(0.6390666404381897, 0.7681778460977907), (0....  \n",
      "XGBoost  [(0.7620425633891599, 0.7867172499809815), (0....  \n",
      "RF       [(0.7612894319420733, 0.8085143605130621), (0....  \n",
      "MLP      [(0.7328897904505509, 0.8005037264022796), (0....  \n",
      "Performance saved to models/data/performance/conventional-ml-performance.csv\n"
     ]
    }
   ],
   "source": [
    "# load the pickled models and evaluate on the corresponding validation set\n",
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import collections\n",
    "from utils.stats_utils import get_pearson_and_spearman_correlation\n",
    "from utils.data_utils import k_fold_cross_validation_split\n",
    "from models.conventional_ml_models import lasso_regression, ridge_regression, mlp, xgboost, random_forest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "import pickle\n",
    "import torch\n",
    "import skorch\n",
    "import os\n",
    "\n",
    "from models.conventional_ml_models import MLP\n",
    "\n",
    "datas = ['ml-dp-hek293t-pe2.csv', 'ml-pd-hek293t-pe2.csv', 'ml-pd-adv-pe2.csv', 'ml-pd-k562-pe2.csv', 'ml-pd-k562mlh1dn-pe2.csv']\n",
    "\n",
    "performance = {}\n",
    "\n",
    "for data in datas:\n",
    "    dataset = pd.read_csv(pjoin('models', 'data', 'conventional-ml', data))\n",
    "    cell_line = '-'.join(data.split('-')[1:3]).split('.')[0]\n",
    "    \n",
    "    data_source = '-'.join(data.split('-')[1:]).split('.')[0]\n",
    "\n",
    "    # 5 fold cross validation\n",
    "    fold = 5\n",
    "\n",
    "    features = dataset.iloc[:, :24].values\n",
    "    target = dataset.iloc[:, -2].values\n",
    "\n",
    "    correlations = collections.defaultdict(list)\n",
    "    \n",
    "    for i in range(0, fold):\n",
    "        X_test = features[dataset['fold'] == i]\n",
    "        y_test = target[dataset['fold'] == i]\n",
    "        print(f'Fold {i+1} of {fold}')\n",
    "\n",
    "        # ============================\n",
    "        # Lasso\n",
    "        # ============================\n",
    "        lasso_model = pickle.load(open(pjoin('models', 'trained-models', 'conventional-ml', f'lasso-{data_source}-fold-{i+1}.pkl'), 'rb'))\n",
    "        lasso_pred = lasso_model.predict(X_test)\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, lasso_pred)\n",
    "        correlations['Lasso'].append((pearson, spearman))\n",
    "        print(f'Lasso: Pearson: {pearson}, Spearman: {spearman}')\n",
    "\n",
    "        # ============================\n",
    "        # Ridge\n",
    "        # ============================\n",
    "        ridge_model = pickle.load(open(pjoin('models', 'trained-models', 'conventional-ml', f'ridge-{data_source}-fold-{i+1}.pkl'), 'rb'))\n",
    "        ridge_pred = ridge_model.predict(X_test)\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, ridge_pred)\n",
    "        correlations['Ridge'].append((pearson, spearman))\n",
    "        print(f'Ridge: Pearson: {pearson}, Spearman: {spearman}')\n",
    "        \n",
    "        # ============================\n",
    "        # xgboost\n",
    "        # ============================\n",
    "        xgboost_model = pickle.load(open(pjoin('models', 'trained-models', 'conventional-ml', f'xgboost-{data_source}-fold-{i+1}.pkl'), 'rb'))\n",
    "        xgboost_pred = xgboost_model.predict(X_test)\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, xgboost_pred)\n",
    "        correlations['XGBoost'].append((pearson, spearman))\n",
    "        print(f'XGBoost: Pearson: {pearson}, Spearman: {spearman}')\n",
    "        \n",
    "        # ============================\n",
    "        # random forest\n",
    "        # ============================\n",
    "        rf_model = pickle.load(open(pjoin('models', 'trained-models', 'conventional-ml', f'random_forest-{data_source}-fold-{i+1}.pkl'), 'rb'))\n",
    "        rf_pred = rf_model.predict(X_test)\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, rf_pred)\n",
    "        correlations['RF'].append((pearson, spearman))\n",
    "        print(f'Random Forest: Pearson: {pearson}, Spearman: {spearman}')\n",
    "        \n",
    "        # ============================\n",
    "        # MLP\n",
    "        # ============================\n",
    "        # load the pickled model\n",
    "        mlp_model = skorch.NeuralNetRegressor(\n",
    "            module=MLP,\n",
    "            criterion=torch.nn.MSELoss,\n",
    "            optimizer=torch.optim.Adam,\n",
    "            max_epochs=200,\n",
    "            module__activation='relu',\n",
    "            lr=0.001,\n",
    "            device='cuda',\n",
    "            batch_size=2048,\n",
    "            module__hidden_layer_sizes = (64, 64,),\n",
    "        )\n",
    "        mlp_model.initialize()\n",
    "        mlp_model.load_params(\n",
    "            f_optimizer=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}-optimizer.pkl'), \n",
    "            f_history=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}-history.json'), \n",
    "            f_params=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}.pkl')\n",
    "        )\n",
    "        X_test = X_test.astype(np.float32)\n",
    "        X_test = torch.tensor(X_test)\n",
    "        mlp_pred = mlp_model.predict(X_test)\n",
    "        # flatten the prediction\n",
    "        mlp_pred = mlp_pred.flatten()\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, mlp_pred)\n",
    "        correlations['MLP'].append((pearson, spearman))\n",
    "        print(f'MLP: Pearson: {pearson}, Spearman: {spearman}')\n",
    "        \n",
    "        print('-----------------------------------')\n",
    "    \n",
    "    print(correlations)\n",
    "    performance[cell_line] = correlations\n",
    "\n",
    "# save the performance\n",
    "save_file = pjoin('models', 'data', 'performance', 'conventional-ml-performance.csv')\n",
    "performance_df = pd.DataFrame(performance)\n",
    "print(performance_df)\n",
    "performance_df.to_csv(save_file)\n",
    "print(f'Performance saved to {save_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the performance in two heat maps, one for pearson and one for spearman\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from os.path import join as pjoin\n",
    "\n",
    "# cell line vs model\n",
    "performance_data = pjoin('models', 'data', 'performance', 'conventional-ml-performance.csv')\n",
    "df = pd.read_csv(performance_data, index_col=0)\n",
    "\n",
    "cell_lines = df.columns\n",
    "models = df.index\n",
    "\n",
    "# plot the mean of the pearson and spearman correlation\n",
    "pearson = np.zeros((len(models), len(cell_lines)))\n",
    "spearman = np.zeros((len(models), len(cell_lines)))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    for j, cell_line in enumerate(cell_lines):\n",
    "        performance = df.loc[model, cell_line]\n",
    "        # string to list\n",
    "        performance = ast.literal_eval(performance)\n",
    "        pearson[i, j] = np.mean([x[0] for x in performance])\n",
    "        spearman[i, j] = np.mean([x[1] for x in performance])\n",
    "\n",
    "font_size = 18\n",
    "\n",
    "# pearson and spearman correlation share the same color bar\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7), width_ratios=[1, 1])\n",
    "sns.heatmap(pearson, ax=axes[0], annot=True, xticklabels=cell_lines, yticklabels=models, cmap='icefire', cbar=False, vmin=0, vmax=1, annot_kws={'size': font_size})\n",
    "axes[0].set_title('Pearson')\n",
    "sns.heatmap(spearman, ax=axes[1], annot=True, xticklabels=cell_lines, yticklabels=models, cmap='icefire', cbar=False, vmin=0, vmax=1, annot_kws={'size': font_size})\n",
    "axes[1].set_title('Spearman')\n",
    "\n",
    "\n",
    "# increase the font size\n",
    "for ax in axes:\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(font_size)\n",
    "# # increase color bar font size\n",
    "# cbar = axes[1].collections[0].colorbar\n",
    "# cbar.ax.tick_params(labelsize=font_size)\n",
    "# cbar.set_label('Correlation', fontsize=font_size)\n",
    "\n",
    "\n",
    "# rotate the x labels\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "# rotate the y labels\n",
    "for ax in axes:\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "# make sure the figure saved is not cut off\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "plt.savefig(pjoin('dissertation', 'figures', 'conventional_ml_models_performance.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepPrime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Training DeepPrime\n",
    "'''\n",
    "from os.path import join as pjoin, basename\n",
    "\n",
    "from models.deepprime import DeepPrime, preprocess_deep_prime, train_deep_prime\n",
    "\n",
    "fname = pjoin('dp-pd-hek293t-pe2.csv')\n",
    "train_deep_prime(fname, hidden_size=128, num_features=24, num_layers=1, dropout=0.05, epochs=500, batch_size=1024, lr=0.005, patience=10, device='cuda', num_runs=5, adjustment='none')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Testing DeepPrime on the clinvar dataset\n",
    "'''\n",
    "from os.path import join as pjoin, basename\n",
    "\n",
    "from models.deepprime import DeepPrime, preprocess_deep_prime, train_deep_prime, predict_deep_prime\n",
    "\n",
    "data = 'dp-pd-hek293t-pe2.csv'\n",
    "predict_deep_prime(data, hidden_size=128, num_layers=1, dropout=0.05, num_features=24, adjustment='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test log and undersample adjustments on deep prime\n",
    "from models.deepprime import DeepPrime, preprocess_deep_prime, train_deep_prime, predict_deep_prime\n",
    "import pandas as pd\n",
    "\n",
    "datas = ['dp-dp-hek293t-pe2.csv', 'dp-pd-hek293t-pe2.csv', 'dp-pd-adv-pe2.csv', 'dp-pd-k562-pe2.csv', 'dp-pd-k562mlh1d-pe2.csv']\n",
    "\n",
    "for data in datas:        \n",
    "    print('Training Log')\n",
    "    deepprime_log = train_deep_prime(data, hidden_size=128, num_features=24, num_layers=1, dropout=0.05, epochs=500, batch_size=2048, lr=0.005, patience=20, device='cuda', adjustment='log')\n",
    "    \n",
    "    print('Training Undersample')\n",
    "    deepprime_undersample = train_deep_prime(data, hidden_size=128, num_features=24, num_layers=1, dropout=0.05, epochs=500, batch_size=2048, lr=0.005, patience=20, device='cuda', adjustment='undersample')\n",
    "    \n",
    "    print('Training Org')\n",
    "    deepprime_org = train_deep_prime(data, hidden_size=128, num_features=24, num_layers=1, dropout=0.05, epochs=500, batch_size=2048, lr=0.005, patience=20, device='cuda')\n",
    "        \n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test log and undersample adjustments on deep prime\n",
    "from models.deepprime import DeepPrime, preprocess_deep_prime, train_deep_prime, predict_deep_prime\n",
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "\n",
    "datas = ['dp-pd-hek293t-pe2.csv', 'dp-pd-adv-pe2.csv', 'dp-pd-k562-pe2.csv', 'dp-pd-k562mlh1d-pe2.csv', 'dp-dp-hek293t-pe2.csv']\n",
    "\n",
    "performance_pearson = {}\n",
    "performance_spearman = {}\n",
    "\n",
    "\n",
    "for data in datas:\n",
    "    print('-----------------------------------')\n",
    "    print('Log adjustment')\n",
    "    # log\n",
    "    deepprime_log_pred, deepprime_log_performance = predict_deep_prime(data, hidden_size=128, num_layers=1, dropout=0.05, num_features=24, adjustment='log')\n",
    "    \n",
    "    print('-----------------------------------')\n",
    "    print('Undersample adjustment')\n",
    "    # undersample\n",
    "    deepprime_undersample_pred, deepprime_undersample_performance = predict_deep_prime(data, hidden_size=128, num_layers=1, dropout=0.05, num_features=24, adjustment='undersample')\n",
    "    \n",
    "    print('-----------------------------------')\n",
    "    print('Original')\n",
    "    # original\n",
    "    deepprime_org_pred, deepprime_og_performance = predict_deep_prime(data, hidden_size=128, num_layers=1, dropout=0.05, num_features=24)\n",
    "    \n",
    "    # save the predictions\n",
    "    performance_pearson[data.split('.')[0]] = {\n",
    "        'orginal': [x[0] for x in deepprime_og_performance],\n",
    "        'log': [x[0] for x in deepprime_log_performance],\n",
    "        'undersample': [x[0] for x in deepprime_undersample_performance]\n",
    "    }\n",
    "    \n",
    "    performance_spearman[data.split('.')[0]] = {\n",
    "        'orginal': [x[1] for x in deepprime_og_performance],\n",
    "        'log': [x[1] for x in deepprime_log_performance],\n",
    "        'undersample': [x[1] for x in deepprime_undersample_performance]\n",
    "    }\n",
    "    \n",
    "# save the performance\n",
    "performance_pearson_df = pd.DataFrame(performance_pearson)\n",
    "performance_spearman_df = pd.DataFrame(performance_spearman)\n",
    "\n",
    "# invert the x and y axis\n",
    "performance_pearson_df = performance_pearson_df.T\n",
    "performance_spearman_df = performance_spearman_df.T\n",
    "\n",
    "performance_pearson_df.to_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-pearson.csv'))\n",
    "performance_spearman_df.to_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-spearman.csv'))\n",
    "\n",
    "print('Performance saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot both the pearson and spearman correlation performance\n",
    "# each figure contains the performance of the model on the different datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join as pjoin\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import scipy\n",
    "\n",
    "performance_pearson = pd.read_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-pearson.csv'), index_col=0)\n",
    "performance_spearman = pd.read_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-spearman.csv'), index_col=0)\n",
    "f_size = 14\n",
    "\n",
    "adjustment_shorthands = {\n",
    "    'weighted-mse': '   WMSE',\n",
    "    'quantile-transform': '     QT',\n",
    "    'original': '     OG',\n",
    "    'log': '     LA',\n",
    "    'undersample': '     US'\n",
    "}\n",
    "\n",
    "# convert all list strings to list\n",
    "import ast\n",
    "\n",
    "performance_pearson = performance_pearson.map(lambda x: ast.literal_eval(x))\n",
    "performance_spearman = performance_spearman.map(lambda x: ast.literal_eval(x))\n",
    "\n",
    "for i, data in enumerate(['dp-dp-hek293t-pe2', 'dp-pd-hek293t-pe2', 'dp-pd-k562-pe2', 'dp-pd-k562mlh1d-pe2', 'dp-pd-adv-pe2']):\n",
    "    # plot the performance of the model on the different datasets\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 1.8), width_ratios=(1.2, 1))\n",
    "    cell_data_pearson = performance_pearson.loc[data]\n",
    "    # into a dataframe of two columns, adjustment and performance\n",
    "    cell_data_pearson = pd.DataFrame(np.array(cell_data_pearson.tolist()).T, columns=['original', 'log', 'undersample'])\n",
    "    \n",
    "    cell_data_spearman = performance_spearman.loc[data]\n",
    "    cell_data_spearman = pd.DataFrame(np.array(cell_data_spearman.tolist()).T, columns=['original', 'log', 'undersample'])\n",
    "    \n",
    "    for ind, performance in enumerate([performance_pearson, performance_spearman]):\n",
    "        # plot the mean of each adjustment as barplot\n",
    "        # plot stripplot of the performance of each fold on top\n",
    "        # of the barplot\n",
    "        cell_data = cell_data_pearson if ind == 0 else cell_data_spearman\n",
    "        sns.barplot(data=cell_data, ax=ax[ind], palette=iter(sns.color_palette('icefire', 3)),alpha=0.5, orient='h', errorbar=None)\n",
    "        sns.stripplot(data=cell_data, ax=ax[ind], palette=iter(sns.color_palette('icefire', 3)), size=5, jitter=True, orient='h')\n",
    "        # ax[ind].set_title('Pearson' if ind == 0 else 'Spearman')\n",
    "        metric = 'Pearson' if ind == 0 else 'Spearman'\n",
    "        ax[ind].set_xlabel(f'{metric}', fontsize=f_size)\n",
    "        # ax[ind].set_ylabel('Adjustment')\n",
    "        \n",
    "        # fix y axis to 0 to 1\n",
    "        ax[ind].set_xlim(0, 1)\n",
    "        \n",
    "        # remove top and right spines\n",
    "        ax[ind].spines['top'].set_visible(False)\n",
    "        if ind == 0:\n",
    "            ax[ind].spines['left'].set_visible(False)\n",
    "        else:\n",
    "            ax[ind].spines['right'].set_visible(False)\n",
    "            \n",
    "        # test the significance between each adjustment with the original\n",
    "        # using the paired t-test\n",
    "        original = cell_data['original']\n",
    "        for adj in cell_data.columns:\n",
    "            if adj != 'original':\n",
    "                if np.mean(cell_data[adj]) < np.mean(cell_data['original']):\n",
    "                    t_stat, p_val = scipy.stats.ttest_rel(cell_data[adj], original)\n",
    "                    if p_val < 0.05:\n",
    "                        print(f'{data} {metric} {adjustment_shorthands[adj]}: {p_val}')\n",
    "    \n",
    "    ax[0].set_yticks(range(len(cell_data.columns)))\n",
    "    ax[0].set_yticklabels([adjustment_shorthands[adj] for adj in cell_data.columns])\n",
    "    # ax 1 should have no y labels\n",
    "    ax[1].set_yticklabels([])\n",
    "    # flip the x axis of ax 0\n",
    "    ax[0].invert_xaxis()\n",
    "    # move the y axis of ax 0 to the right\n",
    "    ax[0].yaxis.tick_right()\n",
    "    \n",
    "    # change the font of x tick labels\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=f_size)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # save the figure\n",
    "    data_name = '-'.join(data.split('-')[1:3])\n",
    "    plt.savefig(pjoin('dissertation/figures', f'adjustment-deepprime-{data_name}-performance.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pridict import train_pridict\n",
    "\n",
    "train_pridict('pd-pd-hek293t-pe2.csv', lr=0.005, batch_size=2048, epochs=200, patience=20, num_runs=5, adjustment='none', num_features=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pridict import predict_pridict\n",
    "\n",
    "predict_pridict('pd-pd-hek293t-pe2.csv', num_features=24, device='cuda', adjustment='none')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
