{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import collections\n",
    "from utils.stats_utils import get_pearson_and_spearman_correlation\n",
    "from utils.data_utils import k_fold_cross_validation_split\n",
    "from models.conventional_ml_models import lasso_regression, ridge_regression, mlp, xgboost, random_forest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import skorch\n",
    "from models.conventional_ml_models import MLP\n",
    "import os\n",
    "\n",
    "datas = ['ml-dp-hek293t-pe2.csv', 'ml-pd-hek293t-pe2.csv', 'ml-pd-adv-pe2.csv', 'ml-pd-k562-pe2.csv', 'ml-pd-k562mlh1d-pe2.csv']\n",
    "\n",
    "performance = {}\n",
    "\n",
    "def undersample(features, target):\n",
    "    # sample 10% of the training data with editing efficiency of less than 10\n",
    "    indices = np.where(target < 10)[0]\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.choice(indices, int(len(indices) * 0.1), replace=False)\n",
    "    features = np.delete(features, indices, axis=0)\n",
    "    target = np.delete(target, indices, axis=0)\n",
    "    return features, target\n",
    "\n",
    "for data in datas:\n",
    "    dataset = pd.read_csv(pjoin('models', 'data', 'conventional-ml', data))\n",
    "    cell_line = '-'.join(data.split('-')[1:3]).split('.')[0]\n",
    "    data_source = '-'.join(data.split('-')[1:]).split('.')[0]\n",
    "\n",
    "    # 5 fold cross validation\n",
    "    fold = 5\n",
    "\n",
    "    features = dataset.iloc[:, :24].values\n",
    "    target = dataset.iloc[:, -2].values\n",
    "\n",
    "    # standardize the features\n",
    "    # scaler = StandardScaler()\n",
    "    # features = scaler.fit_transform(features)\n",
    "\n",
    "    correlations = collections.defaultdict(list)\n",
    "    \n",
    "    for i in range(0, fold):\n",
    "        print(f'Fold {i+1} of {fold}')\n",
    "        train_features = features[dataset['fold'] != i]\n",
    "        train_target = target[dataset['fold'] != i]\n",
    "        \n",
    "        # undersample the training data\n",
    "        train_features, train_target = undersample(train_features, train_target)\n",
    "        \n",
    "        # ============================\n",
    "        # Lasso\n",
    "        # ============================\n",
    "        print('Training Lasso')\n",
    "        lasso_model = lasso_regression(train_features, train_target)\n",
    "        lasso_model.fit(train_features, train_target)\n",
    "        # pickle the model\n",
    "        pickle.dump(lasso_model, open(pjoin('models', 'trained-models', 'conventional-ml', f'lasso-{data_source}-fold-{i+1}.pkl'), 'wb'))\n",
    "\n",
    "        # ============================\n",
    "        # Ridge\n",
    "        # ============================\n",
    "        print('Training Ridge')\n",
    "        ridge_model = ridge_regression(train_features, train_target)\n",
    "        ridge_model.fit(train_features, train_target)\n",
    "        # pickle the model\n",
    "        pickle.dump(ridge_model, open(pjoin('models', 'trained-models', 'conventional-ml', f'ridge-{data_source}-fold-{i+1}.pkl'), 'wb'))\n",
    "\n",
    "        # ============================\n",
    "        # xgboost\n",
    "        # ============================\n",
    "        print('Training XGBoost')\n",
    "        xgboost_model = xgboost(train_features, train_target)\n",
    "        xgboost_model.fit(train_features, train_target)\n",
    "        # pickle the model\n",
    "        pickle.dump(xgboost_model, open(pjoin('models', 'trained-models', 'conventional-ml', f'xgboost-{data_source}-fold-{i+1}.pkl'), 'wb'))\n",
    "\n",
    "        # ============================\n",
    "        # random forest\n",
    "        # ============================\n",
    "        print('Training Random Forest')\n",
    "        rf_model = random_forest(train_features, train_target)\n",
    "        rf_model.fit(train_features, train_target)\n",
    "        # pickle the model\n",
    "        pickle.dump(rf_model, open(pjoin('models', 'trained-models', 'conventional-ml', f'random_forest-{data_source}-fold-{i+1}.pkl'), 'wb'))\n",
    "        \n",
    "        # ============================\n",
    "        # MLP\n",
    "        # ============================\n",
    "        \n",
    "        print('Training MLP')\n",
    "        mlp_model = skorch.NeuralNetRegressor(\n",
    "            module=MLP,\n",
    "            criterion=torch.nn.MSELoss,\n",
    "            optimizer=torch.optim.Adam,\n",
    "            max_epochs=200,\n",
    "            module__activation='relu',\n",
    "            lr=0.005,\n",
    "            device='cuda',\n",
    "            batch_size=2048,\n",
    "            train_split=skorch.dataset.ValidSplit(cv=5),\n",
    "            module__hidden_layer_sizes = (64, 64,),\n",
    "            # early stopping\n",
    "            callbacks=[\n",
    "                skorch.callbacks.EarlyStopping(patience=30),\n",
    "                skorch.callbacks.Checkpoint(monitor='valid_loss_best', f_pickle=None, f_criterion=None, f_optimizer=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}-optimizer.pkl'), f_history=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}-history.json'), f_params=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}.pkl'), event_name='event_cp'),\n",
    "                skorch.callbacks.LRScheduler(policy=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts, monitor='valid_loss', T_0=20, T_mult=1),\n",
    "            ]\n",
    "        )\n",
    "        # convert features and target to float32\n",
    "        train_features = train_features.astype(np.float32)\n",
    "        train_target = train_target.astype(np.float32)\n",
    "        # add a dimension to the target\n",
    "        train_target = train_target[:, np.newaxis]\n",
    "        mlp_model.fit(train_features, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickled models and evaluate on the corresponding validation set\n",
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import collections\n",
    "from utils.stats_utils import get_pearson_and_spearman_correlation\n",
    "from utils.data_utils import k_fold_cross_validation_split\n",
    "from models.conventional_ml_models import lasso_regression, ridge_regression, mlp, xgboost, random_forest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy\n",
    "import pickle\n",
    "import torch\n",
    "import skorch\n",
    "\n",
    "datas = ['ml-dp-hek293t-pe2.csv', 'ml-pd-hek293t-pe2.csv', 'ml-pd-adv-pe2.csv', 'ml-pd-k562-pe2.csv', 'ml-pd-k562mlh1d-pe2.csv']\n",
    "\n",
    "performance = {}\n",
    "\n",
    "for data in datas:\n",
    "    dataset = pd.read_csv(pjoin('models', 'data', 'conventional-ml', data))\n",
    "    cell_line = '-'.join(data.split('-')[1:3]).split('.')[0]\n",
    "    \n",
    "    data_source = '-'.join(data.split('-')[1:]).split('.')[0]\n",
    "\n",
    "    # 5 fold cross validation\n",
    "    fold = 5\n",
    "\n",
    "    features = dataset.iloc[:, :24].values\n",
    "    target = dataset.iloc[:, -2].values\n",
    "\n",
    "    correlations = collections.defaultdict(list)\n",
    "    \n",
    "    for i in range(0, fold):\n",
    "        X_test = features[dataset['fold'] == i]\n",
    "        y_test = target[dataset['fold'] == i]\n",
    "        print(f'Fold {i+1} of {fold}')\n",
    "\n",
    "        # ============================\n",
    "        # Lasso\n",
    "        # ============================\n",
    "        lasso_model = pickle.load(open(pjoin('models', 'trained-models', 'conventional-ml', f'lasso-{data_source}-fold-{i+1}.pkl'), 'rb'))\n",
    "        lasso_pred = lasso_model.predict(X_test)\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, lasso_pred)\n",
    "        correlations['Lasso'].append((pearson, spearman))\n",
    "        print(f'Lasso: Pearson: {pearson}, Spearman: {spearman}')\n",
    "\n",
    "        # ============================\n",
    "        # Ridge\n",
    "        # ============================\n",
    "        ridge_model = pickle.load(open(pjoin('models', 'trained-models', 'conventional-ml', f'ridge-{data_source}-fold-{i+1}.pkl'), 'rb'))\n",
    "        ridge_pred = ridge_model.predict(X_test)\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, ridge_pred)\n",
    "        correlations['Ridge'].append((pearson, spearman))\n",
    "        print(f'Ridge: Pearson: {pearson}, Spearman: {spearman}')\n",
    "        \n",
    "        # ============================\n",
    "        # xgboost\n",
    "        # ============================\n",
    "        xgboost_model = pickle.load(open(pjoin('models', 'trained-models', 'conventional-ml', f'xgboost-{data_source}-fold-{i+1}.pkl'), 'rb'))\n",
    "        xgboost_pred = xgboost_model.predict(X_test)\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, xgboost_pred)\n",
    "        correlations['XGBoost'].append((pearson, spearman))\n",
    "        print(f'XGBoost: Pearson: {pearson}, Spearman: {spearman}')\n",
    "        \n",
    "        # ============================\n",
    "        # random forest\n",
    "        # ============================\n",
    "        rf_model = pickle.load(open(pjoin('models', 'trained-models', 'conventional-ml', f'random_forest-{data_source}-fold-{i+1}.pkl'), 'rb'))\n",
    "        rf_pred = rf_model.predict(X_test)\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, rf_pred)\n",
    "        correlations['RF'].append((pearson, spearman))\n",
    "        print(f'Random Forest: Pearson: {pearson}, Spearman: {spearman}')\n",
    "        \n",
    "        # ============================\n",
    "        # MLP\n",
    "        # ============================\n",
    "        # load the pickled model\n",
    "        mlp_model = skorch.NeuralNetRegressor(\n",
    "            module=MLP,\n",
    "            criterion=torch.nn.MSELoss,\n",
    "            optimizer=torch.optim.Adam,\n",
    "            max_epochs=200,\n",
    "            module__activation='relu',\n",
    "            lr=0.001,\n",
    "            device='cuda',\n",
    "            batch_size=2048,\n",
    "            module__hidden_layer_sizes = (64, 64,),\n",
    "        )\n",
    "        mlp_model.initialize()\n",
    "        mlp_model.load_params(\n",
    "            f_optimizer=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}-optimizer.pkl'), \n",
    "            f_history=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}-history.json'), \n",
    "            f_params=os.path.join('models', 'trained-models', 'conventional-ml', f'mlp-{data_source}-fold-{i+1}.pkl')\n",
    "        )\n",
    "        X_test = X_test.astype(np.float32)\n",
    "        X_test = torch.tensor(X_test)\n",
    "        mlp_pred = mlp_model.predict(X_test)\n",
    "        # flatten the prediction\n",
    "        mlp_pred = mlp_pred.flatten()\n",
    "        pearson, spearman = get_pearson_and_spearman_correlation(y_test, mlp_pred)\n",
    "        correlations['MLP'].append((pearson, spearman))\n",
    "        print(f'MLP: Pearson: {pearson}, Spearman: {spearman}')\n",
    "        \n",
    "        print('-----------------------------------')\n",
    "    \n",
    "    print(correlations)\n",
    "    performance[cell_line] = correlations\n",
    "\n",
    "# save the performance\n",
    "save_file = pjoin('models', 'data', 'performance', 'conventional-ml-performance.csv')\n",
    "performance_df = pd.DataFrame(performance)\n",
    "print(performance_df)\n",
    "performance_df.to_csv(save_file)\n",
    "print(f'Performance saved to {save_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the performance in two heat maps, one for pearson and one for spearman\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "from os.path import join as pjoin\n",
    "\n",
    "# cell line vs model\n",
    "performance_data = pjoin('models', 'data', 'performance', 'conventional-ml-performance.csv')\n",
    "df = pd.read_csv(performance_data, index_col=0)\n",
    "\n",
    "cell_lines = df.columns\n",
    "models = df.index\n",
    "\n",
    "# plot the mean of the pearson and spearman correlation\n",
    "pearson = np.zeros((len(models), len(cell_lines)))\n",
    "spearman = np.zeros((len(models), len(cell_lines)))\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    for j, cell_line in enumerate(cell_lines):\n",
    "        performance = df.loc[model, cell_line]\n",
    "        # string to list\n",
    "        performance = ast.literal_eval(performance)\n",
    "        pearson[i, j] = np.mean([x[0] for x in performance])\n",
    "        spearman[i, j] = np.mean([x[1] for x in performance])\n",
    "\n",
    "font_size = 18\n",
    "\n",
    "# pearson and spearman correlation share the same color bar\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7), width_ratios=[1, 1])\n",
    "sns.heatmap(pearson, ax=axes[0], annot=True, xticklabels=cell_lines, yticklabels=models, cmap='icefire', cbar=False, vmin=0, vmax=1, annot_kws={'size': font_size})\n",
    "axes[0].set_title('Pearson')\n",
    "sns.heatmap(spearman, ax=axes[1], annot=True, xticklabels=cell_lines, yticklabels=models, cmap='icefire', cbar=False, vmin=0, vmax=1, annot_kws={'size': font_size})\n",
    "axes[1].set_title('Spearman')\n",
    "\n",
    "\n",
    "# increase the font size\n",
    "for ax in axes:\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] + ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(font_size)\n",
    "# # increase color bar font size\n",
    "# cbar = axes[1].collections[0].colorbar\n",
    "# cbar.ax.tick_params(labelsize=font_size)\n",
    "# cbar.set_label('Correlation', fontsize=font_size)\n",
    "\n",
    "\n",
    "# rotate the x labels\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment='right')\n",
    "# rotate the y labels\n",
    "for ax in axes:\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0, horizontalalignment='right')\n",
    "# make sure the figure saved is not cut off\n",
    "plt.tight_layout()\n",
    "\n",
    "# save the figure\n",
    "plt.savefig(pjoin('dissertation', 'figures', 'conventional_ml_models_performance.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepPrime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['wt-sequence', 'mut-sequence', 'pbs-length', 'rt-length',\n",
      "       'extension-length', 'edit-length', 'rha-length', 'edit-position',\n",
      "       'edit-type-replacement', 'edit-type-insertion', 'edit-type-deletion',\n",
      "       'pbs-melting-temperature', 'rtt-wt-cdna-melting-temperature',\n",
      "       'rtt-wt-cdna-new-melting-temperature', 'rtt-cdna-melting-temperature',\n",
      "       'rtt-melting-temperature', 'delta-melting-temperature',\n",
      "       'pbs-gc-content', 'rtt-gc-content', 'extension-gc-content',\n",
      "       'pbs-gc-count', 'rtt-gc-count', 'extension-gc-count',\n",
      "       'extension-minimum-free-energy', 'spacer-minimum-free-energy',\n",
      "       'spcas9-score', 'group-id', 'editing-efficiency', 'fold'],\n",
      "      dtype='object')\n",
      "Fold 1 of 5\n",
      "Training DeepPrime model...\n",
      "Run 1 of 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa096e9dd4324857a6eeb9e3b04b4814",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr      dur\n",
      "-------  ------------  ------------  ----  ------  -------\n",
      "      1       \u001b[36m10.2833\u001b[0m        \u001b[32m9.5234\u001b[0m     +  0.0050  52.2750\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e79095859694b739c127268cc04f518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m9.1031\u001b[0m       10.1530        0.0049  53.7234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f376d52a4cf149c69ef0a073e5c8b5d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "Training DeepPrime\n",
    "'''\n",
    "from os.path import join as pjoin, basename\n",
    "\n",
    "from models.deepprime import DeepPrime, preprocess_deep_prime, train_deep_prime\n",
    "\n",
    "fname = pjoin('dp-dp-hek293t-pe2.csv')\n",
    "train_deep_prime(fname, hidden_size=128, num_features=24, num_layers=1, dropout=0.05, epochs=500, batch_size=1024, lr=0.005, patience=10, device='cuda', num_runs=5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Testing DeepPrime on the clinvar dataset\n",
    "'''\n",
    "from os.path import join as pjoin, basename\n",
    "\n",
    "from models.deepprime import DeepPrime, preprocess_deep_prime, train_deep_prime, predict_deep_prime\n",
    "\n",
    "data = 'dp-pd-hek293t-pe2.csv'\n",
    "predict_deep_prime(data, hidden_size=128, num_layers=1, dropout=0.05, num_features=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test log and undersample adjustments on deep prime\n",
    "from models.deepprime import DeepPrime, preprocess_deep_prime, train_deep_prime, predict_deep_prime\n",
    "import pandas as pd\n",
    "\n",
    "datas = ['dp-dp-hek293t-pe2.csv', 'dp-pd-hek293t-pe2.csv', 'dp-pd-adv-pe2.csv', 'dp-pd-k562-pe2.csv', 'dp-pd-k562mlh1d-pe2.csv']\n",
    "\n",
    "for data in datas:        \n",
    "    print('Training Log')\n",
    "    deepprime_log = train_deep_prime(data, hidden_size=128, num_features=24, num_layers=1, dropout=0.05, epochs=500, batch_size=2048, lr=0.005, patience=20, device='cuda', adjustment='log')\n",
    "    \n",
    "    print('Training Undersample')\n",
    "    deepprime_undersample = train_deep_prime(data, hidden_size=128, num_features=24, num_layers=1, dropout=0.05, epochs=500, batch_size=2048, lr=0.005, patience=20, device='cuda', adjustment='undersample')\n",
    "    \n",
    "    print('Training Org')\n",
    "    deepprime_org = train_deep_prime(data, hidden_size=128, num_features=24, num_layers=1, dropout=0.05, epochs=500, batch_size=2048, lr=0.005, patience=20, device='cuda')\n",
    "        \n",
    "    print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test log and undersample adjustments on deep prime\n",
    "from models.deepprime import DeepPrime, preprocess_deep_prime, train_deep_prime, predict_deep_prime\n",
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "\n",
    "datas = ['dp-pd-hek293t-pe2.csv', 'dp-pd-adv-pe2.csv', 'dp-pd-k562-pe2.csv', 'dp-pd-k562mlh1d-pe2.csv', 'dp-dp-hek293t-pe2.csv']\n",
    "\n",
    "performance_pearson = {}\n",
    "performance_spearman = {}\n",
    "\n",
    "\n",
    "for data in datas:\n",
    "    print('-----------------------------------')\n",
    "    print('Log adjustment')\n",
    "    # log\n",
    "    deepprime_log_pred, deepprime_log_performance = predict_deep_prime(data, hidden_size=128, num_layers=1, dropout=0.05, num_features=24, adjustment='log')\n",
    "    \n",
    "    print('-----------------------------------')\n",
    "    print('Undersample adjustment')\n",
    "    # undersample\n",
    "    deepprime_undersample_pred, deepprime_undersample_performance = predict_deep_prime(data, hidden_size=128, num_layers=1, dropout=0.05, num_features=24, adjustment='undersample')\n",
    "    \n",
    "    print('-----------------------------------')\n",
    "    print('Original')\n",
    "    # original\n",
    "    deepprime_org_pred, deepprime_og_performance = predict_deep_prime(data, hidden_size=128, num_layers=1, dropout=0.05, num_features=24)\n",
    "    \n",
    "    # save the predictions\n",
    "    performance_pearson[data.split('.')[0]] = {\n",
    "        'orginal': [x[0] for x in deepprime_og_performance],\n",
    "        'log': [x[0] for x in deepprime_log_performance],\n",
    "        'undersample': [x[0] for x in deepprime_undersample_performance]\n",
    "    }\n",
    "    \n",
    "    performance_spearman[data.split('.')[0]] = {\n",
    "        'orginal': [x[1] for x in deepprime_og_performance],\n",
    "        'log': [x[1] for x in deepprime_log_performance],\n",
    "        'undersample': [x[1] for x in deepprime_undersample_performance]\n",
    "    }\n",
    "    \n",
    "# save the performance\n",
    "performance_pearson_df = pd.DataFrame(performance_pearson)\n",
    "performance_spearman_df = pd.DataFrame(performance_spearman)\n",
    "\n",
    "# invert the x and y axis\n",
    "performance_pearson_df = performance_pearson_df.T\n",
    "performance_spearman_df = performance_spearman_df.T\n",
    "\n",
    "performance_pearson_df.to_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-pearson.csv'))\n",
    "performance_spearman_df.to_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-spearman.csv'))\n",
    "\n",
    "print('Performance saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot both the pearson and spearman correlation performance\n",
    "# each figure contains the performance of the model on the different datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import join as pjoin\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import scipy\n",
    "\n",
    "performance_pearson = pd.read_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-pearson.csv'), index_col=0)\n",
    "performance_spearman = pd.read_csv(pjoin('models', 'data', 'performance', 'deep-prime-performance-spearman.csv'), index_col=0)\n",
    "f_size = 14\n",
    "\n",
    "adjustment_shorthands = {\n",
    "    'weighted-mse': '   WMSE',\n",
    "    'quantile-transform': '     QT',\n",
    "    'original': '     OG',\n",
    "    'log': '     LA',\n",
    "    'undersample': '     US'\n",
    "}\n",
    "\n",
    "# convert all list strings to list\n",
    "import ast\n",
    "\n",
    "performance_pearson = performance_pearson.map(lambda x: ast.literal_eval(x))\n",
    "performance_spearman = performance_spearman.map(lambda x: ast.literal_eval(x))\n",
    "\n",
    "for i, data in enumerate(['dp-dp-hek293t-pe2', 'dp-pd-hek293t-pe2', 'dp-pd-k562-pe2', 'dp-pd-k562mlh1d-pe2', 'dp-pd-adv-pe2']):\n",
    "    # plot the performance of the model on the different datasets\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 1.8), width_ratios=(1.2, 1))\n",
    "    cell_data_pearson = performance_pearson.loc[data]\n",
    "    # into a dataframe of two columns, adjustment and performance\n",
    "    cell_data_pearson = pd.DataFrame(np.array(cell_data_pearson.tolist()).T, columns=['original', 'log', 'undersample'])\n",
    "    \n",
    "    cell_data_spearman = performance_spearman.loc[data]\n",
    "    cell_data_spearman = pd.DataFrame(np.array(cell_data_spearman.tolist()).T, columns=['original', 'log', 'undersample'])\n",
    "    \n",
    "    for ind, performance in enumerate([performance_pearson, performance_spearman]):\n",
    "        # plot the mean of each adjustment as barplot\n",
    "        # plot stripplot of the performance of each fold on top\n",
    "        # of the barplot\n",
    "        cell_data = cell_data_pearson if ind == 0 else cell_data_spearman\n",
    "        sns.barplot(data=cell_data, ax=ax[ind], palette=iter(sns.color_palette('icefire', 3)),alpha=0.5, orient='h', errorbar=None)\n",
    "        sns.stripplot(data=cell_data, ax=ax[ind], palette=iter(sns.color_palette('icefire', 3)), size=5, jitter=True, orient='h')\n",
    "        # ax[ind].set_title('Pearson' if ind == 0 else 'Spearman')\n",
    "        metric = 'Pearson' if ind == 0 else 'Spearman'\n",
    "        ax[ind].set_xlabel(f'{metric}', fontsize=f_size)\n",
    "        # ax[ind].set_ylabel('Adjustment')\n",
    "        \n",
    "        # fix y axis to 0 to 1\n",
    "        ax[ind].set_xlim(0, 1)\n",
    "        \n",
    "        # remove top and right spines\n",
    "        ax[ind].spines['top'].set_visible(False)\n",
    "        if ind == 0:\n",
    "            ax[ind].spines['left'].set_visible(False)\n",
    "        else:\n",
    "            ax[ind].spines['right'].set_visible(False)\n",
    "            \n",
    "        # test the significance between each adjustment with the original\n",
    "        # using the paired t-test\n",
    "        original = cell_data['original']\n",
    "        for adj in cell_data.columns:\n",
    "            if adj != 'original':\n",
    "                if np.mean(cell_data[adj]) < np.mean(cell_data['original']):\n",
    "                    t_stat, p_val = scipy.stats.ttest_rel(cell_data[adj], original)\n",
    "                    if p_val < 0.05:\n",
    "                        print(f'{data} {metric} {adjustment_shorthands[adj]}: {p_val}')\n",
    "    \n",
    "    ax[0].set_yticks(range(len(cell_data.columns)))\n",
    "    ax[0].set_yticklabels([adjustment_shorthands[adj] for adj in cell_data.columns])\n",
    "    # ax 1 should have no y labels\n",
    "    ax[1].set_yticklabels([])\n",
    "    # flip the x axis of ax 0\n",
    "    ax[0].invert_xaxis()\n",
    "    # move the y axis of ax 0 to the right\n",
    "    ax[0].yaxis.tick_right()\n",
    "    \n",
    "    # change the font of x tick labels\n",
    "    ax[0].tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax[1].tick_params(axis='both', which='major', labelsize=f_size)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # save the figure\n",
    "    data_name = '-'.join(data.split('-')[1:3])\n",
    "    plt.savefig(pjoin('dissertation/figures', f'adjustment-deepprime-{data_name}-performance.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRIDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 of 5\n",
      "Training DeepPrime model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315ce55eea994390bf3e5190d5e0d9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr      dur\n",
      "-------  ------------  ------------  ----  ------  -------\n",
      "      1        \u001b[36m1.5152\u001b[0m        \u001b[32m1.7020\u001b[0m     +  0.0050  15.9691\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c83ff96fea34118bea2c9d3673af07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m1.2415\u001b[0m        \u001b[32m1.5950\u001b[0m     +  0.0049  14.8409\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd93bd951e6e48bdb04698afaeb0b06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3        \u001b[36m1.2102\u001b[0m        \u001b[32m1.5031\u001b[0m     +  0.0048  15.1875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f536476d864c28bb600073233dd834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4        \u001b[36m1.1499\u001b[0m        1.5244        0.0045  14.4737\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20776ceb2934efc9124af4851b19acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5        \u001b[36m1.1276\u001b[0m        1.6138        0.0042  15.4438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f75b66e8dc044979f29652918195728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6        \u001b[36m1.0797\u001b[0m        1.5978        0.0037  14.2313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a12c96a4074eea9e65bb62a429c8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7        \u001b[36m1.0340\u001b[0m        1.5609        0.0033  13.9099\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5658f62ea5a34b12956f0f549d5f2d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8        \u001b[36m0.9980\u001b[0m        \u001b[32m1.4730\u001b[0m     +  0.0028  14.3386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9488c32c2d34759833d19c6fbe49355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/147 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing the preprocessing of the clinvar dataset\n",
    "from models.pridict import train_pridict\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train_pridict('pd-pd-hek293t-pe2.csv', lr=0.005, batch_size=124, epochs=500, patience=10, num_runs=5, adjustment='log', num_features=24)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
