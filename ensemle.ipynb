{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Mean Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_weighted_mean import EnsembleWeightedMean\n",
    "\n",
    "ensemble_direct_optimization = EnsembleWeightedMean(optimization=True)\n",
    "ensemble_direct_optimization_with_features = EnsembleWeightedMean(optimization=True, with_features=True)\n",
    "ensemble_weigthed_mean = EnsembleWeightedMean(optimization=False)\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "ensemble_direct_optimization.fit(data)\n",
    "direct_optimization_performance = ensemble_direct_optimization.test(data) \n",
    "\n",
    "ensemble_weigthed_mean.fit(data)\n",
    "weighted_mean_performance = ensemble_weigthed_mean.test(data)\n",
    "\n",
    "ensemble_direct_optimization_with_features.fit(data)\n",
    "with_features_performance = ensemble_direct_optimization_with_features.test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "\n",
    "direct_op_pearson, direct_op_spearman = direct_optimization_performance\n",
    "performance_weighted_pearson, performance_weighted_spearman = weighted_mean_performance\n",
    "performance_with_features_pearson, performance_with_features_spearman = with_features_performance\n",
    "\n",
    "# join the performance values, ignore the common keys\n",
    "direct_op_pearson.update(performance_weighted_pearson)\n",
    "direct_op_spearman.update(performance_weighted_spearman)\n",
    "\n",
    "direct_op_pearson.update(performance_with_features_pearson)\n",
    "direct_op_spearman.update(performance_with_features_spearman)\n",
    "\n",
    "performance_pearson = direct_op_pearson\n",
    "performance_spearman = direct_op_spearman\n",
    "\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "# plot the bar plot on top of the strip plot\n",
    "# bar plot should be shortened to emphasize the difference in values\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [performance_pearson, performance_spearman]):\n",
    "    # performance = pd.DataFrame({'Models': list(performance.keys()), 'Performance': list(performance.values()), 'Category': [0 if 'op' in model or 'pwm' in model else 1 for model in performance.keys()]})\n",
    "    # print(performance)\n",
    "    # add a category column\n",
    "    print(name)\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=3))\n",
    "    colours = ['gray' if not ('opt' in model or 'pwm' in model) else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Ensemble', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for 'opt', 'pwm' models of matching color\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'opt' in model or 'pwm' in model:\n",
    "            ax.axhline(y=performance[model], color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    plt.show()\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'opt' in model or 'pwm' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if not ('opt' in model or 'pwm' in model)}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')\n",
    "                \n",
    "    # save the figure\n",
    "    fig.savefig(pjoin('dissertation', 'figures', f'ensemble_{name.lower()}.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n",
      "Training rf\n"
     ]
    }
   ],
   "source": [
    "# train performance weighted mean ensemble with features\n",
    "from models.ensemble_weighted_mean import EnsembleWeightedMean\n",
    "\n",
    "# performance weighted mean ensemble\n",
    "ensemble_pwm = EnsembleWeightedMean(optimization=False, with_features=False)\n",
    "\n",
    "data = 'ensemble-dp-hek293t-pe2.csv'\n",
    "\n",
    "ensemble_pwm.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_bagging import EnsembleBagging\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "n_rounds = [1, 2, 3, 5, 10, 15]\n",
    "\n",
    "performances_pearson = {}\n",
    "performances_spearman = {}\n",
    "for i in n_rounds:\n",
    "    print(f'Bagging with {i} rounds')\n",
    "    ensemble_bagging = EnsembleBagging(n_rounds=i)\n",
    "    ensemble_bagging.fit(data)\n",
    "    performance_pearson, performance_spearman = ensemble_bagging.test(data)\n",
    "    performance_pearson[f'bag-{i}'] = performance_pearson.pop('bag')\n",
    "    performance_spearman[f'bag-{i}'] = performance_spearman.pop('bag')\n",
    "    performances_pearson.update(performance_pearson)\n",
    "    performances_spearman.update(performance_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [performances_pearson, performances_spearman]):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=len(n_rounds)))\n",
    "    colours = ['gray' if 'bag' not in model else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Model', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for adaboost model\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'bag' in model:\n",
    "            ax.axhline(y=np.mean(performance[model]), color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, horizontalalignment='right')\n",
    "    plt.show()\n",
    "\n",
    "    # save the figure\n",
    "    fig.savefig(pjoin('dissertation', 'figures', f'ensemble_bagging_{name.lower()}_round.png'), bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'bag' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if 'bag' not in model}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_bagging import EnsembleBagging\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "percentages = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "performances_pearson = {}\n",
    "performances_spearman = {}\n",
    "for i in percentages:\n",
    "    ensemble_bagging = EnsembleBagging(n_rounds=3, sample_percentage=i)\n",
    "    ensemble_bagging.fit(data)\n",
    "    performance_pearson, performance_spearman = ensemble_bagging.test(data)\n",
    "    performance_pearson[f'bag-{i}'] = performance_pearson.pop('bag')\n",
    "    performance_spearman[f'bag-{i}'] = performance_spearman.pop('bag')\n",
    "    performances_pearson.update(performance_pearson)\n",
    "    performances_spearman.update(performance_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [performances_pearson, performances_spearman]):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=len(percentages)))\n",
    "    colours = ['gray' if 'bag' not in model else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Model', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for adaboost model\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'bag' in model:\n",
    "            ax.axhline(y=np.mean(performance[model]), color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, horizontalalignment='right')\n",
    "    plt.show()\n",
    "\n",
    "    # save the figure\n",
    "    fig.savefig(pjoin('dissertation', 'figures', f'ensemble_{name.lower()}_bagging_percentage.pdf'), bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'bag' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if 'bag' not in model}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power: 1, Threshold: 0.05, Rounds: 1, Pearson: 0.8362684472728854, Spearman: 0.8618529173303514\n",
      "Power: 1, Threshold: 0.1, Rounds: 1, Pearson: 0.8360670814416642, Spearman: 0.8614859544750895\n",
      "Power: 1, Threshold: 0.2, Rounds: 1, Pearson: 0.8347947021759317, Spearman: 0.8610169140900504\n",
      "Power: 1, Threshold: 0.3, Rounds: 1, Pearson: 0.8369271022734002, Spearman: 0.862071598752438\n",
      "Power: 1, Threshold: 0.5, Rounds: 1, Pearson: 0.8393064682045722, Spearman: 0.8634157160382048\n",
      "Power: 1, Threshold: 0.7, Rounds: 1, Pearson: 0.8371736899899517, Spearman: 0.8624066932620561\n",
      "Power: 1, Threshold: 0.05, Rounds: 3, Pearson: 0.8296377485949542, Spearman: 0.8567639926328968\n",
      "Power: 1, Threshold: 0.1, Rounds: 3, Pearson: 0.835181385758919, Spearman: 0.8602522584804607\n",
      "Power: 1, Threshold: 0.2, Rounds: 3, Pearson: 0.8355581018442533, Spearman: 0.8600356652521848\n",
      "Power: 1, Threshold: 0.3, Rounds: 3, Pearson: 0.8373111795262218, Spearman: 0.863030095370604\n",
      "Power: 1, Threshold: 0.5, Rounds: 3, Pearson: 0.8293001364242338, Spearman: 0.8578566025083305\n",
      "Power: 1, Threshold: 0.7, Rounds: 3, Pearson: 0.7906490527310306, Spearman: 0.850835027397624\n",
      "Power: 1, Threshold: 0.05, Rounds: 5, Pearson: 0.833479664333372, Spearman: 0.8594437358654423\n",
      "Power: 1, Threshold: 0.1, Rounds: 5, Pearson: 0.8370115413395862, Spearman: 0.8618827275503864\n",
      "Power: 1, Threshold: 0.2, Rounds: 5, Pearson: 0.8378142908278099, Spearman: 0.862721123943169\n",
      "Power: 1, Threshold: 0.3, Rounds: 5, Pearson: 0.8380049592130223, Spearman: 0.8630274926618399\n",
      "Power: 1, Threshold: 0.5, Rounds: 5, Pearson: 0.8271580101206916, Spearman: 0.8557823142211011\n",
      "Power: 1, Threshold: 0.7, Rounds: 5, Pearson: 0.8081541363177458, Spearman: 0.8446707569068614\n",
      "Power: 1, Threshold: 0.05, Rounds: 10, Pearson: 0.8377462040741377, Spearman: 0.861518315426035\n",
      "Power: 1, Threshold: 0.1, Rounds: 10, Pearson: 0.8385486172887398, Spearman: 0.8628196500038711\n",
      "Power: 1, Threshold: 0.2, Rounds: 10, Pearson: 0.8377383047612055, Spearman: 0.8624779123298237\n",
      "Power: 1, Threshold: 0.3, Rounds: 10, Pearson: 0.8364770263527057, Spearman: 0.8600144124948627\n",
      "Power: 1, Threshold: 0.5, Rounds: 10, Pearson: 0.8270531705142207, Spearman: 0.8537847021498851\n",
      "Power: 1, Threshold: 0.7, Rounds: 10, Pearson: 0.7913981453339598, Spearman: 0.8340509190993921\n",
      "Power: 2, Threshold: 0.05, Rounds: 1, Pearson: 0.8331367061791977, Spearman: 0.8604446693743272\n",
      "Power: 2, Threshold: 0.1, Rounds: 1, Pearson: 0.835907429669029, Spearman: 0.8615598334930546\n",
      "Power: 2, Threshold: 0.2, Rounds: 1, Pearson: 0.8383061853875187, Spearman: 0.8634384572701811\n",
      "Power: 2, Threshold: 0.3, Rounds: 1, Pearson: 0.839556545144867, Spearman: 0.8640783093166049\n",
      "Power: 2, Threshold: 0.5, Rounds: 1, Pearson: 0.8384522641304467, Spearman: 0.8635258471744904\n",
      "Power: 2, Threshold: 0.7, Rounds: 1, Pearson: 0.8394301136608188, Spearman: 0.8620295843956107\n",
      "Power: 2, Threshold: 0.05, Rounds: 3, Pearson: 0.8384899237883889, Spearman: 0.8619997524633082\n",
      "Power: 2, Threshold: 0.1, Rounds: 3, Pearson: 0.8351260887554606, Spearman: 0.8602497225533692\n",
      "Power: 2, Threshold: 0.2, Rounds: 3, Pearson: 0.8378700959688063, Spearman: 0.8626832321538563\n",
      "Power: 2, Threshold: 0.3, Rounds: 3, Pearson: 0.8357332159615862, Spearman: 0.8602782376695233\n",
      "Power: 2, Threshold: 0.5, Rounds: 3, Pearson: 0.8289293022355528, Spearman: 0.8540659494456637\n",
      "Power: 2, Threshold: 0.7, Rounds: 3, Pearson: 0.8104514048310482, Spearman: 0.8419536353472409\n",
      "Power: 2, Threshold: 0.05, Rounds: 5, Pearson: 0.8352823258971369, Spearman: 0.8609356377682188\n",
      "Power: 2, Threshold: 0.1, Rounds: 5, Pearson: 0.8365872451516088, Spearman: 0.8616338504168183\n",
      "Power: 2, Threshold: 0.2, Rounds: 5, Pearson: 0.8388376431398936, Spearman: 0.8630029261518786\n",
      "Power: 2, Threshold: 0.3, Rounds: 5, Pearson: 0.8308106299557635, Spearman: 0.8562333645447304\n",
      "Power: 2, Threshold: 0.5, Rounds: 5, Pearson: 0.8260285834892929, Spearman: 0.8520011563937343\n",
      "Power: 2, Threshold: 0.7, Rounds: 5, Pearson: 0.7712491644407042, Spearman: 0.8220371121127827\n",
      "Power: 2, Threshold: 0.05, Rounds: 10, Pearson: 0.8304391606361785, Spearman: 0.8561283056573967\n",
      "Power: 2, Threshold: 0.1, Rounds: 10, Pearson: 0.8380750873969691, Spearman: 0.8621492998532895\n",
      "Power: 2, Threshold: 0.2, Rounds: 10, Pearson: 0.8360095442251252, Spearman: 0.8599120339540993\n",
      "Power: 2, Threshold: 0.3, Rounds: 10, Pearson: 0.8292202659907597, Spearman: 0.8546178923356027\n",
      "Power: 2, Threshold: 0.5, Rounds: 10, Pearson: 0.8238660879912972, Spearman: 0.8495597155649753\n",
      "Power: 2, Threshold: 0.7, Rounds: 10, Pearson: 0.7888153465342139, Spearman: 0.8324461193252513\n",
      "Power: 3, Threshold: 0.05, Rounds: 1, Pearson: 0.8323696220444288, Spearman: 0.8598306572294776\n",
      "Power: 3, Threshold: 0.1, Rounds: 1, Pearson: 0.8382897371727045, Spearman: 0.8634279580727737\n",
      "Power: 3, Threshold: 0.2, Rounds: 1, Pearson: 0.8373005604074134, Spearman: 0.8626300749295719\n",
      "Power: 3, Threshold: 0.3, Rounds: 1, Pearson: 0.8379456732491223, Spearman: 0.8631410828255753\n",
      "Power: 3, Threshold: 0.5, Rounds: 1, Pearson: 0.8391014085874076, Spearman: 0.8643010859355897\n",
      "Power: 3, Threshold: 0.7, Rounds: 1, Pearson: 0.8407016213535644, Spearman: 0.8616377313860066\n",
      "Power: 3, Threshold: 0.05, Rounds: 3, Pearson: 0.8375948907580907, Spearman: 0.8623473229078354\n",
      "Power: 3, Threshold: 0.1, Rounds: 3, Pearson: 0.8368579354770928, Spearman: 0.8613387057563275\n",
      "Power: 3, Threshold: 0.2, Rounds: 3, Pearson: 0.8375793222362742, Spearman: 0.8623066706997403\n",
      "Power: 3, Threshold: 0.3, Rounds: 3, Pearson: 0.8337119734820639, Spearman: 0.8580372862115552\n",
      "Power: 3, Threshold: 0.5, Rounds: 3, Pearson: 0.8236465959122817, Spearman: 0.8540814268055289\n",
      "Power: 3, Threshold: 0.7, Rounds: 3, Pearson: 0.7804124273569549, Spearman: 0.8273258090182416\n",
      "Power: 3, Threshold: 0.05, Rounds: 5, Pearson: 0.8377486700878567, Spearman: 0.8615267603139285\n",
      "Power: 3, Threshold: 0.1, Rounds: 5, Pearson: 0.8380110644478849, Spearman: 0.8628578326717784\n",
      "Power: 3, Threshold: 0.2, Rounds: 5, Pearson: 0.8305399312042008, Spearman: 0.8568245895328673\n",
      "Power: 3, Threshold: 0.3, Rounds: 5, Pearson: 0.8312251867725788, Spearman: 0.8572807082893531\n",
      "Power: 3, Threshold: 0.5, Rounds: 5, Pearson: 0.816205391489214, Spearman: 0.8474560770288161\n",
      "Power: 3, Threshold: 0.7, Rounds: 5, Pearson: 0.786144233037729, Spearman: 0.8288141579386638\n",
      "Power: 3, Threshold: 0.05, Rounds: 10, Pearson: 0.8396980294735792, Spearman: 0.8624711488925892\n",
      "Power: 3, Threshold: 0.1, Rounds: 10, Pearson: 0.8398366466232412, Spearman: 0.8637589521877084\n",
      "Power: 3, Threshold: 0.2, Rounds: 10, Pearson: 0.8326991277761862, Spearman: 0.8589246714679611\n",
      "Power: 3, Threshold: 0.3, Rounds: 10, Pearson: 0.8289404790348779, Spearman: 0.8548833234285481\n",
      "Power: 3, Threshold: 0.5, Rounds: 10, Pearson: 0.8154599225267752, Spearman: 0.8440367150633179\n",
      "Power: 3, Threshold: 0.7, Rounds: 10, Pearson: 0.7634543959545924, Spearman: 0.816400030289573\n"
     ]
    }
   ],
   "source": [
    "# tune adaboost models\n",
    "from models.ensemble_adaboost import EnsembleAdaBoost\n",
    "# disable warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "ensemble_adaboost = EnsembleAdaBoost()\n",
    "params = ensemble_adaboost.tune(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "\n",
    "# convert params grid to dictionary\n",
    "params = pd.DataFrame(params)\n",
    "\n",
    "# save the parameters to a file\n",
    "params.to_csv(pjoin('models', 'data', 'performance', 'ensemble_adaboost_params.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 xgb\n",
      "[0.23073747 0.23073747 0.23073747 ... 0.23073747 1.73895825 0.23073747]\n",
      "Round 1 mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27196443 0.08620591 0.08620591 ... 0.08620591 2.04966614 0.08620591]\n",
      "Round 1 ridge\n",
      "[0.16396746 0.09010845 0.05197357 ... 0.09010845 2.14245452 0.05197357]\n",
      "Round 1 rf\n",
      "[0.02836673 0.01558896 0.00899154 ... 0.01558896 0.37064937 0.00899154]\n",
      "Round 1 dp\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02855051 0.01568995 0.00904979 ... 0.01568995 0.37305061 0.00904979]\n",
      "Round 1 xgb\n",
      "[0.23388482 0.23388482 0.23388482 ... 0.23388482 0.23388482 0.23388482]\n",
      "Round 1 mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [10:35:37] WARNING: /workspace/src/collective/../data/../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.09980612 0.09980612 0.09980612 ... 0.09980612 0.27184386 0.09980612]\n",
      "Round 1 ridge\n",
      "[0.05699213 0.10445325 0.05699213 ... 0.10445325 0.28450133 0.05699213]\n",
      "Round 1 rf\n",
      "[0.00972456 0.01782285 0.00972456 ... 0.01782285 0.34121809 0.00972456]\n",
      "Round 1 dp\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00242624 0.00444673 0.01014391 ... 0.00444673 0.35593247 0.00242624]\n",
      "Round 1 xgb\n",
      "[0.23279516 0.23279516 0.23279516 ... 0.23279516 1.72993943 0.23279516]\n",
      "Round 1 mlp\n",
      "[0.08392788 0.27506989 0.08392788 ... 0.08392788 0.62368201 0.08392788]\n",
      "Round 1 ridge\n",
      "[0.05071687 0.16622227 0.08757203 ... 0.08757203 0.65076228 0.05071687]\n",
      "Round 1 rf\n",
      "[0.00869156 0.02848619 0.01500758 ... 0.01500758 0.11152378 0.00869156]\n",
      "Round 1 dp\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00437543 0.01434028 0.0153813  ... 0.0153813  0.11430096 0.00437543]\n",
      "Round 1 xgb\n",
      "[0.23708532 0.23708532 0.23708532 ... 0.23708532 0.23708532 0.23708532]\n",
      "Round 1 mlp\n",
      "[0.08409219 0.08409219 0.08409219 ... 0.08409219 0.2775151  0.2775151 ]\n",
      "Round 1 ridge\n",
      "[0.05157333 0.0875814  0.0875814  ... 0.0875814  0.28902994 0.28902994]\n",
      "Round 1 rf\n",
      "[0.00982972 0.01669275 0.01669275 ... 0.01669275 0.05508823 0.34174219]\n",
      "Round 1 dp\n",
      "99\n",
      "[0.00290597 0.00493489 0.00493489 ... 0.00493489 0.05705448 0.35393992]\n",
      "Round 1 xgb\n",
      "[0.23216122 0.23216122 0.23216122 ... 0.23216122 0.23216122 0.23216122]\n",
      "Round 1 mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0800001  0.27420349 0.0800001  ... 0.0800001  0.27420349 0.0800001 ]\n",
      "Round 1 ridge\n",
      "[0.04711346 0.16148323 0.08326874 ... 0.08326874 0.28540686 0.04711346]\n",
      "Round 1 rf\n",
      "[0.00805859 0.02762113 0.01424282 ... 0.01424282 0.33553022 0.00805859]\n",
      "Round 1 dp\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/modules/conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n",
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00186763 0.00640139 0.00330087 ... 0.00330087 0.35263381 0.00186763]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/trained-models/ensemble/weighted-mean/dp-pd-hek293t-pe2-fold-1.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m ensemble_adaboost \u001b[38;5;241m=\u001b[39m EnsembleAdaBoost(n_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mround\u001b[39m)\n\u001b[1;32m     12\u001b[0m ensemble_adaboost\u001b[38;5;241m.\u001b[39mfit(data)\n\u001b[0;32m---> 13\u001b[0m ensemble_adaboost_performance_pearson, ensemble_adaboost_performance_spearman \u001b[38;5;241m=\u001b[39m \u001b[43mensemble_adaboost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# rename the keys to include the round number\u001b[39;00m\n\u001b[1;32m     15\u001b[0m ensemble_adaboost_performance_pearson[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mada-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m ensemble_adaboost_performance_pearson\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mada\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/development/ox-dissertation/models/ensemble_adaboost.py:301\u001b[0m, in \u001b[0;36mEnsembleAdaBoost.test\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    299\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_learners[base_learner](save_path\u001b[38;5;241m=\u001b[39msave_path)\n\u001b[1;32m    300\u001b[0m     model\u001b[38;5;241m.\u001b[39minitialize()\n\u001b[0;32m--> 301\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msave_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/skorch/net.py:2669\u001b[0m, in \u001b[0;36mNeuralNet.load_params\u001b[0;34m(self, f_params, f_optimizer, f_criterion, f_history, checkpoint, use_safetensors, **kwargs)\u001b[0m\n\u001b[1;32m   2667\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_is_fitted([attr], msg\u001b[38;5;241m=\u001b[39mmsg_init)\n\u001b[1;32m   2668\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(attr, msg\u001b[38;5;241m=\u001b[39mmsg_module)\n\u001b[0;32m-> 2669\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43m_get_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2670\u001b[0m module\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/skorch/net.py:2626\u001b[0m, in \u001b[0;36mNeuralNet.load_params.<locals>._get_state_dict\u001b[0;34m(f_name)\u001b[0m\n\u001b[1;32m   2624\u001b[0m map_location \u001b[38;5;241m=\u001b[39m get_map_location(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2625\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_device(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, map_location)\n\u001b[0;32m-> 2626\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/torch/serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/torch/serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/dl/lib/python3.11/site-packages/torch/serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/trained-models/ensemble/weighted-mean/dp-pd-hek293t-pe2-fold-1.pt'"
     ]
    }
   ],
   "source": [
    "from models.ensemble_adaboost import EnsembleAdaBoost\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "ensemble_adaboost_performances_pearson = {}\n",
    "ensemble_adaboost_performances_spearman = {}\n",
    "\n",
    "rounds = [1, 2, 3, 5, 10]\n",
    "\n",
    "for round in rounds:  \n",
    "    ensemble_adaboost = EnsembleAdaBoost(n_rounds=round)\n",
    "    ensemble_adaboost.fit(data)\n",
    "    ensemble_adaboost_performance_pearson, ensemble_adaboost_performance_spearman = ensemble_adaboost.test(data)\n",
    "    # rename the keys to include the round number\n",
    "    ensemble_adaboost_performance_pearson[f'ada-{round}'] = ensemble_adaboost_performance_pearson.pop('ada')\n",
    "    ensemble_adaboost_performance_spearman[f'ada-{round}'] = ensemble_adaboost_performance_spearman.pop('ada')\n",
    "\n",
    "    ensemble_adaboost_performances_pearson.update(ensemble_adaboost_performance_pearson)\n",
    "    ensemble_adaboost_performances_spearman.update(ensemble_adaboost_performance_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from scipy.stats import ttest_ind\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [ensemble_adaboost_performances_pearson, ensemble_adaboost_performances_spearman]):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=len(rounds)))\n",
    "    colours = ['gray' if 'ada' not in model else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Model', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for adaboost model\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'ada' in model:\n",
    "            ax.axhline(y=np.mean(performance[model]), color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    plt.show()\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'ada' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if 'ada' not in model}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
