{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Mean Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_weighted_mean import EnsembleWeightedMean\n",
    "\n",
    "ensemble_direct_optimization = EnsembleWeightedMean(optimization=True)\n",
    "ensemble_direct_optimization_with_features = EnsembleWeightedMean(optimization=True, with_features=True)\n",
    "ensemble_weigthed_mean = EnsembleWeightedMean(optimization=False)\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "ensemble_direct_optimization.fit(data)\n",
    "direct_optimization_performance = ensemble_direct_optimization.test(data) \n",
    "\n",
    "ensemble_weigthed_mean.fit(data)\n",
    "weighted_mean_performance = ensemble_weigthed_mean.test(data)\n",
    "\n",
    "ensemble_direct_optimization_with_features.fit(data)\n",
    "with_features_performance = ensemble_direct_optimization_with_features.test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "\n",
    "direct_op_pearson, direct_op_spearman = direct_optimization_performance\n",
    "performance_weighted_pearson, performance_weighted_spearman = weighted_mean_performance\n",
    "performance_with_features_pearson, performance_with_features_spearman = with_features_performance\n",
    "\n",
    "# join the performance values, ignore the common keys\n",
    "direct_op_pearson.update(performance_weighted_pearson)\n",
    "direct_op_spearman.update(performance_weighted_spearman)\n",
    "\n",
    "direct_op_pearson.update(performance_with_features_pearson)\n",
    "direct_op_spearman.update(performance_with_features_spearman)\n",
    "\n",
    "performance_pearson = direct_op_pearson\n",
    "performance_spearman = direct_op_spearman\n",
    "\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "# plot the bar plot on top of the strip plot\n",
    "# bar plot should be shortened to emphasize the difference in values\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [performance_pearson, performance_spearman]):\n",
    "    # performance = pd.DataFrame({'Models': list(performance.keys()), 'Performance': list(performance.values()), 'Category': [0 if 'op' in model or 'pwm' in model else 1 for model in performance.keys()]})\n",
    "    # print(performance)\n",
    "    # add a category column\n",
    "    print(name)\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=3))\n",
    "    colours = ['gray' if not ('opt' in model or 'pwm' in model) else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Ensemble', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for 'opt', 'pwm' models of matching color\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'opt' in model or 'pwm' in model:\n",
    "            ax.axhline(y=performance[model], color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    plt.show()\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'opt' in model or 'pwm' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if not ('opt' in model or 'pwm' in model)}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')\n",
    "                \n",
    "    # save the figure\n",
    "    fig.savefig(pjoin('dissertation', 'figures', f'ensemble_{name.lower()}.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_bagging import EnsembleBagging\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "n_rounds = [1, 2, 3, 5, 10, 15]\n",
    "\n",
    "performances_pearson = {}\n",
    "performances_spearman = {}\n",
    "for i in n_rounds:\n",
    "    print(f'Bagging with {i} rounds')\n",
    "    ensemble_bagging = EnsembleBagging(n_rounds=i)\n",
    "    ensemble_bagging.fit(data)\n",
    "    performance_pearson, performance_spearman = ensemble_bagging.test(data)\n",
    "    performance_pearson[f'bag-{i}'] = performance_pearson.pop('bag')\n",
    "    performance_spearman[f'bag-{i}'] = performance_spearman.pop('bag')\n",
    "    performances_pearson.update(performance_pearson)\n",
    "    performances_spearman.update(performance_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [performances_pearson, performances_spearman]):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=len(n_rounds)))\n",
    "    colours = ['gray' if 'bag' not in model else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Model', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for adaboost model\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'bag' in model:\n",
    "            ax.axhline(y=np.mean(performance[model]), color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, horizontalalignment='right')\n",
    "    plt.show()\n",
    "\n",
    "    # save the figure\n",
    "    fig.savefig(pjoin('dissertation', 'figures', f'ensemble_bagging_{name.lower()}_round.png'), bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'bag' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if 'bag' not in model}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_bagging import EnsembleBagging\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "percentages = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "performances_pearson = {}\n",
    "performances_spearman = {}\n",
    "for i in percentages:\n",
    "    ensemble_bagging = EnsembleBagging(n_rounds=3, sample_percentage=i)\n",
    "    ensemble_bagging.fit(data)\n",
    "    performance_pearson, performance_spearman = ensemble_bagging.test(data)\n",
    "    performance_pearson[f'bag-{i}'] = performance_pearson.pop('bag')\n",
    "    performance_spearman[f'bag-{i}'] = performance_spearman.pop('bag')\n",
    "    performances_pearson.update(performance_pearson)\n",
    "    performances_spearman.update(performance_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [performances_pearson, performances_spearman]):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=len(percentages)))\n",
    "    colours = ['gray' if 'bag' not in model else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Model', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for adaboost model\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'bag' in model:\n",
    "            ax.axhline(y=np.mean(performance[model]), color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, horizontalalignment='right')\n",
    "    plt.show()\n",
    "\n",
    "    # save the figure\n",
    "    fig.savefig(pjoin('dissertation', 'figures', f'ensemble_{name.lower()}_bagging_percentage.pdf'), bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'bag' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if 'bag' not in model}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m902.8081\u001b[0m     \u001b[32m1065.8015\u001b[0m     +  0.0050  0.4552\n",
      "      2      905.6232     1177.5085        0.0049  0.2039\n",
      "      3      \u001b[36m670.7646\u001b[0m      \u001b[32m979.2058\u001b[0m     +  0.0045  0.3045\n",
      "      4      694.8727      998.2118        0.0040  0.2413\n",
      "      5      \u001b[36m620.1143\u001b[0m      \u001b[32m951.4051\u001b[0m     +  0.0033  0.3506\n",
      "      6      \u001b[36m587.0508\u001b[0m      \u001b[32m916.3622\u001b[0m     +  0.0025  0.2057\n",
      "      7      \u001b[36m550.3486\u001b[0m      \u001b[32m893.7935\u001b[0m     +  0.0017  0.3391\n",
      "      8      \u001b[36m524.0824\u001b[0m      \u001b[32m872.5058\u001b[0m     +  0.0010  0.2080\n",
      "      9      \u001b[36m507.1752\u001b[0m      \u001b[32m862.3949\u001b[0m     +  0.0005  0.2053\n",
      "     10      \u001b[36m498.3182\u001b[0m      \u001b[32m859.3911\u001b[0m     +  0.0001  0.2991\n",
      "     11      589.1594      \u001b[32m766.1726\u001b[0m     +  0.0050  0.2001\n",
      "     12      739.4451     1065.9639        0.0049  0.2992\n",
      "     13      529.4422      787.9208        0.0045  0.1999\n",
      "     14      \u001b[36m481.7765\u001b[0m      812.6475        0.0040  0.3053\n",
      "     15      \u001b[36m471.9525\u001b[0m      790.1809        0.0033  0.2846\n",
      "     16      \u001b[36m444.4198\u001b[0m      767.1551        0.0025  0.2427\n",
      "     17      \u001b[36m435.8997\u001b[0m      \u001b[32m755.5438\u001b[0m     +  0.0017  0.3509\n",
      "     18      \u001b[36m426.2733\u001b[0m      \u001b[32m750.8749\u001b[0m     +  0.0010  0.2056\n",
      "     19      \u001b[36m421.2908\u001b[0m      \u001b[32m747.8373\u001b[0m     +  0.0005  0.3155\n",
      "     20      \u001b[36m418.7145\u001b[0m      \u001b[32m746.9964\u001b[0m     +  0.0001  0.2280\n",
      "     21      461.1732      758.3670        0.0050  0.3543\n",
      "     22      508.8209      804.7632        0.0049  0.3849\n",
      "     23      477.4124      771.9286        0.0045  0.3767\n",
      "     24      430.4582      \u001b[32m729.3857\u001b[0m     +  0.0040  0.4505\n",
      "     25      420.2491      \u001b[32m725.5357\u001b[0m     +  0.0033  0.2027\n",
      "     26      \u001b[36m409.4977\u001b[0m      \u001b[32m714.8279\u001b[0m     +  0.0025  0.3018\n",
      "     27      \u001b[36m400.0170\u001b[0m      \u001b[32m708.5782\u001b[0m     +  0.0017  0.2229\n",
      "     28      \u001b[36m394.2086\u001b[0m      \u001b[32m705.4187\u001b[0m     +  0.0010  0.3428\n",
      "     29      \u001b[36m390.3566\u001b[0m      \u001b[32m704.2140\u001b[0m     +  0.0005  0.2169\n",
      "     30      \u001b[36m388.2762\u001b[0m      \u001b[32m703.8837\u001b[0m     +  0.0001  0.3175\n",
      "     31      422.0031      736.0880        0.0050  0.2088\n",
      "     32      467.6041      757.8389        0.0049  0.2503\n",
      "     33      452.3752      740.0438        0.0045  0.4620\n",
      "     34      408.6741      \u001b[32m690.3753\u001b[0m     +  0.0040  0.4973\n",
      "     35      395.5992      691.4751        0.0033  0.6271\n",
      "     36      388.5968      \u001b[32m683.3821\u001b[0m     +  0.0025  0.1989\n",
      "     37      \u001b[36m379.0173\u001b[0m      \u001b[32m678.3960\u001b[0m     +  0.0017  0.3074\n",
      "     38      \u001b[36m374.3544\u001b[0m      \u001b[32m677.0709\u001b[0m     +  0.0010  0.1962\n",
      "     39      \u001b[36m370.8274\u001b[0m      \u001b[32m676.6643\u001b[0m     +  0.0005  0.2974\n",
      "     40      \u001b[36m368.9931\u001b[0m      \u001b[32m676.6029\u001b[0m     +  0.0001  0.1969\n",
      "     41      398.8749      700.1971        0.0050  0.1926\n",
      "     42      441.4835      732.9442        0.0049  0.2994\n",
      "     43      438.2327      716.3636        0.0045  0.1956\n",
      "     44      394.2193      \u001b[32m666.5887\u001b[0m     +  0.0040  0.3038\n",
      "     45      378.0552      668.2636        0.0033  0.1976\n",
      "     46      373.9012      \u001b[32m659.8384\u001b[0m     +  0.0025  0.2966\n",
      "     47      \u001b[36m363.6824\u001b[0m      \u001b[32m659.0797\u001b[0m     +  0.0017  0.1978\n",
      "     48      \u001b[36m359.9887\u001b[0m      660.2121        0.0010  0.2973\n",
      "     49      \u001b[36m356.5373\u001b[0m      660.0927        0.0005  0.2197\n",
      "     50      \u001b[36m354.8535\u001b[0m      660.1663        0.0001  0.2525\n",
      "     51      381.8255      681.5887        0.0050  0.4168\n",
      "     52      423.3216      718.3383        0.0049  0.2027\n",
      "     53      430.6485      699.3266        0.0045  0.3177\n",
      "     54      386.0480      \u001b[32m650.1838\u001b[0m     +  0.0040  0.2058\n",
      "     55      365.3447      \u001b[32m649.7745\u001b[0m     +  0.0033  0.3014\n",
      "     56      363.5564      \u001b[32m644.3022\u001b[0m     +  0.0025  0.2000\n",
      "     57      \u001b[36m353.1784\u001b[0m      646.0273        0.0017  0.2925\n",
      "     58      \u001b[36m349.8630\u001b[0m      648.5710        0.0010  0.2058\n",
      "     59      \u001b[36m346.4866\u001b[0m      648.4510        0.0005  0.1872\n",
      "     60      \u001b[36m344.9779\u001b[0m      648.7297        0.0001  0.3088\n",
      "     61      369.8522      671.5675        0.0050  0.1942\n",
      "     62      409.2376      702.0442        0.0049  0.3045\n",
      "     63      418.7431      676.3412        0.0045  0.1993\n",
      "     64      376.6420      \u001b[32m635.9094\u001b[0m     +  0.0040  0.2947\n",
      "     65      355.7782      636.8612        0.0033  0.2012\n",
      "     66      354.7284      \u001b[32m630.5064\u001b[0m     +  0.0025  0.2937\n",
      "     67      \u001b[36m344.9410\u001b[0m      632.8761        0.0017  0.1957\n",
      "     68      \u001b[36m341.8384\u001b[0m      637.3977        0.0010  0.2013\n",
      "     69      \u001b[36m338.6310\u001b[0m      637.6085        0.0005  0.3216\n",
      "     70      \u001b[36m337.2613\u001b[0m      638.0855        0.0001  0.2070\n",
      "     71      360.4556      655.0051        0.0050  0.3092\n",
      "     72      396.5542      685.6575        0.0049  0.1988\n",
      "     73      409.4783      662.0721        0.0045  0.2954\n",
      "     74      372.5544      \u001b[32m618.5508\u001b[0m     +  0.0040  0.2024\n",
      "     75      347.6150      623.4213        0.0033  0.2979\n",
      "     76      346.3932      619.9716        0.0025  0.1985\n",
      "     77      337.9461      621.9931        0.0017  0.1887\n",
      "     78      \u001b[36m334.5146\u001b[0m      629.5485        0.0010  0.3020\n",
      "     79      \u001b[36m331.5259\u001b[0m      630.4027        0.0005  0.1963\n",
      "     80      \u001b[36m330.2200\u001b[0m      631.1189        0.0001  0.3097\n",
      "     81      352.9659      638.7177        0.0050  0.2221\n",
      "     82      383.7182      663.3626        0.0049  0.2956\n",
      "     83      399.5235      651.9179        0.0045  0.1989\n",
      "     84      371.6316      \u001b[32m591.5618\u001b[0m     +  0.0040  0.2902\n",
      "     85      340.9274      607.4309        0.0033  0.1983\n",
      "     86      337.2399      \u001b[32m588.2753\u001b[0m     +  0.0025  0.1969\n",
      "     87      331.2305      600.3977        0.0017  0.2989\n",
      "     88      \u001b[36m325.1609\u001b[0m      601.3607        0.0010  0.2031\n",
      "     89      \u001b[36m322.4572\u001b[0m      602.1445        0.0005  0.3133\n",
      "     90      \u001b[36m320.9633\u001b[0m      602.6719        0.0001  0.2197\n",
      "     91      345.6440      610.4647        0.0050  0.3059\n",
      "     92      368.5057      629.9702        0.0049  0.1944\n",
      "     93      384.1034      618.8249        0.0045  0.2968\n",
      "     94      364.4958      \u001b[32m568.2179\u001b[0m     +  0.0040  0.2059\n",
      "     95      337.1364      581.1986        0.0033  0.1962\n",
      "     96      324.0601      574.3995        0.0025  0.2948\n",
      "     97      \u001b[36m320.4539\u001b[0m      580.2297        0.0017  0.1942\n",
      "     98      \u001b[36m314.2442\u001b[0m      582.8157        0.0010  0.3031\n",
      "     99      \u001b[36m311.9333\u001b[0m      587.4468        0.0005  0.2063\n",
      "    100      \u001b[36m310.4900\u001b[0m      587.9693        0.0001  0.2967\n",
      "    101      334.0657      587.9130        0.0050  0.1895\n",
      "    102      354.5781      611.8794        0.0049  0.2922\n",
      "    103      369.8083      599.2503        0.0045  0.2074\n",
      "    104      359.1010      \u001b[32m559.9890\u001b[0m     +  0.0040  0.1953\n",
      "    105      329.3641      567.1555        0.0033  0.3006\n",
      "    106      314.6080      568.9590        0.0025  0.2021\n",
      "    107      311.1486      569.8588        0.0017  0.3030\n",
      "    108      \u001b[36m305.8224\u001b[0m      572.4189        0.0010  0.2149\n",
      "    109      \u001b[36m303.5807\u001b[0m      577.1293        0.0005  0.3084\n",
      "    110      \u001b[36m302.1784\u001b[0m      577.3781        0.0001  0.2194\n",
      "    111      325.5213      571.4625        0.0050  0.3696\n",
      "    112      341.7624      595.4723        0.0049  0.3951\n",
      "    113      357.7257      590.0221        0.0045  0.2903\n",
      "    114      357.1720      \u001b[32m552.8361\u001b[0m     +  0.0040  0.3134\n",
      "    115      325.5128      \u001b[32m550.0945\u001b[0m     +  0.0033  0.2065\n",
      "    116      307.0565      580.7775        0.0025  0.3089\n",
      "    117      303.5985      557.3680        0.0017  0.2042\n",
      "    118      \u001b[36m298.6739\u001b[0m      563.9642        0.0010  0.3167\n",
      "    119      \u001b[36m296.1668\u001b[0m      570.2899        0.0005  0.2021\n",
      "    120      \u001b[36m294.7750\u001b[0m      569.6060        0.0001  0.3146\n",
      "    121      318.0253      558.8121        0.0050  0.2122\n",
      "    122      328.2876      574.1702        0.0049  0.2062\n",
      "    123      342.8155      576.1314        0.0045  0.3057\n",
      "    124      352.4636      558.7224        0.0040  0.2001\n",
      "    125      327.2965      \u001b[32m536.4619\u001b[0m     +  0.0033  0.3005\n",
      "    126      301.8305      585.6460        0.0025  0.2101\n",
      "    127      297.4705      560.8818        0.0017  0.3057\n",
      "    128      \u001b[36m293.6084\u001b[0m      561.0700        0.0010  0.2127\n",
      "    129      \u001b[36m290.5419\u001b[0m      569.4434        0.0005  0.3288\n",
      "    130      \u001b[36m289.1606\u001b[0m      568.6061        0.0001  0.2069\n",
      "    131      310.2403      544.3390        0.0050  0.1987\n",
      "    132      320.2289      566.8314        0.0049  0.3102\n",
      "    133      333.7532      571.7384        0.0045  0.1964\n",
      "    134      341.3169      542.9846        0.0040  0.3016\n",
      "    135      323.0948      \u001b[32m524.4352\u001b[0m     +  0.0033  0.2040\n",
      "    136      298.2161      589.4745        0.0025  0.3010\n",
      "    137      290.8002      559.0819        0.0017  0.1972\n",
      "    138      \u001b[36m288.0303\u001b[0m      563.3078        0.0010  0.2921\n",
      "    139      \u001b[36m285.1847\u001b[0m      568.0397        0.0005  0.2167\n",
      "    140      \u001b[36m284.0116\u001b[0m      567.3117        0.0001  0.1954\n",
      "    141      303.1042      542.7934        0.0050  0.3132\n",
      "    142      312.4316      553.1585        0.0049  0.2076\n",
      "    143      322.7564      555.1936        0.0045  0.3041\n",
      "    144      332.0899      540.6722        0.0040  0.1973\n",
      "    145      320.2841      \u001b[32m519.5310\u001b[0m     +  0.0033  0.2997\n",
      "    146      295.9910      579.4146        0.0025  0.2031\n",
      "    147      285.5863      559.4606        0.0017  0.2019\n",
      "    148      \u001b[36m283.4474\u001b[0m      562.2467        0.0010  0.3059\n",
      "    149      \u001b[36m280.2490\u001b[0m      564.7794        0.0005  0.2197\n",
      "    150      \u001b[36m279.1311\u001b[0m      564.2724        0.0001  0.3642\n",
      "    151      296.9359      537.1289        0.0050  0.2173\n",
      "    152      307.2971      555.4983        0.0049  0.2951\n",
      "    153      315.4309      561.4160        0.0045  0.2093\n",
      "    154      326.8828      536.8958        0.0040  0.2945\n",
      "    155      316.7114      \u001b[32m509.0988\u001b[0m     +  0.0033  0.2094\n",
      "    156      296.7488      586.4688        0.0025  0.2342\n",
      "    157      281.6380      557.8335        0.0017  0.3231\n",
      "    158      279.4273      561.4419        0.0010  0.2060\n",
      "    159      \u001b[36m275.8885\u001b[0m      558.5779        0.0005  0.3090\n",
      "    160      \u001b[36m274.7565\u001b[0m      558.4132        0.0001  0.1985\n",
      "    161      293.0250      544.7891        0.0050  0.2943\n",
      "    162      298.6834      543.5230        0.0049  0.2048\n",
      "    163      306.7581      544.7551        0.0045  0.3190\n",
      "    164      316.0052      539.7456        0.0040  0.2153\n",
      "    165      314.0605      \u001b[32m499.4810\u001b[0m     +  0.0033  0.3291\n",
      "    166      294.1223      581.8099        0.0025  0.4305\n",
      "    167      277.3836      562.6186        0.0017  0.2214\n",
      "    168      274.8771      566.3704        0.0010  0.5343\n",
      "    169      \u001b[36m271.8785\u001b[0m      558.0749        0.0005  0.4293\n",
      "    170      \u001b[36m270.7797\u001b[0m      558.7269        0.0001  0.3236\n",
      "    171      287.3215      541.7466        0.0050  0.2567\n",
      "    172      294.5391      542.5226        0.0049  0.3011\n",
      "    173      301.3511      539.6823        0.0045  0.1976\n",
      "    174      310.6976      538.7699        0.0040  0.1886\n",
      "    175      311.4976      502.1581        0.0033  0.2948\n",
      "    176      293.0783      582.1252        0.0025  0.1955\n",
      "    177      275.0039      575.2297        0.0017  0.2946\n",
      "    178      272.2843      571.8329        0.0010  0.1956\n",
      "    179      \u001b[36m268.8661\u001b[0m      559.8693        0.0005  0.3552\n",
      "    180      \u001b[36m267.7143\u001b[0m      561.1135        0.0001  0.3522\n",
      "    181      282.6424      536.1624        0.0050  0.3162\n",
      "    182      290.7222      541.9994        0.0049  0.1963\n",
      "    183      296.3086      535.6809        0.0045  0.1972\n",
      "    184      303.7555      528.6901        0.0040  0.3012\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m920.9788\u001b[0m     \u001b[32m1026.7804\u001b[0m     +  0.0050  0.3244\n",
      "      2      \u001b[36m910.6159\u001b[0m     1222.1693        0.0049  0.2113\n",
      "      3      \u001b[36m670.7083\u001b[0m      \u001b[32m953.7262\u001b[0m     +  0.0045  0.3215\n",
      "      4      699.8666     1032.0830        0.0040  0.2651\n",
      "      5      \u001b[36m620.9295\u001b[0m      968.9040        0.0033  0.4581\n",
      "      6      \u001b[36m592.5362\u001b[0m      \u001b[32m936.8785\u001b[0m     +  0.0025  0.4835\n",
      "      7      \u001b[36m553.9709\u001b[0m      \u001b[32m909.9374\u001b[0m     +  0.0017  0.2829\n",
      "      8      \u001b[36m528.0126\u001b[0m      \u001b[32m886.8773\u001b[0m     +  0.0010  0.6763\n",
      "      9      \u001b[36m512.4157\u001b[0m      \u001b[32m876.8320\u001b[0m     +  0.0005  0.4554\n",
      "     10      \u001b[36m504.6346\u001b[0m      \u001b[32m874.1538\u001b[0m     +  0.0001  0.3223\n",
      "     11      596.3525      \u001b[32m807.3248\u001b[0m     +  0.0050  0.2140\n",
      "     12      686.8835      978.2230        0.0049  0.3070\n",
      "     13      533.7908      820.3949        0.0045  0.2083\n",
      "     14      \u001b[36m474.7146\u001b[0m      \u001b[32m798.2728\u001b[0m     +  0.0040  0.2057\n",
      "     15      \u001b[36m473.2590\u001b[0m      \u001b[32m780.5044\u001b[0m     +  0.0033  0.3133\n",
      "     16      \u001b[36m443.4073\u001b[0m      \u001b[32m747.1531\u001b[0m     +  0.0025  0.2097\n",
      "     17      \u001b[36m433.7412\u001b[0m      \u001b[32m738.9633\u001b[0m     +  0.0017  0.3495\n",
      "     18      \u001b[36m423.1865\u001b[0m      \u001b[32m731.1215\u001b[0m     +  0.0010  0.2152\n",
      "     19      \u001b[36m417.9839\u001b[0m      \u001b[32m727.1718\u001b[0m     +  0.0005  0.3253\n",
      "     20      \u001b[36m415.0676\u001b[0m      \u001b[32m726.2297\u001b[0m     +  0.0001  0.2168\n",
      "     21      460.9456      755.7930        0.0050  0.3035\n",
      "     22      527.9827      801.3829        0.0049  0.2217\n",
      "     23      500.7209      790.3333        0.0045  0.2078\n",
      "     24      436.2826      \u001b[32m710.8665\u001b[0m     +  0.0040  0.3034\n",
      "     25      417.6657      711.9215        0.0033  0.2063\n",
      "     26      \u001b[36m411.0295\u001b[0m      \u001b[32m703.2995\u001b[0m     +  0.0025  0.3229\n",
      "     27      \u001b[36m398.3659\u001b[0m      \u001b[32m693.2609\u001b[0m     +  0.0017  0.2079\n",
      "     28      \u001b[36m392.8643\u001b[0m      \u001b[32m689.3372\u001b[0m     +  0.0010  0.3198\n",
      "     29      \u001b[36m388.1811\u001b[0m      \u001b[32m688.0932\u001b[0m     +  0.0005  0.2124\n",
      "     30      \u001b[36m385.8792\u001b[0m      \u001b[32m687.8194\u001b[0m     +  0.0001  0.2070\n",
      "     31      422.0427      711.7949        0.0050  0.3036\n",
      "     32      476.2791      767.5932        0.0049  0.2018\n",
      "     33      475.0714      739.2968        0.0045  0.3626\n",
      "     34      416.2165      \u001b[32m679.5590\u001b[0m     +  0.0040  0.2097\n",
      "     35      396.0923      \u001b[32m676.9175\u001b[0m     +  0.0033  0.3439\n",
      "     36      391.9077      \u001b[32m666.6022\u001b[0m     +  0.0025  0.3052\n",
      "     37      \u001b[36m380.5305\u001b[0m      \u001b[32m660.3255\u001b[0m     +  0.0017  0.4222\n",
      "     38      \u001b[36m376.2652\u001b[0m      660.5577        0.0010  0.3059\n",
      "     39      \u001b[36m372.3581\u001b[0m      660.6956        0.0005  0.1976\n",
      "     40      \u001b[36m370.4784\u001b[0m      660.8169        0.0001  0.3021\n",
      "     41      399.5374      693.6891        0.0050  0.2141\n",
      "     42      445.6389      740.4395        0.0049  0.3093\n",
      "     43      455.0985      720.0199        0.0045  0.2075\n",
      "     44      404.2773      \u001b[32m658.2744\u001b[0m     +  0.0040  0.3061\n",
      "     45      380.9190      \u001b[32m657.3354\u001b[0m     +  0.0033  0.2037\n",
      "     46      378.7284      \u001b[32m651.2437\u001b[0m     +  0.0025  0.2013\n",
      "     47      \u001b[36m367.9278\u001b[0m      \u001b[32m648.4713\u001b[0m     +  0.0017  0.3077\n",
      "     48      \u001b[36m364.3232\u001b[0m      651.1494        0.0010  0.2009\n",
      "     49      \u001b[36m360.5793\u001b[0m      651.5144        0.0005  0.3029\n",
      "     50      \u001b[36m358.9138\u001b[0m      651.7923        0.0001  0.2064\n",
      "     51      385.6574      686.6535        0.0050  0.2985\n",
      "     52      430.8393      731.7406        0.0049  0.2037\n",
      "     53      442.0969      698.0304        0.0045  0.3254\n",
      "     54      394.8754      \u001b[32m639.9239\u001b[0m     +  0.0040  0.2948\n",
      "     55      370.2834      \u001b[32m638.5978\u001b[0m     +  0.0033  0.2915\n",
      "     56      369.4502      \u001b[32m637.0208\u001b[0m     +  0.0025  0.3083\n",
      "     57      359.1444      \u001b[32m636.1253\u001b[0m     +  0.0017  0.2029\n",
      "     58      \u001b[36m355.8532\u001b[0m      641.4258        0.0010  0.3009\n",
      "     59      \u001b[36m352.2025\u001b[0m      641.3780        0.0005  0.2107\n",
      "     60      \u001b[36m350.6554\u001b[0m      641.3578        0.0001  0.3014\n",
      "     61      377.4455      672.3786        0.0050  0.2110\n",
      "     62      417.2305      702.1605        0.0049  0.3028\n",
      "     63      428.4980      688.2185        0.0045  0.2039\n",
      "     64      391.3590      \u001b[32m633.2218\u001b[0m     +  0.0040  0.2007\n",
      "     65      361.7989      \u001b[32m632.5563\u001b[0m     +  0.0033  0.3106\n",
      "     66      362.1096      \u001b[32m630.4339\u001b[0m     +  0.0025  0.2081\n",
      "     67      352.4789      \u001b[32m628.7211\u001b[0m     +  0.0017  0.3179\n",
      "     68      \u001b[36m349.2803\u001b[0m      637.1594        0.0010  0.1961\n",
      "     69      \u001b[36m345.7533\u001b[0m      637.9974        0.0005  0.3041\n",
      "     70      \u001b[36m344.3938\u001b[0m      638.6304        0.0001  0.1975\n",
      "     71      368.1592      656.4331        0.0050  0.3133\n",
      "     72      410.5192      690.5559        0.0049  0.2000\n",
      "     73      424.5575      676.4204        0.0045  0.2219\n",
      "     74      390.7789      \u001b[32m624.7047\u001b[0m     +  0.0040  0.3157\n",
      "     75      354.9763      \u001b[32m620.8841\u001b[0m     +  0.0033  0.1965\n",
      "     76      355.6970      621.7694        0.0025  0.3246\n",
      "     77      347.0367      \u001b[32m618.7845\u001b[0m     +  0.0017  0.2055\n",
      "     78      \u001b[36m343.3415\u001b[0m      633.5172        0.0010  0.3051\n",
      "     79      \u001b[36m339.8297\u001b[0m      633.9292        0.0005  0.1938\n",
      "     80      \u001b[36m338.5444\u001b[0m      634.4960        0.0001  0.3034\n",
      "     81      361.2381      640.7937        0.0050  0.1973\n",
      "     82      399.4066      687.3178        0.0049  0.2064\n",
      "     83      417.5637      649.9722        0.0045  0.3029\n",
      "     84      376.6102      \u001b[32m617.2607\u001b[0m     +  0.0040  0.2143\n",
      "     85      349.5861      622.6363        0.0033  0.3063\n",
      "     86      348.5296      \u001b[32m616.5204\u001b[0m     +  0.0025  0.2119\n",
      "     87      340.3705      617.1354        0.0017  0.3154\n",
      "     88      \u001b[36m336.6708\u001b[0m      628.8577        0.0010  0.2023\n",
      "     89      \u001b[36m333.4595\u001b[0m      628.7873        0.0005  0.3004\n",
      "     90      \u001b[36m332.2111\u001b[0m      629.5501        0.0001  0.2137\n",
      "     91      354.6159      623.4167        0.0050  0.2094\n",
      "     92      390.1719      668.1007        0.0049  0.3103\n",
      "     93      411.5300      644.9011        0.0045  0.2124\n",
      "     94      373.2701      \u001b[32m593.0376\u001b[0m     +  0.0040  0.3065\n",
      "     95      341.9637      594.9193        0.0033  0.1978\n",
      "     96      340.1421      \u001b[32m583.3018\u001b[0m     +  0.0025  0.3099\n",
      "     97      333.6696      588.3565        0.0017  0.2073\n",
      "     98      \u001b[36m326.9804\u001b[0m      596.5224        0.0010  0.3003\n",
      "     99      \u001b[36m324.2527\u001b[0m      597.1957        0.0005  0.2688\n",
      "    100      \u001b[36m322.6060\u001b[0m      597.7594        0.0001  0.3771\n",
      "    101      348.9790      594.5038        0.0050  0.3284\n",
      "    102      381.3250      644.8135        0.0049  0.2056\n",
      "    103      399.0349      663.8453        0.0045  0.3120\n",
      "    104      384.9716      587.5899        0.0040  0.2078\n",
      "    105      344.6164      628.6412        0.0033  0.3153\n",
      "    106      336.6873      644.1796        0.0025  0.1976\n",
      "    107      331.6549      613.7176        0.0017  0.2981\n",
      "    108      325.7930      616.0017        0.0010  0.1994\n",
      "    109      323.0064      615.6624        0.0005  0.1924\n",
      "    110      \u001b[36m321.5688\u001b[0m      615.8250        0.0001  0.3127\n",
      "    111      345.3316      589.3727        0.0050  0.1993\n",
      "    112      373.3081      633.3374        0.0049  0.3261\n",
      "    113      390.3131      652.3404        0.0045  0.2153\n",
      "    114      372.3563      603.6249        0.0040  0.3151\n",
      "    115      337.5895      607.3885        0.0033  0.2032\n",
      "    116      324.2430      \u001b[32m570.8289\u001b[0m     +  0.0025  0.3119\n",
      "    117      325.4114      \u001b[32m567.9051\u001b[0m     +  0.0017  0.1947\n",
      "    118      \u001b[36m312.9389\u001b[0m      \u001b[32m563.6833\u001b[0m     +  0.0010  0.2057\n",
      "    119      \u001b[36m310.1275\u001b[0m      573.5076        0.0005  0.2952\n",
      "    120      \u001b[36m308.1384\u001b[0m      572.5695        0.0001  0.2143\n",
      "    121      338.9481      567.4831        0.0050  0.3151\n",
      "    122      363.4298      601.7015        0.0049  0.2195\n",
      "    123      377.6814      605.2748        0.0045  0.3087\n",
      "    124      365.9533      \u001b[32m542.3899\u001b[0m     +  0.0040  0.2021\n",
      "    125      330.8768      \u001b[32m541.5064\u001b[0m     +  0.0033  0.2977\n",
      "    126      313.1431      606.1320        0.0025  0.1994\n",
      "    127      309.9758      587.0768        0.0017  0.2035\n",
      "    128      \u001b[36m304.3038\u001b[0m      575.2756        0.0010  0.3052\n",
      "    129      \u001b[36m300.8962\u001b[0m      579.4975        0.0005  0.2013\n",
      "    130      \u001b[36m299.3404\u001b[0m      577.5657        0.0001  0.3014\n",
      "    131      324.9281      556.5305        0.0050  0.2004\n",
      "    132      343.5976      566.8765        0.0049  0.3442\n",
      "    133      364.6027      576.2656        0.0045  0.3510\n",
      "    134      361.1431      548.0813        0.0040  0.2990\n",
      "    135      328.0060      594.8903        0.0033  0.1996\n",
      "    136      307.4509      562.3459        0.0025  0.2437\n",
      "    137      303.3113      544.3262        0.0017  0.3487\n",
      "    138      \u001b[36m296.9244\u001b[0m      552.7292        0.0010  0.1948\n",
      "    139      \u001b[36m294.2179\u001b[0m      558.5875        0.0005  0.3123\n",
      "    140      \u001b[36m292.8949\u001b[0m      557.1627        0.0001  0.2023\n",
      "    141      317.3494      553.7135        0.0050  0.3030\n",
      "    142      330.8269      552.4615        0.0049  0.2062\n",
      "    143      349.4579      557.1116        0.0045  0.3114\n",
      "    144      358.9571      551.9490        0.0040  0.2060\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m898.7598\u001b[0m      \u001b[32m965.8378\u001b[0m     +  0.0050  0.2029\n",
      "      2      907.4150     1239.3410        0.0049  0.3601\n",
      "      3      \u001b[36m663.8160\u001b[0m      \u001b[32m925.8660\u001b[0m     +  0.0045  0.2133\n",
      "      4      684.7243      976.8768        0.0040  0.2097\n",
      "      5      \u001b[36m601.1083\u001b[0m      926.7989        0.0033  0.3123\n",
      "      6      \u001b[36m573.4029\u001b[0m      \u001b[32m893.7280\u001b[0m     +  0.0025  0.2073\n",
      "      7      \u001b[36m537.5873\u001b[0m      \u001b[32m873.7815\u001b[0m     +  0.0017  0.3245\n",
      "      8      \u001b[36m514.8380\u001b[0m      \u001b[32m857.1051\u001b[0m     +  0.0010  0.2109\n",
      "      9      \u001b[36m501.3101\u001b[0m      \u001b[32m849.8808\u001b[0m     +  0.0005  0.3146\n",
      "     10      \u001b[36m494.5833\u001b[0m      \u001b[32m847.8590\u001b[0m     +  0.0001  0.2071\n",
      "     11      579.2743      \u001b[32m797.3135\u001b[0m     +  0.0050  0.3156\n",
      "     12      686.9142      982.5496        0.0049  0.2135\n",
      "     13      531.3062      802.0340        0.0045  0.2099\n",
      "     14      \u001b[36m469.0612\u001b[0m      \u001b[32m778.1533\u001b[0m     +  0.0040  0.3296\n",
      "     15      470.8330      \u001b[32m774.1059\u001b[0m     +  0.0033  0.2069\n",
      "     16      \u001b[36m443.0857\u001b[0m      \u001b[32m755.0290\u001b[0m     +  0.0025  0.3052\n",
      "     17      \u001b[36m436.2091\u001b[0m      \u001b[32m746.4378\u001b[0m     +  0.0017  0.2071\n",
      "     18      \u001b[36m426.9866\u001b[0m      \u001b[32m742.1005\u001b[0m     +  0.0010  0.3098\n",
      "     19      \u001b[36m422.6030\u001b[0m      \u001b[32m739.6291\u001b[0m     +  0.0005  0.2134\n",
      "     20      \u001b[36m420.2426\u001b[0m      \u001b[32m738.9789\u001b[0m     +  0.0001  0.2141\n",
      "     21      459.8307      747.0838        0.0050  0.3130\n",
      "     22      501.1250      791.3323        0.0049  0.2116\n",
      "     23      478.8410      754.3378        0.0045  0.3157\n",
      "     24      434.6871      \u001b[32m716.5488\u001b[0m     +  0.0040  0.2069\n",
      "     25      420.3739      \u001b[32m712.4769\u001b[0m     +  0.0033  0.3296\n",
      "     26      \u001b[36m411.4727\u001b[0m      \u001b[32m705.2591\u001b[0m     +  0.0025  0.2619\n",
      "     27      \u001b[36m401.7562\u001b[0m      \u001b[32m702.0597\u001b[0m     +  0.0017  0.3227\n",
      "     28      \u001b[36m396.4649\u001b[0m      \u001b[32m700.1254\u001b[0m     +  0.0010  0.2099\n",
      "     29      \u001b[36m392.6992\u001b[0m      \u001b[32m699.2942\u001b[0m     +  0.0005  0.2120\n",
      "     30      \u001b[36m390.6925\u001b[0m      \u001b[32m699.1029\u001b[0m     +  0.0001  0.3090\n",
      "     31      422.8189      709.4096        0.0050  0.2064\n",
      "     32      463.6326      757.3643        0.0049  0.3201\n",
      "     33      457.8840      719.2119        0.0045  0.2107\n",
      "     34      415.7921      \u001b[32m687.4725\u001b[0m     +  0.0040  0.3048\n",
      "     35      397.9251      \u001b[32m680.7044\u001b[0m     +  0.0033  0.2211\n",
      "     36      392.3213      \u001b[32m676.7150\u001b[0m     +  0.0025  0.2527\n",
      "     37      \u001b[36m382.5299\u001b[0m      \u001b[32m673.3667\u001b[0m     +  0.0017  0.3237\n",
      "     38      \u001b[36m378.1047\u001b[0m      \u001b[32m672.5785\u001b[0m     +  0.0010  0.2092\n",
      "     39      \u001b[36m374.5048\u001b[0m      \u001b[32m671.9242\u001b[0m     +  0.0005  0.3068\n",
      "     40      \u001b[36m372.6858\u001b[0m      \u001b[32m671.8354\u001b[0m     +  0.0001  0.1991\n",
      "     41      401.1911      689.8204        0.0050  0.2944\n",
      "     42      443.1507      717.4152        0.0049  0.1962\n",
      "     43      443.2652      708.1958        0.0045  0.2044\n",
      "     44      407.2213      \u001b[32m660.3978\u001b[0m     +  0.0040  0.3049\n",
      "     45      380.8086      \u001b[32m651.5261\u001b[0m     +  0.0033  0.1997\n",
      "     46      379.2489      651.8503        0.0025  0.3068\n",
      "     47      \u001b[36m368.3273\u001b[0m      \u001b[32m645.8598\u001b[0m     +  0.0017  0.2018\n",
      "     48      \u001b[36m364.1745\u001b[0m      \u001b[32m643.2974\u001b[0m     +  0.0010  0.3226\n",
      "     49      \u001b[36m359.8033\u001b[0m      \u001b[32m641.5628\u001b[0m     +  0.0005  0.1991\n",
      "     50      \u001b[36m357.9134\u001b[0m      641.7591        0.0001  0.3159\n",
      "     51      387.5000      720.4432        0.0050  0.2012\n",
      "     52      443.8522      690.5310        0.0049  0.1976\n",
      "     53      470.8300      751.2762        0.0045  0.2995\n",
      "     54      411.7895      \u001b[32m627.9291\u001b[0m     +  0.0040  0.2086\n",
      "     55      370.7327      638.9592        0.0033  0.3128\n",
      "     56      373.1765      637.1792        0.0025  0.1976\n",
      "     57      359.7662      628.6900        0.0017  0.3024\n",
      "     58      \u001b[36m357.3513\u001b[0m      631.1268        0.0010  0.2119\n",
      "     59      \u001b[36m353.2992\u001b[0m      631.0422        0.0005  0.3104\n",
      "     60      \u001b[36m351.7260\u001b[0m      631.5063        0.0001  0.2042\n",
      "     61      375.1147      652.4393        0.0050  0.2046\n",
      "     62      411.2031      671.7086        0.0049  0.3110\n",
      "     63      417.1906      650.7861        0.0045  0.2092\n",
      "     64      376.5802      \u001b[32m611.8606\u001b[0m     +  0.0040  0.3187\n",
      "     65      361.3036      622.8477        0.0033  0.2088\n",
      "     66      359.9323      \u001b[32m611.0203\u001b[0m     +  0.0025  0.3069\n",
      "     67      \u001b[36m348.9045\u001b[0m      \u001b[32m608.9885\u001b[0m     +  0.0017  0.1941\n",
      "     68      \u001b[36m345.7785\u001b[0m      613.7302        0.0010  0.3048\n",
      "     69      \u001b[36m342.0051\u001b[0m      613.2563        0.0005  0.2012\n",
      "     70      \u001b[36m340.4345\u001b[0m      613.7053        0.0001  0.1987\n",
      "     71      365.4241      632.7764        0.0050  0.3057\n",
      "     72      397.7767      639.1706        0.0049  0.2028\n",
      "     73      410.6179      654.9784        0.0045  0.2959\n",
      "     74      384.1606      625.3531        0.0040  0.2215\n",
      "     75      354.0830      630.2933        0.0033  0.3099\n",
      "     76      355.4382      623.1263        0.0025  0.2151\n",
      "     77      346.7848      626.2695        0.0017  0.3062\n",
      "     78      343.0682      632.9666        0.0010  0.1988\n",
      "     79      \u001b[36m339.7433\u001b[0m      633.7157        0.0005  0.1991\n",
      "     80      \u001b[36m338.4026\u001b[0m      634.6548        0.0001  0.3160\n",
      "     81      362.9823      637.3186        0.0050  0.2100\n",
      "     82      395.6965      664.2660        0.0049  0.3030\n",
      "     83      407.6939      628.3212        0.0045  0.1997\n",
      "     84      368.1511      612.6452        0.0040  0.3035\n",
      "     85      348.5802      625.1517        0.0033  0.1954\n",
      "     86      351.3421      610.8821        0.0025  0.3150\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m913.0894\u001b[0m     \u001b[32m1002.7401\u001b[0m     +  0.0050  0.5142\n",
      "      2      947.5048     1229.2290        0.0049  0.5155\n",
      "      3      \u001b[36m685.6170\u001b[0m      \u001b[32m972.2225\u001b[0m     +  0.0045  0.4397\n",
      "      4      711.6134     1022.6613        0.0040  0.3137\n",
      "      5      \u001b[36m641.9010\u001b[0m      976.5618        0.0033  0.2024\n",
      "      6      \u001b[36m614.0837\u001b[0m      \u001b[32m956.8644\u001b[0m     +  0.0025  0.3071\n",
      "      7      \u001b[36m583.2347\u001b[0m      \u001b[32m932.7861\u001b[0m     +  0.0017  0.2042\n",
      "      8      \u001b[36m558.0270\u001b[0m      \u001b[32m910.6742\u001b[0m     +  0.0010  0.3068\n",
      "      9      \u001b[36m542.1783\u001b[0m      \u001b[32m900.4566\u001b[0m     +  0.0005  0.2047\n",
      "     10      \u001b[36m534.3117\u001b[0m      \u001b[32m897.7429\u001b[0m     +  0.0001  0.3100\n",
      "     11      623.3129      \u001b[32m859.2677\u001b[0m     +  0.0050  0.2121\n",
      "     12      661.5527      971.2301        0.0049  0.2116\n",
      "     13      \u001b[36m524.4801\u001b[0m      \u001b[32m797.9391\u001b[0m     +  0.0045  0.3286\n",
      "     14      \u001b[36m488.8656\u001b[0m      814.3422        0.0040  0.2107\n",
      "     15      \u001b[36m476.1756\u001b[0m      \u001b[32m774.1103\u001b[0m     +  0.0033  0.3137\n",
      "     16      \u001b[36m445.9011\u001b[0m      \u001b[32m744.4866\u001b[0m     +  0.0025  0.2165\n",
      "     17      \u001b[36m434.7651\u001b[0m      \u001b[32m736.4402\u001b[0m     +  0.0017  0.3200\n",
      "     18      \u001b[36m424.3232\u001b[0m      \u001b[32m730.6908\u001b[0m     +  0.0010  0.2164\n",
      "     19      \u001b[36m419.1153\u001b[0m      \u001b[32m727.5990\u001b[0m     +  0.0005  0.2190\n",
      "     20      \u001b[36m416.3156\u001b[0m      \u001b[32m726.8346\u001b[0m     +  0.0001  0.3178\n",
      "     21      461.9162      745.4241        0.0050  0.2125\n",
      "     22      524.3492      803.7046        0.0049  0.3191\n",
      "     23      497.7248      774.9451        0.0045  0.2130\n",
      "     24      436.4439      \u001b[32m716.1474\u001b[0m     +  0.0040  0.3275\n",
      "     25      420.4577      \u001b[32m715.2096\u001b[0m     +  0.0033  0.2630\n",
      "     26      \u001b[36m412.4446\u001b[0m      \u001b[32m704.3846\u001b[0m     +  0.0025  0.3661\n",
      "     27      \u001b[36m401.7753\u001b[0m      \u001b[32m698.0479\u001b[0m     +  0.0017  0.6644\n",
      "     28      \u001b[36m396.4833\u001b[0m      \u001b[32m695.8807\u001b[0m     +  0.0010  0.3091\n",
      "     29      \u001b[36m392.5861\u001b[0m      \u001b[32m695.2967\u001b[0m     +  0.0005  0.3447\n",
      "     30      \u001b[36m390.5484\u001b[0m      \u001b[32m695.2044\u001b[0m     +  0.0001  0.2057\n",
      "     31      422.8170      714.3352        0.0050  0.3075\n",
      "     32      468.1021      750.6785        0.0049  0.2129\n",
      "     33      462.5472      729.3398        0.0045  0.3095\n",
      "     34      419.2418      \u001b[32m690.9432\u001b[0m     +  0.0040  0.2089\n",
      "     35      399.2996      \u001b[32m688.2180\u001b[0m     +  0.0033  0.2117\n",
      "     36      394.4378      \u001b[32m683.4521\u001b[0m     +  0.0025  0.3266\n",
      "     37      \u001b[36m384.8217\u001b[0m      \u001b[32m679.4414\u001b[0m     +  0.0017  0.1989\n",
      "     38      \u001b[36m380.6067\u001b[0m      \u001b[32m679.3930\u001b[0m     +  0.0010  0.2982\n",
      "     39      \u001b[36m377.0764\u001b[0m      679.5805        0.0005  0.2051\n",
      "     40      \u001b[36m375.3100\u001b[0m      679.7613        0.0001  0.3150\n",
      "     41      403.4743      699.5317        0.0050  0.2122\n",
      "     42      445.0136      725.7300        0.0049  0.3123\n",
      "     43      446.5849      710.3227        0.0045  0.2176\n",
      "     44      407.8531      \u001b[32m673.0557\u001b[0m     +  0.0040  0.2281\n",
      "     45      386.1603      \u001b[32m672.4143\u001b[0m     +  0.0033  0.3002\n",
      "     46      382.6594      \u001b[32m669.1656\u001b[0m     +  0.0025  0.1998\n",
      "     47      \u001b[36m373.3470\u001b[0m      \u001b[32m668.1025\u001b[0m     +  0.0017  0.2985\n",
      "     48      \u001b[36m369.6754\u001b[0m      670.7998        0.0010  0.2053\n",
      "     49      \u001b[36m366.3229\u001b[0m      671.7833        0.0005  0.3003\n",
      "     50      \u001b[36m364.7185\u001b[0m      672.2110        0.0001  0.2010\n",
      "     51      390.6686      685.1528        0.0050  0.3071\n",
      "     52      429.9148      715.6565        0.0049  0.2021\n",
      "     53      437.0131      695.4641        0.0045  0.2353\n",
      "     54      400.9454      \u001b[32m659.8578\u001b[0m     +  0.0040  0.2971\n",
      "     55      376.3174      661.1921        0.0033  0.3373\n",
      "     56      373.7970      \u001b[32m659.6163\u001b[0m     +  0.0025  0.5248\n",
      "     57      365.0265      660.3470        0.0017  0.4919\n",
      "     58      \u001b[36m361.3395\u001b[0m      663.6163        0.0010  0.3131\n",
      "     59      \u001b[36m358.0324\u001b[0m      664.6418        0.0005  0.2161\n",
      "     60      \u001b[36m356.4910\u001b[0m      665.1470        0.0001  0.3077\n",
      "     61      381.2532      676.3111        0.0050  0.2242\n",
      "     62      420.2256      698.6636        0.0049  0.2248\n",
      "     63      428.4393      689.2775        0.0045  0.3119\n",
      "     64      394.2042      \u001b[32m647.7926\u001b[0m     +  0.0040  0.2143\n",
      "     65      367.5300      648.1170        0.0033  0.3592\n",
      "     66      365.1063      648.8801        0.0025  0.1968\n",
      "     67      \u001b[36m356.4757\u001b[0m      651.3288        0.0017  0.3250\n",
      "     68      \u001b[36m352.9166\u001b[0m      655.7659        0.0010  0.2077\n",
      "     69      \u001b[36m349.6704\u001b[0m      657.0097        0.0005  0.3160\n",
      "     70      \u001b[36m348.2553\u001b[0m      657.7568        0.0001  0.2122\n",
      "     71      372.3696      667.1171        0.0050  0.2167\n",
      "     72      409.9953      674.3110        0.0049  0.3237\n",
      "     73      421.2872      683.7845        0.0045  0.1989\n",
      "     74      390.2502      \u001b[32m629.8157\u001b[0m     +  0.0040  0.3080\n",
      "     75      359.9122      640.6145        0.0033  0.2124\n",
      "     76      358.8881      642.1416        0.0025  0.3069\n",
      "     77      350.9195      645.4726        0.0017  0.2294\n",
      "     78      \u001b[36m347.5647\u001b[0m      652.7776        0.0010  0.2997\n",
      "     79      \u001b[36m344.5991\u001b[0m      654.1764        0.0005  0.2083\n",
      "     80      \u001b[36m343.3518\u001b[0m      655.1658        0.0001  0.2173\n",
      "     81      365.4127      650.6547        0.0050  0.3018\n",
      "     82      396.4359      666.7129        0.0049  0.2087\n",
      "     83      407.5323      664.2880        0.0045  0.2961\n",
      "     84      382.1158      \u001b[32m621.3996\u001b[0m     +  0.0040  0.2099\n",
      "     85      354.8582      635.8537        0.0033  0.3146\n",
      "     86      351.4637      639.9110        0.0025  0.2166\n",
      "     87      345.3080      640.6751        0.0017  0.3138\n",
      "     88      \u001b[36m341.5629\u001b[0m      653.2353        0.0010  0.2056\n",
      "     89      \u001b[36m339.0084\u001b[0m      655.1013        0.0005  0.2036\n",
      "     90      \u001b[36m337.8125\u001b[0m      655.8359        0.0001  0.3045\n",
      "     91      358.7678      640.5250        0.0050  0.1998\n",
      "     92      385.7255      651.4433        0.0049  0.3050\n",
      "     93      399.5248      651.9633        0.0045  0.1997\n",
      "     94      381.4400      \u001b[32m613.6530\u001b[0m     +  0.0040  0.3192\n",
      "     95      350.4923      627.6020        0.0033  0.2161\n",
      "     96      344.1210      635.5174        0.0025  0.2984\n",
      "     97      339.6492      633.5367        0.0017  0.2007\n",
      "     98      \u001b[36m334.8710\u001b[0m      641.1934        0.0010  0.1996\n",
      "     99      \u001b[36m332.3476\u001b[0m      642.7981        0.0005  0.3043\n",
      "    100      \u001b[36m330.9991\u001b[0m      643.3941        0.0001  0.2249\n",
      "    101      353.4497      629.6309        0.0050  0.3073\n",
      "    102      379.8476      625.8876        0.0049  0.1919\n",
      "    103      394.7967      636.1135        0.0045  0.3008\n",
      "    104      388.2816      \u001b[32m580.3551\u001b[0m     +  0.0040  0.2036\n",
      "    105      350.5472      608.0815        0.0033  0.3090\n",
      "    106      334.4836      603.1246        0.0025  0.1980\n",
      "    107      331.9278      598.4464        0.0017  0.1953\n",
      "    108      \u001b[36m324.1715\u001b[0m      596.8622        0.0010  0.3024\n",
      "    109      \u001b[36m321.6020\u001b[0m      603.5872        0.0005  0.2046\n",
      "    110      \u001b[36m319.8591\u001b[0m      603.9615        0.0001  0.3039\n",
      "    111      345.2049      597.0624        0.0050  0.2015\n",
      "    112      365.3618      604.1432        0.0049  0.3111\n",
      "    113      384.7692      637.1260        0.0045  0.2026\n",
      "    114      374.2130      \u001b[32m569.6959\u001b[0m     +  0.0040  0.2997\n",
      "    115      342.1748      595.0759        0.0033  0.1985\n",
      "    116      327.7723      588.2494        0.0025  0.2111\n",
      "    117      322.0912      592.9209        0.0017  0.3109\n",
      "    118      \u001b[36m316.5810\u001b[0m      597.7577        0.0010  0.2007\n",
      "    119      \u001b[36m314.0041\u001b[0m      601.4207        0.0005  0.2999\n",
      "    120      \u001b[36m312.5294\u001b[0m      601.5462        0.0001  0.2277\n",
      "    121      334.8545      584.1016        0.0050  0.3263\n",
      "    122      354.6477      591.6954        0.0049  0.2064\n",
      "    123      371.4345      601.7514        0.0045  0.3289\n",
      "    124      368.2025      \u001b[32m559.8837\u001b[0m     +  0.0040  0.2045\n",
      "    125      338.3775      583.1089        0.0033  0.2070\n",
      "    126      318.9350      605.5612        0.0025  0.2993\n",
      "    127      313.3770      590.6514        0.0017  0.2037\n",
      "    128      \u001b[36m308.9375\u001b[0m      592.1126        0.0010  0.3033\n",
      "    129      \u001b[36m306.2513\u001b[0m      597.4020        0.0005  0.2094\n",
      "    130      \u001b[36m304.8243\u001b[0m      596.8161        0.0001  0.3122\n",
      "    131      326.6648      576.5362        0.0050  0.1993\n",
      "    132      340.8193      576.8422        0.0049  0.3077\n",
      "    133      356.7034      581.3280        0.0045  0.2070\n",
      "    134      361.3162      571.0306        0.0040  0.2050\n",
      "    135      339.6058      561.2189        0.0033  0.3187\n",
      "    136      315.1782      617.9462        0.0025  0.2005\n",
      "    137      306.9497      590.6628        0.0017  0.3211\n",
      "    138      \u001b[36m303.3416\u001b[0m      588.1327        0.0010  0.1966\n",
      "    139      \u001b[36m299.6027\u001b[0m      592.8590        0.0005  0.3177\n",
      "    140      \u001b[36m298.1222\u001b[0m      591.2033        0.0001  0.2315\n",
      "    141      320.6975      563.9115        0.0050  0.3122\n",
      "    142      329.6345      578.8074        0.0049  0.2091\n",
      "    143      347.4490      563.6344        0.0045  0.2065\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m905.6090\u001b[0m      \u001b[32m991.8356\u001b[0m     +  0.0050  0.3290\n",
      "      2      \u001b[36m901.9322\u001b[0m     1209.6575        0.0049  0.2111\n",
      "      3      \u001b[36m662.8551\u001b[0m      \u001b[32m952.4351\u001b[0m     +  0.0045  0.2156\n",
      "      4      691.0481     1006.7476        0.0040  0.3113\n",
      "      5      \u001b[36m615.3777\u001b[0m      \u001b[32m947.3514\u001b[0m     +  0.0033  0.2046\n",
      "      6      \u001b[36m592.6725\u001b[0m      \u001b[32m930.5410\u001b[0m     +  0.0025  0.3143\n",
      "      7      \u001b[36m559.3033\u001b[0m      \u001b[32m911.8325\u001b[0m     +  0.0017  0.2170\n",
      "      8      \u001b[36m535.6096\u001b[0m      \u001b[32m891.9778\u001b[0m     +  0.0010  0.3145\n",
      "      9      \u001b[36m520.9843\u001b[0m      \u001b[32m883.2241\u001b[0m     +  0.0005  0.2091\n",
      "     10      \u001b[36m513.7586\u001b[0m      \u001b[32m880.9071\u001b[0m     +  0.0001  0.2107\n",
      "     11      601.2715      \u001b[32m830.8233\u001b[0m     +  0.0050  0.3232\n",
      "     12      675.3852      979.7410        0.0049  0.2091\n",
      "     13      542.2242      840.1100        0.0045  0.3214\n",
      "     14      \u001b[36m481.2673\u001b[0m      \u001b[32m808.1478\u001b[0m     +  0.0040  0.2138\n",
      "     15      \u001b[36m480.2754\u001b[0m      \u001b[32m800.1737\u001b[0m     +  0.0033  0.3089\n",
      "     16      \u001b[36m453.5633\u001b[0m      \u001b[32m772.8812\u001b[0m     +  0.0025  0.2091\n",
      "     17      \u001b[36m442.4952\u001b[0m      \u001b[32m762.4825\u001b[0m     +  0.0017  0.2080\n",
      "     18      \u001b[36m433.2043\u001b[0m      \u001b[32m756.4983\u001b[0m     +  0.0010  0.3180\n",
      "     19      \u001b[36m428.1854\u001b[0m      \u001b[32m753.4957\u001b[0m     +  0.0005  0.2202\n",
      "     20      \u001b[36m425.5000\u001b[0m      \u001b[32m752.7259\u001b[0m     +  0.0001  0.5022\n",
      "     21      469.4006      758.0022        0.0050  0.2192\n",
      "     22      525.9155      805.8558        0.0049  0.3307\n",
      "     23      501.6332      792.4469        0.0045  0.2153\n",
      "     24      446.6212      \u001b[32m735.8252\u001b[0m     +  0.0040  0.3205\n",
      "     25      428.0912      \u001b[32m731.1302\u001b[0m     +  0.0033  0.2362\n",
      "     26      \u001b[36m421.2689\u001b[0m      \u001b[32m720.8146\u001b[0m     +  0.0025  0.2759\n",
      "     27      \u001b[36m410.0455\u001b[0m      \u001b[32m715.4850\u001b[0m     +  0.0017  0.3813\n",
      "     28      \u001b[36m404.3599\u001b[0m      \u001b[32m713.2501\u001b[0m     +  0.0010  0.2131\n",
      "     29      \u001b[36m400.2715\u001b[0m      \u001b[32m712.4175\u001b[0m     +  0.0005  0.3249\n",
      "     30      \u001b[36m398.1226\u001b[0m      \u001b[32m712.2277\u001b[0m     +  0.0001  0.2119\n",
      "     31      431.7151      728.6735        0.0050  0.3173\n",
      "     32      478.0051      762.7819        0.0049  0.2128\n",
      "     33      470.5909      749.8715        0.0045  0.2077\n",
      "     34      426.7476      \u001b[32m705.8606\u001b[0m     +  0.0040  0.3180\n",
      "     35      406.8043      \u001b[32m701.6150\u001b[0m     +  0.0033  0.2095\n",
      "     36      401.9973      \u001b[32m693.7540\u001b[0m     +  0.0025  0.3138\n",
      "     37      \u001b[36m391.7022\u001b[0m      \u001b[32m692.9789\u001b[0m     +  0.0017  0.2064\n",
      "     38      \u001b[36m387.2289\u001b[0m      \u001b[32m692.1553\u001b[0m     +  0.0010  0.3115\n",
      "     39      \u001b[36m383.4124\u001b[0m      \u001b[32m691.7084\u001b[0m     +  0.0005  0.2015\n",
      "     40      \u001b[36m381.4880\u001b[0m      691.7742        0.0001  0.3006\n",
      "     41      410.8391      704.3593        0.0050  0.1993\n",
      "     42      453.7331      733.2541        0.0049  0.2026\n",
      "     43      453.4943      728.0682        0.0045  0.2951\n",
      "     44      414.0708      \u001b[32m685.3469\u001b[0m     +  0.0040  0.2195\n",
      "     45      392.4470      \u001b[32m677.3557\u001b[0m     +  0.0033  0.5269\n",
      "     46      388.7453      \u001b[32m675.0275\u001b[0m     +  0.0025  0.1994\n",
      "     47      \u001b[36m379.1627\u001b[0m      \u001b[32m674.8417\u001b[0m     +  0.0017  0.3060\n",
      "     48      \u001b[36m374.9744\u001b[0m      675.9120        0.0010  0.2122\n",
      "     49      \u001b[36m371.2858\u001b[0m      676.2675        0.0005  0.2059\n",
      "     50      \u001b[36m369.5027\u001b[0m      676.5684        0.0001  0.3262\n",
      "     51      397.0614      675.0855        0.0050  0.2022\n",
      "     52      436.7882      710.5849        0.0049  0.3047\n",
      "     53      441.8627      726.2875        0.0045  0.2080\n",
      "     54      406.2608      \u001b[32m661.9337\u001b[0m     +  0.0040  0.3044\n",
      "     55      380.9681      667.0832        0.0033  0.2072\n",
      "     56      379.3683      \u001b[32m661.9284\u001b[0m     +  0.0025  0.2127\n",
      "     57      \u001b[36m369.2148\u001b[0m      \u001b[32m660.8851\u001b[0m     +  0.0017  0.3010\n",
      "     58      \u001b[36m365.3353\u001b[0m      664.1763        0.0010  0.2101\n",
      "     59      \u001b[36m361.5956\u001b[0m      665.1315        0.0005  0.3168\n",
      "     60      \u001b[36m359.9118\u001b[0m      665.7014        0.0001  0.2006\n",
      "     61      386.5613      669.9235        0.0050  0.3017\n",
      "     62      423.6005      695.9678        0.0049  0.1976\n",
      "     63      431.7164      691.9088        0.0045  0.3207\n",
      "     64      399.8553      \u001b[32m651.8756\u001b[0m     +  0.0040  0.2264\n",
      "     65      371.5241      \u001b[32m645.0511\u001b[0m     +  0.0033  0.2045\n",
      "     66      370.3644      646.6688        0.0025  0.3033\n",
      "     67      360.9363      649.0955        0.0017  0.2181\n",
      "     68      \u001b[36m356.8367\u001b[0m      652.5570        0.0010  0.3027\n",
      "     69      \u001b[36m353.1643\u001b[0m      652.7419        0.0005  0.2058\n",
      "     70      \u001b[36m351.5633\u001b[0m      653.3140        0.0001  0.3137\n",
      "     71      376.8094      652.5814        0.0050  0.2071\n",
      "     72      410.6238      668.9485        0.0049  0.3068\n",
      "     73      422.1629      692.9602        0.0045  0.1975\n",
      "     74      397.2631      \u001b[32m631.7867\u001b[0m     +  0.0040  0.2007\n",
      "     75      363.0054      640.3104        0.0033  0.3165\n",
      "     76      361.6262      \u001b[32m618.9898\u001b[0m     +  0.0025  0.2041\n",
      "     77      353.7967      625.4428        0.0017  0.3149\n",
      "     78      \u001b[36m347.9638\u001b[0m      626.8928        0.0010  0.2053\n",
      "     79      \u001b[36m344.2734\u001b[0m      627.1193        0.0005  0.3163\n",
      "     80      \u001b[36m342.5548\u001b[0m      627.6940        0.0001  0.2407\n",
      "     81      368.8819      629.7801        0.0050  0.3771\n",
      "     82      398.2886      649.4341        0.0049  0.2265\n",
      "     83      414.1324      650.0569        0.0045  0.2238\n",
      "     84      391.0222      \u001b[32m612.5861\u001b[0m     +  0.0040  0.6009\n",
      "     85      351.2980      \u001b[32m598.1683\u001b[0m     +  0.0033  0.4361\n",
      "     86      352.5705      \u001b[32m597.6993\u001b[0m     +  0.0025  0.5309\n",
      "     87      343.5304      607.9824        0.0017  0.2162\n",
      "     88      \u001b[36m336.4059\u001b[0m      604.2073        0.0010  0.3150\n",
      "     89      \u001b[36m333.2546\u001b[0m      604.6383        0.0005  0.2086\n",
      "     90      \u001b[36m331.7025\u001b[0m      605.6187        0.0001  0.3066\n",
      "     91      359.4052      610.7001        0.0050  0.1993\n",
      "     92      386.1054      629.3647        0.0049  0.2116\n",
      "     93      400.8004      625.0929        0.0045  0.3213\n",
      "     94      377.1359      \u001b[32m571.0615\u001b[0m     +  0.0040  0.2113\n",
      "     95      348.5693      591.0383        0.0033  0.3080\n",
      "     96      338.3120      583.1787        0.0025  0.3226\n",
      "     97      334.1906      590.4796        0.0017  0.4702\n",
      "     98      \u001b[36m328.0069\u001b[0m      593.2578        0.0010  0.3308\n",
      "     99      \u001b[36m325.3380\u001b[0m      596.1697        0.0005  0.3094\n",
      "    100      \u001b[36m323.7476\u001b[0m      596.9151        0.0001  0.2057\n",
      "    101      348.6122      596.0655        0.0050  0.2200\n",
      "    102      373.2970      615.3647        0.0049  0.3247\n",
      "    103      390.4240      609.2130        0.0045  0.2034\n",
      "    104      372.4333      \u001b[32m563.2823\u001b[0m     +  0.0040  0.3135\n",
      "    105      339.2529      574.5369        0.0033  0.2073\n",
      "    106      330.4828      575.7177        0.0025  0.3094\n",
      "    107      326.5644      582.3988        0.0017  0.2070\n",
      "    108      \u001b[36m320.3268\u001b[0m      583.8839        0.0010  0.3068\n",
      "    109      \u001b[36m317.9583\u001b[0m      587.9051        0.0005  0.2042\n",
      "    110      \u001b[36m316.4497\u001b[0m      588.7757        0.0001  0.2047\n",
      "    111      340.1825      588.4850        0.0050  0.3009\n",
      "    112      363.3018      594.0714        0.0049  0.2082\n",
      "    113      378.1179      598.3076        0.0045  0.3380\n",
      "    114      370.3689      \u001b[32m553.1061\u001b[0m     +  0.0040  0.2014\n",
      "    115      336.5704      568.4762        0.0033  0.3133\n",
      "    116      322.6789      570.3030        0.0025  0.2066\n",
      "    117      320.1087      576.4939        0.0017  0.3261\n",
      "    118      \u001b[36m314.0099\u001b[0m      577.9469        0.0010  0.3338\n",
      "    119      \u001b[36m311.7545\u001b[0m      583.2134        0.0005  0.2091\n",
      "    120      \u001b[36m310.2198\u001b[0m      583.8453        0.0001  0.3085\n",
      "    121      333.5477      574.2906        0.0050  0.2091\n",
      "    122      352.8452      587.4308        0.0049  0.3073\n",
      "    123      368.3567      589.5937        0.0045  0.2165\n",
      "    124      363.6970      \u001b[32m543.0760\u001b[0m     +  0.0040  0.3316\n",
      "    125      332.5583      565.4206        0.0033  0.2046\n",
      "    126      316.0340      565.0696        0.0025  0.3048\n",
      "    127      313.9297      571.7872        0.0017  0.2106\n",
      "    128      \u001b[36m308.3379\u001b[0m      574.7895        0.0010  0.2173\n",
      "    129      \u001b[36m306.0931\u001b[0m      579.9820        0.0005  0.3199\n",
      "    130      \u001b[36m304.6634\u001b[0m      580.3815        0.0001  0.2085\n",
      "    131      327.4989      566.4893        0.0050  0.2986\n",
      "    132      343.9613      577.1871        0.0049  0.2084\n",
      "    133      357.2220      576.6165        0.0045  0.3215\n",
      "    134      358.6361      547.2613        0.0040  0.2192\n",
      "    135      330.1438      557.1597        0.0033  0.3107\n",
      "    136      310.7276      565.8520        0.0025  0.2158\n",
      "    137      308.3809      570.6182        0.0017  0.2603\n",
      "    138      \u001b[36m303.5549\u001b[0m      571.2219        0.0010  0.5853\n",
      "    139      \u001b[36m301.2084\u001b[0m      576.9048        0.0005  0.2088\n",
      "    140      \u001b[36m299.8154\u001b[0m      577.1167        0.0001  0.3060\n",
      "    141      321.7281      567.7246        0.0050  0.2024\n",
      "    142      335.8849      567.4763        0.0049  0.3176\n",
      "    143      349.0081      577.0082        0.0045  0.2124\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m946.5341\u001b[0m     \u001b[32m1089.0064\u001b[0m     +  0.0050  0.2067\n",
      "      2      \u001b[36m900.9986\u001b[0m     1209.4310        0.0049  0.3223\n",
      "      3      \u001b[36m687.5087\u001b[0m      \u001b[32m971.4418\u001b[0m     +  0.0045  0.2085\n",
      "      4      705.7521     1045.7421        0.0040  0.3105\n",
      "      5      \u001b[36m629.5380\u001b[0m      \u001b[32m962.0528\u001b[0m     +  0.0033  0.2131\n",
      "      6      \u001b[36m600.0318\u001b[0m      \u001b[32m939.3135\u001b[0m     +  0.0025  0.2078\n",
      "      7      \u001b[36m560.9441\u001b[0m      \u001b[32m910.8981\u001b[0m     +  0.0017  0.3134\n",
      "      8      \u001b[36m535.3914\u001b[0m      \u001b[32m887.6884\u001b[0m     +  0.0010  0.2135\n",
      "      9      \u001b[36m518.9528\u001b[0m      \u001b[32m876.8206\u001b[0m     +  0.0005  0.3164\n",
      "     10      \u001b[36m510.9518\u001b[0m      \u001b[32m873.8176\u001b[0m     +  0.0001  0.2114\n",
      "     11      603.2771      \u001b[32m781.9010\u001b[0m     +  0.0050  0.2144\n",
      "     12      742.8278     1060.5545        0.0049  0.3116\n",
      "     13      570.4494      821.3113        0.0045  0.2178\n",
      "     14      \u001b[36m483.0983\u001b[0m      797.7575        0.0040  0.3439\n",
      "     15      484.3701      797.1784        0.0033  0.2162\n",
      "     16      \u001b[36m452.6385\u001b[0m      \u001b[32m769.1894\u001b[0m     +  0.0025  0.3868\n",
      "     17      \u001b[36m444.5004\u001b[0m      \u001b[32m755.6616\u001b[0m     +  0.0017  0.1978\n",
      "     18      \u001b[36m433.8298\u001b[0m      \u001b[32m749.5861\u001b[0m     +  0.0010  0.3175\n",
      "     19      \u001b[36m428.7647\u001b[0m      \u001b[32m746.3342\u001b[0m     +  0.0005  0.2107\n",
      "     20      \u001b[36m426.0956\u001b[0m      \u001b[32m745.5194\u001b[0m     +  0.0001  0.2108\n",
      "     21      470.8019      759.3197        0.0050  0.3094\n",
      "     22      518.3605      803.1590        0.0049  0.2071\n",
      "     23      493.8880      764.8008        0.0045  0.3121\n",
      "     24      442.0954      \u001b[32m727.4015\u001b[0m     +  0.0040  0.2129\n",
      "     25      427.2061      \u001b[32m723.1920\u001b[0m     +  0.0033  0.3137\n",
      "     26      \u001b[36m417.5291\u001b[0m      \u001b[32m713.9221\u001b[0m     +  0.0025  0.2146\n",
      "     27      \u001b[36m406.9787\u001b[0m      \u001b[32m708.6493\u001b[0m     +  0.0017  0.2129\n",
      "     28      \u001b[36m401.1129\u001b[0m      \u001b[32m706.4386\u001b[0m     +  0.0010  0.3211\n",
      "     29      \u001b[36m397.0664\u001b[0m      \u001b[32m705.6150\u001b[0m     +  0.0005  0.2064\n",
      "     30      \u001b[36m394.9241\u001b[0m      \u001b[32m705.4653\u001b[0m     +  0.0001  0.3062\n",
      "     31      430.6168      719.0259        0.0050  0.2067\n",
      "     32      478.7724      755.7746        0.0049  0.3092\n",
      "     33      471.3731      744.6499        0.0045  0.2053\n",
      "     34      425.7434      \u001b[32m694.6637\u001b[0m     +  0.0040  0.3115\n",
      "     35      402.6206      \u001b[32m689.9389\u001b[0m     +  0.0033  0.2081\n",
      "     36      398.2250      \u001b[32m688.5326\u001b[0m     +  0.0025  0.2146\n",
      "     37      \u001b[36m387.6451\u001b[0m      \u001b[32m684.4319\u001b[0m     +  0.0017  0.3151\n",
      "     38      \u001b[36m383.1631\u001b[0m      \u001b[32m683.6446\u001b[0m     +  0.0010  0.2080\n",
      "     39      \u001b[36m379.3183\u001b[0m      \u001b[32m683.4418\u001b[0m     +  0.0005  0.3116\n",
      "     40      \u001b[36m377.4198\u001b[0m      683.5726        0.0001  0.2067\n",
      "     41      408.1041      697.6654        0.0050  0.3110\n",
      "     42      453.6163      726.9645        0.0049  0.2039\n",
      "     43      456.1815      716.4787        0.0045  0.1994\n",
      "     44      414.3626      \u001b[32m679.3530\u001b[0m     +  0.0040  0.3227\n",
      "     45      391.1277      \u001b[32m669.5444\u001b[0m     +  0.0033  0.4118\n",
      "     46      383.8374      \u001b[32m663.6181\u001b[0m     +  0.0025  0.3052\n",
      "     47      \u001b[36m374.9130\u001b[0m      \u001b[32m663.2063\u001b[0m     +  0.0017  0.2018\n",
      "     48      \u001b[36m370.5834\u001b[0m      663.8375        0.0010  0.3250\n",
      "     49      \u001b[36m367.2753\u001b[0m      664.4121        0.0005  0.2829\n",
      "     50      \u001b[36m365.5732\u001b[0m      664.7665        0.0001  0.2434\n",
      "     51      392.6661      675.8930        0.0050  0.3015\n",
      "     52      433.7857      712.6748        0.0049  0.2035\n",
      "     53      442.9127      693.4071        0.0045  0.3018\n",
      "     54      404.2443      \u001b[32m653.2419\u001b[0m     +  0.0040  0.2050\n",
      "     55      376.8647      \u001b[32m645.0067\u001b[0m     +  0.0033  0.3059\n",
      "     56      374.1436      \u001b[32m642.6584\u001b[0m     +  0.0025  0.2060\n",
      "     57      \u001b[36m364.8494\u001b[0m      \u001b[32m640.8234\u001b[0m     +  0.0017  0.3588\n",
      "     58      \u001b[36m361.0284\u001b[0m      644.8577        0.0010  0.2077\n",
      "     59      \u001b[36m357.6855\u001b[0m      646.2654        0.0005  0.2064\n",
      "     60      \u001b[36m356.1380\u001b[0m      646.8793        0.0001  0.3126\n",
      "     61      381.5233      674.4627        0.0050  0.2000\n",
      "     62      420.6092      686.6967        0.0049  0.3034\n",
      "     63      432.4041      679.1909        0.0045  0.2179\n",
      "     64      397.6088      \u001b[32m628.5820\u001b[0m     +  0.0040  0.5643\n",
      "     65      367.9479      633.2768        0.0033  0.3140\n",
      "     66      365.1181      \u001b[32m627.3009\u001b[0m     +  0.0025  0.3302\n",
      "     67      356.6930      629.0940        0.0017  0.2190\n",
      "     68      \u001b[36m352.7629\u001b[0m      634.6235        0.0010  0.2070\n",
      "     69      \u001b[36m349.6164\u001b[0m      635.9326        0.0005  0.2975\n",
      "     70      \u001b[36m348.1480\u001b[0m      636.5564        0.0001  0.2042\n",
      "     71      372.4986      656.0819        0.0050  0.3123\n",
      "     72      408.1338      673.8516        0.0049  0.2028\n",
      "     73      421.3832      661.0342        0.0045  0.3014\n",
      "     74      395.9550      632.3806        0.0040  0.2109\n",
      "     75      364.2697      633.6235        0.0033  0.2996\n",
      "     76      359.1397      635.5270        0.0025  0.2080\n",
      "     77      351.8793      631.4206        0.0017  0.1973\n",
      "     78      \u001b[36m347.7168\u001b[0m      640.2400        0.0010  0.3082\n",
      "     79      \u001b[36m344.6967\u001b[0m      642.3945        0.0005  0.1975\n",
      "     80      \u001b[36m343.3004\u001b[0m      643.0000        0.0001  0.2981\n",
      "     81      364.2172      631.9019        0.0050  0.2148\n",
      "     82      396.3379      659.0404        0.0049  0.3167\n",
      "     83      405.9258      655.6292        0.0045  0.1993\n",
      "     84      398.2751      638.2654        0.0040  0.3145\n",
      "     85      359.3113      635.3778        0.0033  0.1984\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m906.6196\u001b[0m      \u001b[32m927.7069\u001b[0m     +  0.0050  0.2306\n",
      "      2      959.9328     1287.2816        0.0049  0.3429\n",
      "      3      \u001b[36m674.5742\u001b[0m      \u001b[32m924.5365\u001b[0m     +  0.0045  0.2058\n",
      "      4      718.1568     1006.4956        0.0040  0.2067\n",
      "      5      \u001b[36m631.5063\u001b[0m      960.7539        0.0033  0.3148\n",
      "      6      \u001b[36m607.6986\u001b[0m      \u001b[32m918.6101\u001b[0m     +  0.0025  0.2098\n",
      "      7      \u001b[36m573.2123\u001b[0m      \u001b[32m901.6553\u001b[0m     +  0.0017  0.3167\n",
      "      8      \u001b[36m547.0714\u001b[0m      \u001b[32m880.5429\u001b[0m     +  0.0010  0.2082\n",
      "      9      \u001b[36m532.7235\u001b[0m      \u001b[32m870.6760\u001b[0m     +  0.0005  0.3054\n",
      "     10      \u001b[36m525.5137\u001b[0m      \u001b[32m868.1532\u001b[0m     +  0.0001  0.2046\n",
      "     11      611.9446      \u001b[32m828.7815\u001b[0m     +  0.0050  0.3183\n",
      "     12      663.2639      943.1899        0.0049  0.2172\n",
      "     13      529.2379      \u001b[32m802.0325\u001b[0m     +  0.0045  0.2610\n",
      "     14      \u001b[36m490.2499\u001b[0m      \u001b[32m791.0300\u001b[0m     +  0.0040  0.3139\n",
      "     15      \u001b[36m479.6047\u001b[0m      \u001b[32m775.2351\u001b[0m     +  0.0033  0.2051\n",
      "     16      \u001b[36m455.2371\u001b[0m      \u001b[32m753.3715\u001b[0m     +  0.0025  0.3105\n",
      "     17      \u001b[36m445.5302\u001b[0m      \u001b[32m743.1972\u001b[0m     +  0.0017  0.2219\n",
      "     18      \u001b[36m436.3645\u001b[0m      \u001b[32m738.1194\u001b[0m     +  0.0010  0.3408\n",
      "     19      \u001b[36m431.5287\u001b[0m      \u001b[32m735.6240\u001b[0m     +  0.0005  0.2274\n",
      "     20      \u001b[36m428.9330\u001b[0m      \u001b[32m734.9853\u001b[0m     +  0.0001  0.2085\n",
      "     21      470.9835      758.8519        0.0050  0.3246\n",
      "     22      516.5353      807.3549        0.0049  0.2520\n",
      "     23      488.7774      763.8015        0.0045  0.3209\n",
      "     24      441.6292      \u001b[32m722.6200\u001b[0m     +  0.0040  0.2208\n",
      "     25      430.0455      \u001b[32m719.9766\u001b[0m     +  0.0033  0.3819\n",
      "     26      \u001b[36m419.7115\u001b[0m      \u001b[32m709.1939\u001b[0m     +  0.0025  0.3178\n",
      "     27      \u001b[36m409.9485\u001b[0m      \u001b[32m704.2095\u001b[0m     +  0.0017  0.3140\n",
      "     28      \u001b[36m404.1118\u001b[0m      \u001b[32m702.1149\u001b[0m     +  0.0010  0.2130\n",
      "     29      \u001b[36m400.2041\u001b[0m      \u001b[32m701.3843\u001b[0m     +  0.0005  0.2091\n",
      "     30      \u001b[36m398.0970\u001b[0m      \u001b[32m701.2623\u001b[0m     +  0.0001  0.3180\n",
      "     31      430.8302      722.5360        0.0050  0.2069\n",
      "     32      475.2517      764.3310        0.0049  0.3049\n",
      "     33      470.4756      736.1494        0.0045  0.2093\n",
      "     34      422.7806      \u001b[32m693.9352\u001b[0m     +  0.0040  0.3167\n",
      "     35      405.4934      \u001b[32m693.1529\u001b[0m     +  0.0033  0.2161\n",
      "     36      400.0493      \u001b[32m686.4928\u001b[0m     +  0.0025  0.2122\n",
      "     37      \u001b[36m389.9042\u001b[0m      \u001b[32m682.8756\u001b[0m     +  0.0017  0.3244\n",
      "     38      \u001b[36m385.5681\u001b[0m      683.6664        0.0010  0.2097\n",
      "     39      \u001b[36m382.0453\u001b[0m      684.1394        0.0005  0.3032\n",
      "     40      \u001b[36m380.2499\u001b[0m      684.3903        0.0001  0.2239\n",
      "     41      407.7487      702.4490        0.0050  0.3067\n",
      "     42      447.7225      732.9162        0.0049  0.1978\n",
      "     43      450.2172      711.9234        0.0045  0.2085\n",
      "     44      409.4745      \u001b[32m675.3023\u001b[0m     +  0.0040  0.5364\n",
      "     45      390.1541      \u001b[32m674.7346\u001b[0m     +  0.0033  0.4738\n",
      "     46      386.3753      \u001b[32m670.8673\u001b[0m     +  0.0025  0.3319\n",
      "     47      \u001b[36m376.2354\u001b[0m      \u001b[32m670.0085\u001b[0m     +  0.0017  0.1984\n",
      "     48      \u001b[36m372.3313\u001b[0m      672.8722        0.0010  0.3163\n",
      "     49      \u001b[36m368.8779\u001b[0m      673.9181        0.0005  0.2036\n",
      "     50      \u001b[36m367.2177\u001b[0m      674.3643        0.0001  0.3041\n",
      "     51      397.7131      691.8416        0.0050  0.2044\n",
      "     52      435.4198      722.7167        0.0049  0.2049\n",
      "     53      454.1201      714.2472        0.0045  0.2996\n",
      "     54      407.3957      \u001b[32m664.5635\u001b[0m     +  0.0040  0.2039\n",
      "     55      378.6057      \u001b[32m661.3360\u001b[0m     +  0.0033  0.3256\n",
      "     56      377.9709      \u001b[32m659.3549\u001b[0m     +  0.0025  0.2074\n",
      "     57      \u001b[36m367.1943\u001b[0m      662.2104        0.0017  0.2960\n",
      "     58      \u001b[36m364.0558\u001b[0m      668.4892        0.0010  0.2017\n",
      "     59      \u001b[36m360.5862\u001b[0m      669.4556        0.0005  0.3027\n",
      "     60      \u001b[36m359.0903\u001b[0m      670.0535        0.0001  0.2062\n",
      "     61      384.1795      677.9494        0.0050  0.2014\n",
      "     62      422.9126      709.5043        0.0049  0.3497\n",
      "     63      442.2780      693.5394        0.0045  0.2063\n",
      "     64      398.7224      \u001b[32m651.8962\u001b[0m     +  0.0040  0.3200\n",
      "     65      370.6049      \u001b[32m651.2074\u001b[0m     +  0.0033  0.2050\n",
      "     66      370.4627      652.9048        0.0025  0.3160\n",
      "     67      360.0767      655.1731        0.0017  0.1998\n",
      "     68      \u001b[36m357.0415\u001b[0m      659.9615        0.0010  0.3106\n",
      "     69      \u001b[36m353.6816\u001b[0m      660.6912        0.0005  0.2085\n",
      "     70      \u001b[36m352.2904\u001b[0m      661.4280        0.0001  0.1988\n",
      "     71      374.9971      660.7197        0.0050  0.2991\n",
      "     72      408.6234      680.0313        0.0049  0.2065\n",
      "     73      420.0038      665.5082        0.0045  0.2911\n",
      "     74      387.7857      \u001b[32m635.9432\u001b[0m     +  0.0040  0.2029\n",
      "     75      364.3722      640.8142        0.0033  0.3044\n",
      "     76      361.9581      644.1825        0.0025  0.2071\n",
      "     77      353.2312      645.1177        0.0017  0.3158\n",
      "     78      \u001b[36m349.6521\u001b[0m      650.4751        0.0010  0.2045\n",
      "     79      \u001b[36m346.4446\u001b[0m      651.7652        0.0005  0.1979\n",
      "     80      \u001b[36m345.0144\u001b[0m      652.6033        0.0001  0.3102\n",
      "     81      369.1771      645.0783        0.0050  0.2109\n",
      "     82      400.0897      657.2304        0.0049  0.3175\n",
      "     83      414.4493      673.0885        0.0045  0.1977\n",
      "     84      393.9943      \u001b[32m630.5888\u001b[0m     +  0.0040  0.3496\n",
      "     85      358.6647      649.9631        0.0033  0.2602\n",
      "     86      357.0602      641.0231        0.0025  0.3089\n",
      "     87      349.6100      645.8443        0.0017  0.2020\n",
      "     88      345.1979      647.4811        0.0010  0.2050\n",
      "     89      \u001b[36m341.9375\u001b[0m      646.1074        0.0005  0.3081\n",
      "     90      \u001b[36m340.5089\u001b[0m      646.3296        0.0001  0.1997\n",
      "     91      362.3954      631.1026        0.0050  0.3186\n",
      "     92      391.0755      646.4673        0.0049  0.2022\n",
      "     93      405.5655      639.3434        0.0045  0.3342\n",
      "     94      384.7909      630.7588        0.0040  0.2044\n",
      "     95      358.6466      651.8910        0.0033  0.3109\n",
      "     96      350.0529      649.2781        0.0025  0.1989\n",
      "     97      345.8889      658.0799        0.0017  0.2101\n",
      "     98      341.4510      660.3974        0.0010  0.3063\n",
      "     99      \u001b[36m339.0624\u001b[0m      662.2781        0.0005  0.2022\n",
      "    100      \u001b[36m337.8352\u001b[0m      663.2147        0.0001  0.3133\n",
      "    101      357.8512      633.6839        0.0050  0.2253\n",
      "    102      387.1559      641.5835        0.0049  0.3172\n",
      "    103      398.6598      \u001b[32m628.9753\u001b[0m     +  0.0045  0.2069\n",
      "    104      378.4755      \u001b[32m610.3490\u001b[0m     +  0.0040  0.3155\n",
      "    105      349.1873      615.8089        0.0033  0.2017\n",
      "    106      343.4751      \u001b[32m598.5841\u001b[0m     +  0.0025  0.2104\n",
      "    107      339.0827      618.5860        0.0017  0.3188\n",
      "    108      \u001b[36m331.3563\u001b[0m      612.8473        0.0010  0.2084\n",
      "    109      \u001b[36m328.9803\u001b[0m      616.7521        0.0005  0.3085\n",
      "    110      \u001b[36m327.3851\u001b[0m      617.9519        0.0001  0.2075\n",
      "    111      353.4755      598.7498        0.0050  0.3112\n",
      "    112      378.1241      619.3182        0.0049  0.2085\n",
      "    113      391.3766      627.1880        0.0045  0.2983\n",
      "    114      384.7598      607.1920        0.0040  0.2169\n",
      "    115      346.8986      605.9848        0.0033  0.2096\n",
      "    116      335.8496      \u001b[32m587.6816\u001b[0m     +  0.0025  0.3214\n",
      "    117      332.7969      603.4341        0.0017  0.2007\n",
      "    118      \u001b[36m324.2285\u001b[0m      597.2095        0.0010  0.3021\n",
      "    119      \u001b[36m321.6509\u001b[0m      605.8636        0.0005  0.2105\n",
      "    120      \u001b[36m319.8628\u001b[0m      606.1568        0.0001  0.3197\n",
      "    121      347.6451      \u001b[32m586.3328\u001b[0m     +  0.0050  0.2239\n",
      "    122      368.5040      600.6837        0.0049  0.3056\n",
      "    123      382.9398      603.9120        0.0045  0.2114\n",
      "    124      370.8869      \u001b[32m556.0419\u001b[0m     +  0.0040  0.2214\n",
      "    125      349.0680      608.8009        0.0033  0.2972\n",
      "    126      328.6018      583.5270        0.0025  0.2028\n",
      "    127      321.2217      582.6681        0.0017  0.3195\n",
      "    128      \u001b[36m315.9875\u001b[0m      598.7987        0.0010  0.2098\n",
      "    129      \u001b[36m312.2991\u001b[0m      598.6186        0.0005  0.3025\n",
      "    130      \u001b[36m310.7786\u001b[0m      598.1231        0.0001  0.2005\n",
      "    131      339.4990      578.1618        0.0050  0.3046\n",
      "    132      355.5086      591.5845        0.0049  0.2092\n",
      "    133      369.3212      586.5147        0.0045  0.2015\n",
      "    134      370.5331      563.1184        0.0040  0.3125\n",
      "    135      346.7757      579.7561        0.0033  0.2007\n",
      "    136      320.8576      593.6557        0.0025  0.3179\n",
      "    137      312.6629      575.9613        0.0017  0.2032\n",
      "    138      \u001b[36m308.7679\u001b[0m      592.5502        0.0010  0.3251\n",
      "    139      \u001b[36m304.7120\u001b[0m      592.2539        0.0005  0.3670\n",
      "    140      \u001b[36m303.2380\u001b[0m      590.0643        0.0001  0.4365\n",
      "    141      330.8378      570.6267        0.0050  0.4181\n",
      "    142      341.8677      589.1560        0.0049  0.2110\n",
      "    143      353.6412      581.5063        0.0045  0.3050\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m890.1553\u001b[0m      \u001b[32m987.1636\u001b[0m     +  0.0050  0.6277\n",
      "      2      911.0917     1220.0499        0.0049  0.2308\n",
      "      3      \u001b[36m666.3876\u001b[0m      \u001b[32m936.3180\u001b[0m     +  0.0045  0.3071\n",
      "      4      697.0628     1027.7916        0.0040  0.2027\n",
      "      5      \u001b[36m617.9128\u001b[0m      950.1010        0.0033  0.3185\n",
      "      6      \u001b[36m594.6932\u001b[0m      \u001b[32m929.3576\u001b[0m     +  0.0025  0.2128\n",
      "      7      \u001b[36m559.4431\u001b[0m      \u001b[32m910.3927\u001b[0m     +  0.0017  0.2095\n",
      "      8      \u001b[36m536.7417\u001b[0m      \u001b[32m890.6978\u001b[0m     +  0.0010  0.3175\n",
      "      9      \u001b[36m522.9278\u001b[0m      \u001b[32m881.8692\u001b[0m     +  0.0005  0.2046\n",
      "     10      \u001b[36m515.9645\u001b[0m      \u001b[32m879.5036\u001b[0m     +  0.0001  0.3196\n",
      "     11      595.7981      \u001b[32m832.9345\u001b[0m     +  0.0050  0.2068\n",
      "     12      655.6539      954.9618        0.0049  0.3088\n",
      "     13      531.2647      \u001b[32m817.1945\u001b[0m     +  0.0045  0.2091\n",
      "     14      \u001b[36m480.0546\u001b[0m      \u001b[32m791.6585\u001b[0m     +  0.0040  0.2111\n",
      "     15      \u001b[36m474.1015\u001b[0m      \u001b[32m781.3569\u001b[0m     +  0.0033  0.3155\n",
      "     16      \u001b[36m449.5937\u001b[0m      \u001b[32m754.4035\u001b[0m     +  0.0025  0.2138\n",
      "     17      \u001b[36m439.2888\u001b[0m      \u001b[32m744.3379\u001b[0m     +  0.0017  0.3237\n",
      "     18      \u001b[36m430.1893\u001b[0m      \u001b[32m738.7775\u001b[0m     +  0.0010  0.3424\n",
      "     19      \u001b[36m425.4008\u001b[0m      \u001b[32m736.0245\u001b[0m     +  0.0005  0.5383\n",
      "     20      \u001b[36m422.8083\u001b[0m      \u001b[32m735.3060\u001b[0m     +  0.0001  0.2070\n",
      "     21      464.0731      751.1990        0.0050  0.3074\n",
      "     22      515.1362      803.8461        0.0049  0.2143\n",
      "     23      492.4019      774.0337        0.0045  0.2100\n",
      "     24      442.0573      \u001b[32m717.8296\u001b[0m     +  0.0040  0.3141\n",
      "     25      425.2076      \u001b[32m715.6140\u001b[0m     +  0.0033  0.2446\n",
      "     26      \u001b[36m417.3635\u001b[0m      \u001b[32m705.8332\u001b[0m     +  0.0025  0.5124\n",
      "     27      \u001b[36m406.7670\u001b[0m      \u001b[32m698.9549\u001b[0m     +  0.0017  0.3463\n",
      "     28      \u001b[36m401.4710\u001b[0m      \u001b[32m695.5392\u001b[0m     +  0.0010  0.3088\n",
      "     29      \u001b[36m397.5149\u001b[0m      \u001b[32m694.2716\u001b[0m     +  0.0005  0.2144\n",
      "     30      \u001b[36m395.4540\u001b[0m      \u001b[32m693.9589\u001b[0m     +  0.0001  0.2060\n",
      "     31      427.4094      717.3058        0.0050  0.3109\n",
      "     32      470.3998      757.6560        0.0049  0.2076\n",
      "     33      465.6933      732.0521        0.0045  0.3173\n",
      "     34      424.2106      \u001b[32m686.4034\u001b[0m     +  0.0040  0.2124\n",
      "     35      404.1419      \u001b[32m680.7009\u001b[0m     +  0.0033  0.3246\n",
      "     36      398.7422      \u001b[32m677.1708\u001b[0m     +  0.0025  0.2052\n",
      "     37      \u001b[36m388.2317\u001b[0m      \u001b[32m671.7860\u001b[0m     +  0.0017  0.2055\n",
      "     38      \u001b[36m383.8197\u001b[0m      \u001b[32m670.1425\u001b[0m     +  0.0010  0.3071\n",
      "     39      \u001b[36m379.9750\u001b[0m      \u001b[32m670.0960\u001b[0m     +  0.0005  0.2029\n",
      "     40      \u001b[36m378.0739\u001b[0m      670.2080        0.0001  0.3133\n",
      "     41      406.4309      702.9515        0.0050  0.1978\n",
      "     42      449.6789      737.0129        0.0049  0.2956\n",
      "     43      449.9995      706.7246        0.0045  0.2128\n",
      "     44      410.7277      \u001b[32m668.0799\u001b[0m     +  0.0040  0.3551\n",
      "     45      389.6877      \u001b[32m663.2203\u001b[0m     +  0.0033  0.2844\n",
      "     46      386.2449      \u001b[32m661.9131\u001b[0m     +  0.0025  0.1962\n",
      "     47      \u001b[36m375.8553\u001b[0m      \u001b[32m659.9367\u001b[0m     +  0.0017  0.3067\n",
      "     48      \u001b[36m372.0327\u001b[0m      662.0707        0.0010  0.2050\n",
      "     49      \u001b[36m368.3968\u001b[0m      662.5955        0.0005  0.3147\n",
      "     50      \u001b[36m366.6813\u001b[0m      662.9568        0.0001  0.2005\n",
      "     51      393.1743      680.6554        0.0050  0.2981\n",
      "     52      432.1674      718.8722        0.0049  0.2061\n",
      "     53      440.0605      693.1306        0.0045  0.3058\n",
      "     54      401.8892      \u001b[32m656.0642\u001b[0m     +  0.0040  0.2136\n",
      "     55      379.3652      \u001b[32m650.6620\u001b[0m     +  0.0033  0.2044\n",
      "     56      376.1219      \u001b[32m648.3485\u001b[0m     +  0.0025  0.3130\n",
      "     57      \u001b[36m366.1785\u001b[0m      648.8030        0.0017  0.2070\n",
      "     58      \u001b[36m362.4844\u001b[0m      651.6694        0.0010  0.3050\n",
      "     59      \u001b[36m358.9942\u001b[0m      652.1955        0.0005  0.2352\n",
      "     60      \u001b[36m357.3574\u001b[0m      652.6313        0.0001  0.3052\n",
      "     61      384.6900      678.3931        0.0050  0.2076\n",
      "     62      423.7324      697.7243        0.0049  0.3113\n",
      "     63      444.2718      716.2447        0.0045  0.2323\n",
      "     64      399.2302      \u001b[32m640.3041\u001b[0m     +  0.0040  0.2266\n",
      "     65      370.2142      646.2966        0.0033  0.2974\n",
      "     66      370.3826      \u001b[32m634.6829\u001b[0m     +  0.0025  0.1976\n",
      "     67      359.1366      640.2174        0.0017  0.3057\n",
      "     68      \u001b[36m356.2742\u001b[0m      648.3785        0.0010  0.2044\n",
      "     69      \u001b[36m352.6963\u001b[0m      648.2442        0.0005  0.3088\n",
      "     70      \u001b[36m351.2331\u001b[0m      648.6175        0.0001  0.2062\n",
      "     71      374.3500      662.5745        0.0050  0.3064\n",
      "     72      409.3102      680.9198        0.0049  0.2100\n",
      "     73      417.9616      665.2527        0.0045  0.2042\n",
      "     74      383.4102      \u001b[32m617.4341\u001b[0m     +  0.0040  0.3159\n",
      "     75      363.3940      624.7617        0.0033  0.2027\n",
      "     76      359.6877      \u001b[32m610.2033\u001b[0m     +  0.0025  0.3016\n",
      "     77      \u001b[36m350.7695\u001b[0m      613.3252        0.0017  0.2101\n",
      "     78      \u001b[36m345.8071\u001b[0m      615.6470        0.0010  0.3064\n",
      "     79      \u001b[36m342.3061\u001b[0m      615.5460        0.0005  0.1916\n",
      "     80      \u001b[36m340.6677\u001b[0m      615.8196        0.0001  0.3002\n",
      "     81      365.7481      634.3657        0.0050  0.2030\n",
      "     82      392.9386      642.1345        0.0049  0.2022\n",
      "     83      411.2733      674.2662        0.0045  0.3295\n",
      "     84      406.0593      \u001b[32m592.7505\u001b[0m     +  0.0040  0.2127\n",
      "     85      357.1212      602.7884        0.0033  0.3017\n",
      "     86      345.4559      \u001b[32m588.8933\u001b[0m     +  0.0025  0.2049\n",
      "     87      342.3318      597.3769        0.0017  0.2983\n",
      "     88      \u001b[36m333.9849\u001b[0m      593.1013        0.0010  0.2067\n",
      "     89      \u001b[36m331.9544\u001b[0m      598.3514        0.0005  0.3062\n",
      "     90      \u001b[36m330.3811\u001b[0m      599.5523        0.0001  0.2018\n",
      "     91      352.7325      605.6494        0.0050  0.2112\n",
      "     92      378.0121      628.1765        0.0049  0.3052\n",
      "     93      398.6568      638.5251        0.0045  0.2066\n",
      "     94      378.4935      \u001b[32m562.4590\u001b[0m     +  0.0040  0.3096\n",
      "     95      344.8279      580.8237        0.0033  0.2035\n",
      "     96      335.0535      575.2151        0.0025  0.3081\n",
      "     97      330.6505      581.3127        0.0017  0.2045\n",
      "     98      \u001b[36m324.9826\u001b[0m      590.2714        0.0010  0.3008\n",
      "     99      \u001b[36m322.7337\u001b[0m      594.0610        0.0005  0.2063\n",
      "    100      \u001b[36m321.3002\u001b[0m      594.6007        0.0001  0.2055\n",
      "    101      343.0430      593.1405        0.0050  0.3128\n",
      "    102      365.8374      616.0924        0.0049  0.2111\n",
      "    103      390.1299      624.2485        0.0045  0.3307\n",
      "    104      375.6439      \u001b[32m557.1239\u001b[0m     +  0.0040  0.2011\n",
      "    105      339.7726      573.5913        0.0033  0.3060\n",
      "    106      327.2186      571.5915        0.0025  0.2212\n",
      "    107      323.6239      572.7996        0.0017  0.3033\n",
      "    108      \u001b[36m318.2577\u001b[0m      584.4907        0.0010  0.2138\n",
      "    109      \u001b[36m316.1385\u001b[0m      587.8494        0.0005  0.2061\n",
      "    110      \u001b[36m314.7971\u001b[0m      588.0163        0.0001  0.3032\n",
      "    111      335.8665      573.4728        0.0050  0.2013\n",
      "    112      355.2408      602.4234        0.0049  0.3008\n",
      "    113      379.3414      619.4748        0.0045  0.1989\n",
      "    114      372.7155      \u001b[32m543.9172\u001b[0m     +  0.0040  0.3130\n",
      "    115      335.7028      565.2469        0.0033  0.1988\n",
      "    116      320.4215      592.7576        0.0025  0.3001\n",
      "    117      317.7839      569.9334        0.0017  0.2111\n",
      "    118      \u001b[36m312.4310\u001b[0m      579.6282        0.0010  0.2233\n",
      "    119      \u001b[36m310.2826\u001b[0m      585.9997        0.0005  0.3000\n",
      "    120      \u001b[36m308.9538\u001b[0m      585.9539        0.0001  0.2040\n",
      "    121      330.0289      567.0210        0.0050  0.3068\n",
      "    122      346.4158      583.4797        0.0049  0.2085\n",
      "    123      367.5615      616.2416        0.0045  0.3163\n",
      "    124      367.6741      \u001b[32m540.6791\u001b[0m     +  0.0040  0.2009\n",
      "    125      334.3733      560.8923        0.0033  0.3005\n",
      "    126      315.1836      602.5177        0.0025  0.2100\n",
      "    127      311.2262      573.1415        0.0017  0.1984\n",
      "    128      \u001b[36m306.9989\u001b[0m      577.3499        0.0010  0.2985\n",
      "    129      \u001b[36m304.6632\u001b[0m      584.3299        0.0005  0.2086\n",
      "    130      \u001b[36m303.3600\u001b[0m      584.0306        0.0001  0.3045\n",
      "    131      324.0778      571.4204        0.0050  0.2082\n",
      "    132      338.5807      556.6032        0.0049  0.3196\n",
      "    133      356.0095      603.1815        0.0045  0.2048\n",
      "    134      362.5641      542.5712        0.0040  0.3150\n",
      "    135      336.0376      553.9465        0.0033  0.2471\n",
      "    136      312.3936      638.6155        0.0025  0.2003\n",
      "    137      306.5512      615.1019        0.0017  0.3120\n",
      "    138      \u001b[36m303.0691\u001b[0m      617.1132        0.0010  0.2018\n",
      "    139      \u001b[36m299.8993\u001b[0m      616.9776        0.0005  0.3175\n",
      "    140      \u001b[36m298.6147\u001b[0m      614.5774        0.0001  0.2047\n",
      "    141      318.6514      570.1247        0.0050  0.2978\n",
      "    142      330.8176      555.1719        0.0049  0.2143\n",
      "    143      344.4309      565.6985        0.0045  0.3225\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m943.5625\u001b[0m      \u001b[32m977.0776\u001b[0m     +  0.0050  0.3316\n",
      "      2      \u001b[36m914.1303\u001b[0m     1251.9369        0.0049  0.2134\n",
      "      3      \u001b[36m680.4128\u001b[0m      \u001b[32m946.9716\u001b[0m     +  0.0045  0.2106\n",
      "      4      715.6798     1026.8456        0.0040  0.3180\n",
      "      5      \u001b[36m640.9491\u001b[0m      976.4065        0.0033  0.2092\n",
      "      6      \u001b[36m624.0372\u001b[0m      \u001b[32m945.5075\u001b[0m     +  0.0025  0.3167\n",
      "      7      \u001b[36m597.5669\u001b[0m      \u001b[32m937.6584\u001b[0m     +  0.0017  0.2155\n",
      "      8      \u001b[36m577.5977\u001b[0m      \u001b[32m923.8992\u001b[0m     +  0.0010  0.3144\n",
      "      9      \u001b[36m565.7053\u001b[0m      \u001b[32m916.1701\u001b[0m     +  0.0005  0.2123\n",
      "     10      \u001b[36m559.5336\u001b[0m      \u001b[32m914.0084\u001b[0m     +  0.0001  0.3089\n",
      "     11      642.9114      916.4903        0.0050  0.2050\n",
      "     12      644.9441      945.7960        0.0049  0.2119\n",
      "     13      \u001b[36m541.6965\u001b[0m      \u001b[32m837.5739\u001b[0m     +  0.0045  0.3180\n",
      "     14      \u001b[36m519.1904\u001b[0m      \u001b[32m831.0471\u001b[0m     +  0.0040  0.2096\n",
      "     15      \u001b[36m491.9962\u001b[0m      \u001b[32m788.2466\u001b[0m     +  0.0033  0.3131\n",
      "     16      \u001b[36m467.5356\u001b[0m      \u001b[32m767.4184\u001b[0m     +  0.0025  0.1995\n",
      "     17      \u001b[36m452.9247\u001b[0m      \u001b[32m754.5632\u001b[0m     +  0.0017  0.3162\n",
      "     18      \u001b[36m442.3770\u001b[0m      \u001b[32m747.4664\u001b[0m     +  0.0010  0.2362\n",
      "     19      \u001b[36m436.2326\u001b[0m      \u001b[32m744.0422\u001b[0m     +  0.0005  0.2081\n",
      "     20      \u001b[36m433.1053\u001b[0m      \u001b[32m743.1234\u001b[0m     +  0.0001  0.3119\n",
      "     21      480.8543      763.8605        0.0050  0.2090\n",
      "     22      541.1542      834.0794        0.0049  0.3214\n",
      "     23      506.3164      779.6511        0.0045  0.2072\n",
      "     24      445.1968      \u001b[32m727.2069\u001b[0m     +  0.0040  0.3251\n",
      "     25      436.5264      731.7518        0.0033  0.2309\n",
      "     26      \u001b[36m425.1615\u001b[0m      \u001b[32m717.5631\u001b[0m     +  0.0025  0.3021\n",
      "     27      \u001b[36m416.0089\u001b[0m      \u001b[32m712.1508\u001b[0m     +  0.0017  0.5112\n",
      "     28      \u001b[36m409.9406\u001b[0m      \u001b[32m710.4597\u001b[0m     +  0.0010  0.2120\n",
      "     29      \u001b[36m406.2216\u001b[0m      \u001b[32m710.0573\u001b[0m     +  0.0005  0.3696\n",
      "     30      \u001b[36m404.1839\u001b[0m      \u001b[32m709.9803\u001b[0m     +  0.0001  0.2447\n",
      "     31      435.1693      732.0881        0.0050  0.4146\n",
      "     32      474.4199      761.7921        0.0049  0.2849\n",
      "     33      463.4679      731.9798        0.0045  0.4848\n",
      "     34      425.4296      \u001b[32m701.1795\u001b[0m     +  0.0040  0.2362\n",
      "     35      411.6620      \u001b[32m700.8388\u001b[0m     +  0.0033  0.4564\n",
      "     36      404.8707      \u001b[32m693.5877\u001b[0m     +  0.0025  0.4654\n",
      "     37      \u001b[36m395.6670\u001b[0m      \u001b[32m691.1081\u001b[0m     +  0.0017  0.2214\n",
      "     38      \u001b[36m390.9647\u001b[0m      691.4749        0.0010  0.2979\n",
      "     39      \u001b[36m387.3639\u001b[0m      691.8265        0.0005  0.2162\n",
      "     40      \u001b[36m385.4803\u001b[0m      692.0237        0.0001  0.4754\n",
      "     41      414.6811      707.8169        0.0050  0.3141\n",
      "     42      457.1210      743.0123        0.0049  0.3050\n",
      "     43      456.8480      715.9217        0.0045  0.1965\n",
      "     44      413.0946      \u001b[32m680.8527\u001b[0m     +  0.0040  0.2032\n",
      "     45      395.5385      683.5723        0.0033  0.2978\n",
      "     46      391.2231      \u001b[32m673.9256\u001b[0m     +  0.0025  0.1986\n",
      "     47      \u001b[36m382.2462\u001b[0m      674.2340        0.0017  0.3185\n",
      "     48      \u001b[36m378.2399\u001b[0m      677.1777        0.0010  0.2600\n",
      "     49      \u001b[36m374.9545\u001b[0m      677.9215        0.0005  0.5374\n",
      "     50      \u001b[36m373.2886\u001b[0m      678.3056        0.0001  0.3849\n",
      "     51      399.1278      690.5571        0.0050  0.3637\n",
      "     52      436.7699      713.0053        0.0049  0.2076\n",
      "     53      439.6770      694.7533        0.0045  0.1952\n",
      "     54      403.0495      \u001b[32m670.8409\u001b[0m     +  0.0040  0.3171\n",
      "     55      384.7654      \u001b[32m667.0751\u001b[0m     +  0.0033  0.1991\n",
      "     56      381.4505      \u001b[32m662.4506\u001b[0m     +  0.0025  0.2985\n",
      "     57      \u001b[36m372.3389\u001b[0m      663.2543        0.0017  0.2223\n",
      "     58      \u001b[36m368.9832\u001b[0m      667.6049        0.0010  0.3099\n",
      "     59      \u001b[36m365.6074\u001b[0m      668.3234        0.0005  0.2003\n",
      "     60      \u001b[36m364.0261\u001b[0m      668.6907        0.0001  0.3021\n",
      "     61      388.6887      673.2656        0.0050  0.2172\n",
      "     62      424.8368      697.0645        0.0049  0.2017\n",
      "     63      437.6862      693.4033        0.0045  0.3032\n",
      "     64      403.9789      664.0166        0.0040  0.1976\n",
      "     65      376.5095      671.4336        0.0033  0.2989\n",
      "     66      375.4983      664.0300        0.0025  0.2054\n",
      "     67      366.8091      671.1591        0.0017  0.3079\n",
      "     68      \u001b[36m363.9617\u001b[0m      675.7922        0.0010  0.2178\n",
      "     69      \u001b[36m360.7401\u001b[0m      675.9008        0.0005  0.3038\n",
      "     70      \u001b[36m359.3696\u001b[0m      676.5258        0.0001  0.2152\n",
      "     71      381.6305      667.3051        0.0050  0.2020\n",
      "     72      413.1065      682.6654        0.0049  0.3139\n",
      "     73      421.1941      677.6163        0.0045  0.1990\n",
      "     74      391.1904      \u001b[32m648.7827\u001b[0m     +  0.0040  0.3151\n",
      "     75      369.9876      661.8607        0.0033  0.1955\n",
      "     76      368.4222      649.2762        0.0025  0.3039\n",
      "     77      359.8271      654.2626        0.0017  0.2696\n",
      "     78      \u001b[36m356.5050\u001b[0m      656.1847        0.0010  0.4026\n",
      "     79      \u001b[36m353.1626\u001b[0m      654.4934        0.0005  0.2080\n",
      "     80      \u001b[36m351.5754\u001b[0m      654.4805        0.0001  0.1974\n",
      "     81      374.8360      \u001b[32m643.6326\u001b[0m     +  0.0050  0.2971\n",
      "     82      404.4134      655.4182        0.0049  0.1932\n",
      "     83      416.5510      658.9634        0.0045  0.3112\n",
      "     84      394.2551      652.7467        0.0040  0.2085\n",
      "     85      366.4360      662.0910        0.0033  0.3058\n",
      "     86      363.5260      660.6145        0.0025  0.2104\n",
      "     87      356.6409      669.0197        0.0017  0.3016\n",
      "     88      353.5551      672.2836        0.0010  0.2097\n",
      "     89      \u001b[36m350.6656\u001b[0m      672.1775        0.0005  0.2004\n",
      "     90      \u001b[36m349.4205\u001b[0m      672.9561        0.0001  0.3011\n",
      "     91      370.2948      651.2750        0.0050  0.2045\n",
      "     92      396.8845      647.0681        0.0049  0.3134\n",
      "     93      404.4109      \u001b[32m636.5747\u001b[0m     +  0.0045  0.2036\n",
      "     94      385.3099      \u001b[32m610.8078\u001b[0m     +  0.0040  0.2979\n",
      "     95      357.1733      617.0205        0.0033  0.1926\n",
      "     96      354.0197      615.2372        0.0025  0.3077\n",
      "     97      \u001b[36m346.9225\u001b[0m      621.2779        0.0017  0.2234\n",
      "     98      \u001b[36m341.9989\u001b[0m      624.1832        0.0010  0.1970\n",
      "     99      \u001b[36m339.0759\u001b[0m      625.0458        0.0005  0.2922\n",
      "    100      \u001b[36m337.6305\u001b[0m      625.9168        0.0001  0.2074\n",
      "    101      363.1990      617.2883        0.0050  0.3048\n",
      "    102      387.3193      629.1939        0.0049  0.2196\n",
      "    103      401.4621      649.7520        0.0045  0.3063\n",
      "    104      379.8921      \u001b[32m584.1214\u001b[0m     +  0.0040  0.2056\n",
      "    105      354.2286      604.1925        0.0033  0.3116\n",
      "    106      344.2290      607.1030        0.0025  0.2139\n",
      "    107      339.7292      606.0749        0.0017  0.2044\n",
      "    108      \u001b[36m334.3576\u001b[0m      608.6487        0.0010  0.3040\n",
      "    109      \u001b[36m331.9192\u001b[0m      612.7250        0.0005  0.2021\n",
      "    110      \u001b[36m330.4387\u001b[0m      613.5586        0.0001  0.3167\n",
      "    111      354.5120      602.4457        0.0050  0.2049\n",
      "    112      375.7694      609.4038        0.0049  0.3172\n",
      "    113      392.0885      616.9990        0.0045  0.1984\n",
      "    114      377.3306      \u001b[32m576.1585\u001b[0m     +  0.0040  0.3151\n",
      "    115      346.7006      598.2507        0.0033  0.2129\n",
      "    116      336.4099      589.7039        0.0025  0.2461\n",
      "    117      332.9008      595.7068        0.0017  0.4202\n",
      "    118      \u001b[36m327.0965\u001b[0m      597.2823        0.0010  0.2015\n",
      "    119      \u001b[36m324.7939\u001b[0m      601.9359        0.0005  0.2996\n",
      "    120      \u001b[36m323.3376\u001b[0m      602.7385        0.0001  0.2093\n",
      "    121      346.8106      591.3282        0.0050  0.3076\n",
      "    122      366.6569      598.5261        0.0049  0.2018\n",
      "    123      381.2511      602.8984        0.0045  0.3029\n",
      "    124      373.1385      \u001b[32m564.4145\u001b[0m     +  0.0040  0.2030\n",
      "    125      342.4775      593.7381        0.0033  0.1996\n",
      "    126      330.2703      580.7014        0.0025  0.3092\n",
      "    127      326.7497      589.6733        0.0017  0.2033\n",
      "    128      \u001b[36m321.6948\u001b[0m      591.7345        0.0010  0.3132\n",
      "    129      \u001b[36m319.5092\u001b[0m      595.1073        0.0005  0.2045\n",
      "    130      \u001b[36m318.1898\u001b[0m      595.7059        0.0001  0.2999\n",
      "    131      339.7446      584.0653        0.0050  0.2065\n",
      "    132      356.8387      591.0413        0.0049  0.3085\n",
      "    133      371.8744      589.7629        0.0045  0.1956\n",
      "    134      369.5277      \u001b[32m562.8917\u001b[0m     +  0.0040  0.2081\n",
      "    135      339.1437      583.2937        0.0033  0.3155\n",
      "    136      323.5116      580.6363        0.0025  0.2142\n",
      "    137      320.6715      584.5237        0.0017  0.3058\n",
      "    138      \u001b[36m315.8197\u001b[0m      583.0483        0.0010  0.1896\n",
      "    139      \u001b[36m313.7586\u001b[0m      589.0648        0.0005  0.3003\n",
      "    140      \u001b[36m312.4425\u001b[0m      589.3289        0.0001  0.2000\n",
      "    141      333.1860      577.9396        0.0050  0.3055\n",
      "    142      348.7943      580.5732        0.0049  0.2105\n",
      "    143      361.1273      588.9073        0.0045  0.2104\n",
      "    144      363.8328      \u001b[32m554.1512\u001b[0m     +  0.0040  0.3102\n",
      "    145      338.2824      576.0396        0.0033  0.2096\n",
      "    146      319.2285      573.9965        0.0025  0.3022\n",
      "    147      315.3508      581.5101        0.0017  0.2067\n",
      "    148      \u001b[36m311.1280\u001b[0m      580.6474        0.0010  0.3247\n",
      "    149      \u001b[36m308.6989\u001b[0m      585.3982        0.0005  0.2066\n",
      "    150      \u001b[36m307.3810\u001b[0m      584.8649        0.0001  0.3090\n",
      "    151      327.0162      570.8565        0.0050  0.2061\n",
      "    152      340.1740      572.2083        0.0049  0.2011\n",
      "    153      352.6431      575.1542        0.0045  0.3240\n",
      "    154      353.4533      \u001b[32m550.0192\u001b[0m     +  0.0040  0.2099\n",
      "    155      337.7530      564.7755        0.0033  0.3236\n",
      "    156      315.6892      581.4895        0.0025  0.2212\n",
      "    157      309.4859      577.7016        0.0017  0.3132\n",
      "    158      \u001b[36m306.5599\u001b[0m      580.8583        0.0010  0.2035\n",
      "    159      \u001b[36m303.6843\u001b[0m      586.3368        0.0005  0.2970\n",
      "    160      \u001b[36m302.4126\u001b[0m      585.4658        0.0001  0.2041\n",
      "    161      321.1401      570.8907        0.0050  0.2098\n",
      "    162      332.6057      566.4121        0.0049  0.3231\n",
      "    163      343.3914      572.1468        0.0045  0.1989\n",
      "    164      346.3299      \u001b[32m547.8902\u001b[0m     +  0.0040  0.3199\n",
      "    165      332.9506      552.1010        0.0033  0.2006\n",
      "    166      312.7548      599.4612        0.0025  0.3066\n",
      "    167      304.6807      584.0643        0.0017  0.2060\n",
      "    168      302.7099      583.0666        0.0010  0.3008\n",
      "    169      \u001b[36m299.1491\u001b[0m      585.1762        0.0005  0.2058\n",
      "    170      \u001b[36m297.9334\u001b[0m      584.7787        0.0001  0.2194\n",
      "    171      316.6291      572.8984        0.0050  0.3249\n",
      "    172      327.9411      571.4958        0.0049  0.2015\n",
      "    173      337.3005      572.1128        0.0045  0.3210\n",
      "    174      341.0316      554.3538        0.0040  0.2074\n",
      "    175      330.2107      554.4617        0.0033  0.3174\n",
      "    176      309.7053      595.3845        0.0025  0.2091\n",
      "    177      301.5101      585.2817        0.0017  0.2963\n",
      "    178      299.5445      585.1244        0.0010  0.2024\n",
      "    179      \u001b[36m295.8591\u001b[0m      585.0617        0.0005  0.2412\n",
      "    180      \u001b[36m294.6933\u001b[0m      584.7339        0.0001  0.3033\n",
      "    181      312.3596      573.4157        0.0050  0.1949\n",
      "    182      322.2131      569.1261        0.0049  0.3018\n",
      "    183      331.3712      571.5810        0.0045  0.1998\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m881.5166\u001b[0m      \u001b[32m975.8349\u001b[0m     +  0.0050  0.2123\n",
      "      2      910.2136     1208.1966        0.0049  0.4480\n",
      "      3      \u001b[36m663.8597\u001b[0m      \u001b[32m960.6334\u001b[0m     +  0.0045  0.2134\n",
      "      4      690.7549      985.8391        0.0040  0.2088\n",
      "      5      \u001b[36m613.1874\u001b[0m      \u001b[32m927.8260\u001b[0m     +  0.0033  0.3319\n",
      "      6      \u001b[36m588.8722\u001b[0m      \u001b[32m909.5046\u001b[0m     +  0.0025  0.2370\n",
      "      7      \u001b[36m556.3727\u001b[0m      \u001b[32m882.4333\u001b[0m     +  0.0017  0.3198\n",
      "      8      \u001b[36m532.5983\u001b[0m      \u001b[32m861.6475\u001b[0m     +  0.0010  0.2073\n",
      "      9      \u001b[36m518.6592\u001b[0m      \u001b[32m853.1122\u001b[0m     +  0.0005  0.3089\n",
      "     10      \u001b[36m511.7770\u001b[0m      \u001b[32m850.7099\u001b[0m     +  0.0001  0.2085\n",
      "     11      600.1598      \u001b[32m808.9337\u001b[0m     +  0.0050  0.2040\n",
      "     12      677.1550     1014.7946        0.0049  0.3014\n",
      "     13      532.3038      \u001b[32m798.7859\u001b[0m     +  0.0045  0.2210\n",
      "     14      \u001b[36m488.0470\u001b[0m      \u001b[32m795.3585\u001b[0m     +  0.0040  0.3098\n",
      "     15      \u001b[36m480.6131\u001b[0m      797.7256        0.0033  0.2081\n",
      "     16      \u001b[36m455.5674\u001b[0m      \u001b[32m764.4537\u001b[0m     +  0.0025  0.3147\n",
      "     17      \u001b[36m446.0904\u001b[0m      \u001b[32m753.3380\u001b[0m     +  0.0017  0.2078\n",
      "     18      \u001b[36m436.7961\u001b[0m      \u001b[32m749.3532\u001b[0m     +  0.0010  0.3253\n",
      "     19      \u001b[36m431.9745\u001b[0m      \u001b[32m746.9711\u001b[0m     +  0.0005  0.2181\n",
      "     20      \u001b[36m429.3886\u001b[0m      \u001b[32m746.3014\u001b[0m     +  0.0001  0.2187\n",
      "     21      473.0673      769.7592        0.0050  0.3063\n",
      "     22      520.1072      825.9247        0.0049  0.2058\n",
      "     23      490.4808      768.8525        0.0045  0.3210\n",
      "     24      442.5801      \u001b[32m729.4841\u001b[0m     +  0.0040  0.2117\n",
      "     25      432.8660      \u001b[32m727.0424\u001b[0m     +  0.0033  0.3097\n",
      "     26      \u001b[36m421.6614\u001b[0m      \u001b[32m714.6268\u001b[0m     +  0.0025  0.2093\n",
      "     27      \u001b[36m412.1261\u001b[0m      \u001b[32m709.7059\u001b[0m     +  0.0017  0.2134\n",
      "     28      \u001b[36m406.0942\u001b[0m      \u001b[32m707.2273\u001b[0m     +  0.0010  0.3312\n",
      "     29      \u001b[36m402.2590\u001b[0m      \u001b[32m706.1511\u001b[0m     +  0.0005  0.2119\n",
      "     30      \u001b[36m400.1737\u001b[0m      \u001b[32m705.8674\u001b[0m     +  0.0001  0.3059\n",
      "     31      433.1855      742.8950        0.0050  0.2042\n",
      "     32      477.1846      776.4271        0.0049  0.3199\n",
      "     33      464.8144      742.5120        0.0045  0.2058\n",
      "     34      423.0585      \u001b[32m696.8414\u001b[0m     +  0.0040  0.2176\n",
      "     35      408.5730      698.6479        0.0033  0.3077\n",
      "     36      402.0779      \u001b[32m689.1119\u001b[0m     +  0.0025  0.2219\n",
      "     37      \u001b[36m391.7758\u001b[0m      \u001b[32m687.5921\u001b[0m     +  0.0017  0.3004\n",
      "     38      \u001b[36m387.0721\u001b[0m      687.7351        0.0010  0.2088\n",
      "     39      \u001b[36m383.3331\u001b[0m      \u001b[32m687.5800\u001b[0m     +  0.0005  0.3055\n",
      "     40      \u001b[36m381.4157\u001b[0m      687.6415        0.0001  0.2125\n",
      "     41      411.2968      727.6865        0.0050  0.3032\n",
      "     42      456.6947      758.3177        0.0049  0.2683\n",
      "     43      453.6390      721.1926        0.0045  0.2274\n",
      "     44      411.6504      \u001b[32m683.7345\u001b[0m     +  0.0040  0.3304\n",
      "     45      393.0431      \u001b[32m675.1896\u001b[0m     +  0.0033  0.3534\n",
      "     46      389.1784      \u001b[32m675.0649\u001b[0m     +  0.0025  0.7060\n",
      "     47      \u001b[36m378.7544\u001b[0m      \u001b[32m674.2554\u001b[0m     +  0.0017  0.4586\n",
      "     48      \u001b[36m374.7381\u001b[0m      676.5658        0.0010  0.3667\n",
      "     49      \u001b[36m371.1276\u001b[0m      677.0410        0.0005  0.2037\n",
      "     50      \u001b[36m369.3792\u001b[0m      677.3841        0.0001  0.3072\n",
      "     51      396.8614      700.6212        0.0050  0.2205\n",
      "     52      438.3228      750.3169        0.0049  0.1987\n",
      "     53      443.9478      710.0732        0.0045  0.3101\n",
      "     54      403.0835      \u001b[32m663.5242\u001b[0m     +  0.0040  0.1991\n",
      "     55      381.2841      664.5549        0.0033  0.3039\n",
      "     56      379.4934      \u001b[32m657.2351\u001b[0m     +  0.0025  0.2056\n",
      "     57      \u001b[36m368.9908\u001b[0m      661.3171        0.0017  0.2998\n",
      "     58      \u001b[36m365.3160\u001b[0m      666.4460        0.0010  0.1969\n",
      "     59      \u001b[36m361.7356\u001b[0m      667.2569        0.0005  0.3063\n",
      "     60      \u001b[36m360.1119\u001b[0m      667.7752        0.0001  0.2077\n",
      "     61      386.5572      689.8454        0.0050  0.2065\n",
      "     62      425.4675      722.8008        0.0049  0.3072\n",
      "     63      432.8308      689.8737        0.0045  0.2033\n",
      "     64      396.4277      \u001b[32m653.0635\u001b[0m     +  0.0040  0.3140\n",
      "     65      372.0601      \u001b[32m647.4168\u001b[0m     +  0.0033  0.2023\n",
      "     66      370.9753      650.0032        0.0025  0.3094\n",
      "     67      361.3215      649.6812        0.0017  0.2159\n",
      "     68      \u001b[36m357.4070\u001b[0m      656.5009        0.0010  0.3051\n",
      "     69      \u001b[36m354.1078\u001b[0m      657.8317        0.0005  0.2140\n",
      "     70      \u001b[36m352.6106\u001b[0m      658.5453        0.0001  0.2084\n",
      "     71      377.4314      674.7419        0.0050  0.3220\n",
      "     72      413.1717      704.0645        0.0049  0.2013\n",
      "     73      423.2250      681.9771        0.0045  0.3142\n",
      "     74      390.2373      \u001b[32m633.8832\u001b[0m     +  0.0040  0.2442\n",
      "     75      364.2581      643.4149        0.0033  0.3071\n",
      "     76      362.3743      \u001b[32m632.6879\u001b[0m     +  0.0025  0.2074\n",
      "     77      354.1759      640.4773        0.0017  0.3058\n",
      "     78      \u001b[36m350.0752\u001b[0m      647.2517        0.0010  0.2014\n",
      "     79      \u001b[36m346.8492\u001b[0m      648.3249        0.0005  0.2117\n",
      "     80      \u001b[36m345.4139\u001b[0m      649.1743        0.0001  0.3199\n",
      "     81      369.7404      659.1622        0.0050  0.2328\n",
      "     82      403.1992      680.3943        0.0049  0.3069\n",
      "     83      414.4183      678.2911        0.0045  0.2042\n",
      "     84      387.5438      \u001b[32m623.8589\u001b[0m     +  0.0040  0.3184\n",
      "     85      358.1961      635.6987        0.0033  0.1980\n",
      "     86      354.5635      \u001b[32m623.0875\u001b[0m     +  0.0025  0.3045\n",
      "     87      348.1257      634.7504        0.0017  0.2018\n",
      "     88      \u001b[36m343.4030\u001b[0m      640.1511        0.0010  0.2049\n",
      "     89      \u001b[36m340.4853\u001b[0m      641.4803        0.0005  0.3058\n",
      "     90      \u001b[36m339.0530\u001b[0m      642.4346        0.0001  0.2056\n",
      "     91      362.9530      639.9211        0.0050  0.3424\n",
      "     92      391.6727      680.1680        0.0049  0.1975\n",
      "     93      408.4129      633.3220        0.0045  0.3165\n",
      "     94      382.0950      \u001b[32m615.5037\u001b[0m     +  0.0040  0.2073\n",
      "     95      350.5900      \u001b[32m607.7898\u001b[0m     +  0.0033  0.2988\n",
      "     96      347.3272      620.5516        0.0025  0.2022\n",
      "     97      341.9368      614.9367        0.0017  0.2142\n",
      "     98      \u001b[36m336.3658\u001b[0m      626.9953        0.0010  0.3007\n",
      "     99      \u001b[36m333.5257\u001b[0m      628.6286        0.0005  0.2026\n",
      "    100      \u001b[36m332.0549\u001b[0m      629.1923        0.0001  0.3173\n",
      "    101      357.0471      615.3882        0.0050  0.2692\n",
      "    102      383.1549      657.2980        0.0049  0.3057\n",
      "    103      401.8782      630.9360        0.0045  0.2054\n",
      "    104      381.1806      \u001b[32m594.8331\u001b[0m     +  0.0040  0.2989\n",
      "    105      347.6929      595.9438        0.0033  0.2093\n",
      "    106      338.5704      616.3762        0.0025  0.2128\n",
      "    107      335.0566      605.3038        0.0017  0.2986\n",
      "    108      \u001b[36m328.9279\u001b[0m      610.8825        0.0010  0.2055\n",
      "    109      \u001b[36m326.4488\u001b[0m      613.4082        0.0005  0.3001\n",
      "    110      \u001b[36m324.9400\u001b[0m      613.5619        0.0001  0.2032\n",
      "    111      350.3060      601.8176        0.0050  0.3168\n",
      "    112      369.2860      620.4689        0.0049  0.2012\n",
      "    113      391.4391      610.6194        0.0045  0.3048\n",
      "    114      378.3932      \u001b[32m567.7588\u001b[0m     +  0.0040  0.2099\n",
      "    115      343.2223      581.0524        0.0033  0.1967\n",
      "    116      331.1511      587.6722        0.0025  0.2987\n",
      "    117      325.4237      585.3681        0.0017  0.2023\n",
      "    118      \u001b[36m318.9321\u001b[0m      588.0836        0.0010  0.3091\n",
      "    119      \u001b[36m316.4851\u001b[0m      592.1942        0.0005  0.2082\n",
      "    120      \u001b[36m315.0391\u001b[0m      592.6604        0.0001  0.3799\n",
      "    121      339.9702      585.3810        0.0050  0.2268\n",
      "    122      357.1265      608.4889        0.0049  0.2972\n",
      "    123      372.4510      599.2834        0.0045  0.1987\n",
      "    124      375.3835      569.5214        0.0040  0.2110\n",
      "    125      338.3590      \u001b[32m565.7222\u001b[0m     +  0.0033  0.3199\n",
      "    126      322.4439      602.8661        0.0025  0.2031\n",
      "    127      316.1917      586.1639        0.0017  0.3196\n",
      "    128      \u001b[36m312.3059\u001b[0m      585.0156        0.0010  0.1962\n",
      "    129      \u001b[36m309.5963\u001b[0m      591.1542        0.0005  0.3142\n",
      "    130      \u001b[36m308.1504\u001b[0m      590.9189        0.0001  0.2017\n",
      "    131      331.3679      576.4811        0.0050  0.3040\n",
      "    132      344.3462      593.3007        0.0049  0.2077\n",
      "    133      360.4035      592.2683        0.0045  0.2036\n",
      "    134      365.0410      \u001b[32m560.7903\u001b[0m     +  0.0040  0.3074\n",
      "    135      331.3174      \u001b[32m558.5100\u001b[0m     +  0.0033  0.1988\n",
      "    136      317.3843      598.6271        0.0025  0.3118\n",
      "    137      308.8637      581.9989        0.0017  0.2044\n",
      "    138      \u001b[36m306.3417\u001b[0m      583.7648        0.0010  0.3067\n",
      "    139      \u001b[36m303.6587\u001b[0m      587.4833        0.0005  0.2075\n",
      "    140      \u001b[36m302.3329\u001b[0m      587.2482        0.0001  0.3063\n",
      "    141      324.0480      579.4073        0.0050  0.2072\n",
      "    142      336.8371      577.5293        0.0049  0.2008\n",
      "    143      352.3188      568.9644        0.0045  0.2999\n",
      "    144      357.6336      565.6087        0.0040  0.1969\n",
      "    145      332.1818      \u001b[32m544.6739\u001b[0m     +  0.0033  0.3114\n",
      "    146      314.3646      615.2068        0.0025  0.1995\n",
      "    147      304.1387      592.5683        0.0017  0.3015\n",
      "    148      \u001b[36m301.9534\u001b[0m      590.6696        0.0010  0.2049\n",
      "    149      \u001b[36m298.8798\u001b[0m      592.4249        0.0005  0.3131\n",
      "    150      \u001b[36m297.6341\u001b[0m      591.4825        0.0001  0.1952\n",
      "    151      317.7454      567.4717        0.0050  0.1973\n",
      "    152      327.9689      570.3375        0.0049  0.3002\n",
      "    153      338.7026      565.4818        0.0045  0.2043\n",
      "    154      348.2215      557.7222        0.0040  0.2911\n",
      "    155      331.5264      \u001b[32m533.7223\u001b[0m     +  0.0033  0.1962\n",
      "    156      313.2089      629.4240        0.0025  0.3006\n",
      "    157      300.0349      593.4083        0.0017  0.1988\n",
      "    158      298.2955      593.7716        0.0010  0.3078\n",
      "    159      \u001b[36m294.7986\u001b[0m      593.8498        0.0005  0.2082\n",
      "    160      \u001b[36m293.5974\u001b[0m      592.6306        0.0001  0.2430\n",
      "    161      312.0623      559.6500        0.0050  0.3259\n",
      "    162      320.7130      568.9154        0.0049  0.1979\n",
      "    163      329.8197      558.5629        0.0045  0.2994\n",
      "    164      340.1670      551.4380        0.0040  0.1981\n",
      "    165      329.5934      \u001b[32m528.6684\u001b[0m     +  0.0033  0.3159\n",
      "    166      311.8730      631.7029        0.0025  0.1950\n",
      "    167      295.8437      590.6499        0.0017  0.3122\n",
      "    168      293.8449      595.3467        0.0010  0.2093\n",
      "    169      \u001b[36m290.3959\u001b[0m      590.6550        0.0005  0.2020\n",
      "    170      \u001b[36m289.1826\u001b[0m      589.7870        0.0001  0.2982\n",
      "    171      307.7690      560.6818        0.0050  0.2109\n",
      "    172      315.5693      581.6021        0.0049  0.3098\n",
      "    173      321.9040      545.1063        0.0045  0.2088\n",
      "    174      332.8228      555.3676        0.0040  0.3079\n",
      "    175      328.0739      528.6758        0.0033  0.2200\n",
      "    176      309.9079      628.4295        0.0025  0.3018\n",
      "    177      292.7574      596.3316        0.0017  0.1992\n",
      "    178      290.5756      600.5810        0.0010  0.2183\n",
      "    179      \u001b[36m287.0536\u001b[0m      592.3114        0.0005  0.3089\n",
      "    180      \u001b[36m285.8145\u001b[0m      591.7420        0.0001  0.2395\n",
      "    181      302.8989      563.0742        0.0050  0.3028\n",
      "    182      311.1015      570.0817        0.0049  0.2086\n",
      "    183      316.9361      547.1874        0.0045  0.2993\n",
      "    184      324.2745      549.1839        0.0040  0.2067\n",
      "    185      323.9148      \u001b[32m528.4910\u001b[0m     +  0.0033  0.3076\n",
      "    186      306.7423      627.4805        0.0025  0.2103\n",
      "    187      289.6725      600.7474        0.0017  0.2088\n",
      "    188      287.5890      604.9049        0.0010  0.3052\n",
      "    189      \u001b[36m284.2196\u001b[0m      594.3505        0.0005  0.2000\n",
      "    190      \u001b[36m282.9618\u001b[0m      594.2352        0.0001  0.3143\n",
      "    191      297.7905      570.6567        0.0050  0.1990\n",
      "    192      305.6907      576.1606        0.0049  0.2999\n",
      "    193      310.4537      552.1913        0.0045  0.2076\n",
      "    194      317.2616      549.1162        0.0040  0.3009\n",
      "    195      318.0788      532.3170        0.0033  0.1967\n",
      "    196      307.2828      617.2658        0.0025  0.2012\n",
      "    197      289.4651      612.5124        0.0017  0.3071\n",
      "    198      283.9686      614.0466        0.0010  0.3445\n",
      "    199      \u001b[36m281.4175\u001b[0m      593.8267        0.0005  0.4251\n",
      "    200      \u001b[36m279.8111\u001b[0m      595.4904        0.0001  0.2329\n",
      "    201      292.1051      581.9544        0.0050  0.3070\n",
      "    202      303.8651      570.5455        0.0049  0.1985\n",
      "    203      306.6853      554.4073        0.0045  0.2936\n",
      "    204      312.8967      550.6557        0.0040  0.2046\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Power: 1, Threshold: 0.05, Pearson: 0.8377047647141971, Spearman: 0.8609346703879933\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.05, Pearson: 0.8377462040741377, Spearman: 0.861518315426035\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.05, Pearson: 0.8377462040741377, Spearman: 0.861518315426035\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.1, Pearson: 0.8385486172887398, Spearman: 0.8628196500038711\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.1, Pearson: 0.8385486172887398, Spearman: 0.8628196500038711\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.1, Pearson: 0.8385486172887398, Spearman: 0.8628196500038711\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.2, Pearson: 0.8377383047612055, Spearman: 0.8624779123298237\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.2, Pearson: 0.8377383047612055, Spearman: 0.8624779123298237\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.2, Pearson: 0.8377383047612055, Spearman: 0.8624779123298237\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.3, Pearson: 0.8364770263527057, Spearman: 0.8600144124948627\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.3, Pearson: 0.8364770263527057, Spearman: 0.8600144124948627\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.3, Pearson: 0.8364770263527057, Spearman: 0.8600144124948627\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.5, Pearson: 0.8270531705142207, Spearman: 0.8537847021498851\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.5, Pearson: 0.8270531705142207, Spearman: 0.8537847021498851\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.5, Pearson: 0.8270531705142207, Spearman: 0.8537847021498851\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.7, Pearson: 0.7913981453339598, Spearman: 0.8340509190993921\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.7, Pearson: 0.7913981453339598, Spearman: 0.8340509190993921\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 1, Threshold: 0.7, Pearson: 0.7913981453339598, Spearman: 0.8340509190993921\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m936.1968\u001b[0m      \u001b[32m979.0019\u001b[0m     +  0.0050  0.5760\n",
      "      2      \u001b[36m926.2479\u001b[0m     1223.5558        0.0049  0.4964\n",
      "      3      \u001b[36m664.6551\u001b[0m      \u001b[32m927.0636\u001b[0m     +  0.0045  0.6930\n",
      "      4      687.1966     1014.3529        0.0040  0.3395\n",
      "      5      \u001b[36m605.0965\u001b[0m      \u001b[32m904.3182\u001b[0m     +  0.0033  0.4923\n",
      "      6      \u001b[36m568.1400\u001b[0m      \u001b[32m896.2187\u001b[0m     +  0.0025  0.6077\n",
      "      7      \u001b[36m528.0677\u001b[0m      \u001b[32m867.1354\u001b[0m     +  0.0017  0.2428\n",
      "      8      \u001b[36m502.5552\u001b[0m      \u001b[32m848.7787\u001b[0m     +  0.0010  0.6145\n",
      "      9      \u001b[36m486.2292\u001b[0m      \u001b[32m839.1669\u001b[0m     +  0.0005  0.2573\n",
      "     10      \u001b[36m478.3608\u001b[0m      \u001b[32m836.3307\u001b[0m     +  0.0001  0.3218\n",
      "     11      569.5426      \u001b[32m779.2759\u001b[0m     +  0.0050  0.2126\n",
      "     12      716.9736     1009.7319        0.0049  0.2102\n",
      "     13      536.7714      824.6565        0.0045  0.3206\n",
      "     14      \u001b[36m461.5272\u001b[0m      787.6666        0.0040  0.2106\n",
      "     15      466.0288      779.9870        0.0033  0.3126\n",
      "     16      \u001b[36m434.3469\u001b[0m      \u001b[32m756.2629\u001b[0m     +  0.0025  0.2112\n",
      "     17      \u001b[36m427.8882\u001b[0m      \u001b[32m744.7135\u001b[0m     +  0.0017  0.3070\n",
      "     18      \u001b[36m417.8195\u001b[0m      \u001b[32m739.1053\u001b[0m     +  0.0010  0.2076\n",
      "     19      \u001b[36m413.2828\u001b[0m      \u001b[32m735.6915\u001b[0m     +  0.0005  0.2665\n",
      "     20      \u001b[36m410.8203\u001b[0m      \u001b[32m734.8388\u001b[0m     +  0.0001  0.3833\n",
      "     21      451.5605      738.4036        0.0050  0.2237\n",
      "     22      500.5302      788.1005        0.0049  0.3219\n",
      "     23      476.7486      764.1601        0.0045  0.2198\n",
      "     24      426.7663      \u001b[32m710.1663\u001b[0m     +  0.0040  0.3173\n",
      "     25      412.6407      \u001b[32m702.7452\u001b[0m     +  0.0033  0.2096\n",
      "     26      \u001b[36m403.6801\u001b[0m      \u001b[32m691.8178\u001b[0m     +  0.0025  0.3099\n",
      "     27      \u001b[36m393.0438\u001b[0m      \u001b[32m685.3328\u001b[0m     +  0.0017  0.2134\n",
      "     28      \u001b[36m387.5481\u001b[0m      \u001b[32m682.6743\u001b[0m     +  0.0010  0.1996\n",
      "     29      \u001b[36m383.4665\u001b[0m      \u001b[32m681.6944\u001b[0m     +  0.0005  0.3104\n",
      "     30      \u001b[36m381.3615\u001b[0m      \u001b[32m681.4512\u001b[0m     +  0.0001  0.2049\n",
      "     31      414.4358      695.9852        0.0050  0.3091\n",
      "     32      461.9060      742.7957        0.0049  0.2014\n",
      "     33      457.7401      735.7976        0.0045  0.3003\n",
      "     34      412.8655      \u001b[32m668.2210\u001b[0m     +  0.0040  0.2048\n",
      "     35      388.9488      \u001b[32m661.2811\u001b[0m     +  0.0033  0.2024\n",
      "     36      385.4288      \u001b[32m657.8700\u001b[0m     +  0.0025  0.3096\n",
      "     37      \u001b[36m374.1870\u001b[0m      \u001b[32m653.6014\u001b[0m     +  0.0017  0.2062\n",
      "     38      \u001b[36m369.9991\u001b[0m      \u001b[32m653.3375\u001b[0m     +  0.0010  0.3211\n",
      "     39      \u001b[36m366.0632\u001b[0m      \u001b[32m653.1759\u001b[0m     +  0.0005  0.2097\n",
      "     40      \u001b[36m364.2017\u001b[0m      653.2729        0.0001  0.3032\n",
      "     41      393.3194      676.3451        0.0050  0.2075\n",
      "     42      437.2178      719.1309        0.0049  0.2163\n",
      "     43      445.0418      709.6008        0.0045  0.2963\n",
      "     44      402.4946      \u001b[32m644.1497\u001b[0m     +  0.0040  0.2050\n",
      "     45      375.2307      \u001b[32m639.1040\u001b[0m     +  0.0033  0.3029\n",
      "     46      373.6828      \u001b[32m638.2476\u001b[0m     +  0.0025  0.2150\n",
      "     47      \u001b[36m362.6009\u001b[0m      \u001b[32m634.9622\u001b[0m     +  0.0017  0.4499\n",
      "     48      \u001b[36m358.8377\u001b[0m      637.1133        0.0010  0.5187\n",
      "     49      \u001b[36m355.0782\u001b[0m      637.6710        0.0005  0.5050\n",
      "     50      \u001b[36m353.4061\u001b[0m      638.0514        0.0001  0.2216\n",
      "     51      380.5522      665.1465        0.0050  0.1992\n",
      "     52      420.9240      694.0307        0.0049  0.3081\n",
      "     53      431.1433      689.0878        0.0045  0.2034\n",
      "     54      392.6163      \u001b[32m625.1313\u001b[0m     +  0.0040  0.3010\n",
      "     55      365.6630      \u001b[32m625.0953\u001b[0m     +  0.0033  0.2133\n",
      "     56      364.6167      \u001b[32m624.9832\u001b[0m     +  0.0025  0.5586\n",
      "     57      354.1769      \u001b[32m623.7558\u001b[0m     +  0.0017  0.4127\n",
      "     58      \u001b[36m351.0163\u001b[0m      628.0857        0.0010  0.3104\n",
      "     59      \u001b[36m347.3980\u001b[0m      628.6515        0.0005  0.2032\n",
      "     60      \u001b[36m345.8896\u001b[0m      629.1668        0.0001  0.2047\n",
      "     61      370.5647      646.5739        0.0050  0.3219\n",
      "     62      407.1675      677.8056        0.0049  0.1937\n",
      "     63      418.3695      662.5042        0.0045  0.3057\n",
      "     64      383.5354      \u001b[32m610.5108\u001b[0m     +  0.0040  0.2047\n",
      "     65      357.1638      613.7731        0.0033  0.3133\n",
      "     66      356.7907      614.2870        0.0025  0.2099\n",
      "     67      347.1157      614.9711        0.0017  0.3134\n",
      "     68      \u001b[36m343.8578\u001b[0m      619.9137        0.0010  0.2001\n",
      "     69      \u001b[36m340.4402\u001b[0m      620.6377        0.0005  0.2091\n",
      "     70      \u001b[36m339.0496\u001b[0m      621.2849        0.0001  0.2973\n",
      "     71      362.5642      630.0426        0.0050  0.2530\n",
      "     72      396.7833      657.5923        0.0049  0.3029\n",
      "     73      409.6835      647.8122        0.0045  0.2074\n",
      "     74      378.0356      \u001b[32m597.6041\u001b[0m     +  0.0040  0.3144\n",
      "     75      349.3055      601.4597        0.0033  0.2019\n",
      "     76      349.3986      600.8155        0.0025  0.3228\n",
      "     77      340.7649      604.2081        0.0017  0.2088\n",
      "     78      \u001b[36m337.1012\u001b[0m      608.6089        0.0010  0.2128\n",
      "     79      \u001b[36m333.9266\u001b[0m      608.9198        0.0005  0.3080\n",
      "     80      \u001b[36m332.6158\u001b[0m      609.6968        0.0001  0.2031\n",
      "     81      355.1907      610.9574        0.0050  0.3099\n",
      "     82      387.1758      632.7533        0.0049  0.2099\n",
      "     83      403.7602      644.4572        0.0045  0.3240\n",
      "     84      373.8106      \u001b[32m582.0074\u001b[0m     +  0.0040  0.2002\n",
      "     85      343.5690      587.4457        0.0033  0.3060\n",
      "     86      340.8790      \u001b[32m578.5378\u001b[0m     +  0.0025  0.2112\n",
      "     87      334.4925      586.0722        0.0017  0.2056\n",
      "     88      \u001b[36m329.1557\u001b[0m      585.5360        0.0010  0.3026\n",
      "     89      \u001b[36m326.1595\u001b[0m      585.4246        0.0005  0.2054\n",
      "     90      \u001b[36m324.6722\u001b[0m      586.0685        0.0001  0.3150\n",
      "     91      349.8681      589.8033        0.0050  0.2340\n",
      "     92      374.5339      602.6426        0.0049  0.3093\n",
      "     93      391.6184      617.7942        0.0045  0.2307\n",
      "     94      369.8901      \u001b[32m549.8929\u001b[0m     +  0.0040  0.3535\n",
      "     95      340.7854      576.0161        0.0033  0.2004\n",
      "     96      328.3934      551.9098        0.0025  0.2007\n",
      "     97      325.6284      568.6818        0.0017  0.2954\n",
      "     98      \u001b[36m318.2370\u001b[0m      566.3634        0.0010  0.1989\n",
      "     99      \u001b[36m316.1788\u001b[0m      569.6968        0.0005  0.2958\n",
      "    100      \u001b[36m314.6410\u001b[0m      570.2189        0.0001  0.2018\n",
      "    101      337.5979      566.3471        0.0050  0.3099\n",
      "    102      361.2220      582.3298        0.0049  0.2046\n",
      "    103      380.1613      602.7260        0.0045  0.3197\n",
      "    104      365.0225      \u001b[32m539.2708\u001b[0m     +  0.0040  0.2348\n",
      "    105      333.3765      566.7091        0.0033  0.2031\n",
      "    106      319.9065      544.0186        0.0025  0.3062\n",
      "    107      316.6611      558.4143        0.0017  0.2065\n",
      "    108      \u001b[36m310.4410\u001b[0m      558.4053        0.0010  0.3068\n",
      "    109      \u001b[36m308.3015\u001b[0m      563.1362        0.0005  0.2020\n",
      "    110      \u001b[36m306.8324\u001b[0m      563.3009        0.0001  0.3070\n",
      "    111      328.8606      556.9912        0.0050  0.2063\n",
      "    112      348.6155      567.8584        0.0049  0.3091\n",
      "    113      364.9832      580.7917        0.0045  0.2087\n",
      "    114      362.7342      \u001b[32m537.4137\u001b[0m     +  0.0040  0.2120\n",
      "    115      328.9599      550.8877        0.0033  0.3019\n",
      "    116      311.3767      548.0968        0.0025  0.1982\n",
      "    117      308.3233      552.3366        0.0017  0.3005\n",
      "    118      \u001b[36m303.5506\u001b[0m      553.4993        0.0010  0.2059\n",
      "    119      \u001b[36m301.0344\u001b[0m      558.8359        0.0005  0.3219\n",
      "    120      \u001b[36m299.6045\u001b[0m      558.2297        0.0001  0.2232\n",
      "    121      320.8179      552.4738        0.0050  0.3214\n",
      "    122      336.9374      557.1488        0.0049  0.2040\n",
      "    123      353.2891      564.9529        0.0045  0.2056\n",
      "    124      355.1562      538.2843        0.0040  0.3049\n",
      "    125      324.3267      538.4402        0.0033  0.2080\n",
      "    126      307.1776      548.3919        0.0025  0.3232\n",
      "    127      301.6733      550.3210        0.0017  0.2010\n",
      "    128      \u001b[36m297.7264\u001b[0m      553.0353        0.0010  0.2991\n",
      "    129      \u001b[36m295.3367\u001b[0m      556.4662        0.0005  0.2053\n",
      "    130      \u001b[36m294.0623\u001b[0m      555.8956        0.0001  0.3062\n",
      "    131      313.8014      547.5205        0.0050  0.2090\n",
      "    132      328.3804      546.8481        0.0049  0.2084\n",
      "    133      341.8286      576.7928        0.0045  0.3207\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m934.2052\u001b[0m     \u001b[32m1006.9553\u001b[0m     +  0.0050  0.4224\n",
      "      2      952.1989     1235.5503        0.0049  0.3470\n",
      "      3      \u001b[36m673.4932\u001b[0m      \u001b[32m970.8469\u001b[0m     +  0.0045  0.3119\n",
      "      4      706.9782     1028.9082        0.0040  0.2142\n",
      "      5      \u001b[36m624.0793\u001b[0m      \u001b[32m958.6906\u001b[0m     +  0.0033  0.3277\n",
      "      6      \u001b[36m597.3697\u001b[0m      \u001b[32m943.6481\u001b[0m     +  0.0025  0.2155\n",
      "      7      \u001b[36m561.5693\u001b[0m      \u001b[32m917.4466\u001b[0m     +  0.0017  0.2116\n",
      "      8      \u001b[36m537.6285\u001b[0m      \u001b[32m894.4977\u001b[0m     +  0.0010  0.3208\n",
      "      9      \u001b[36m523.3430\u001b[0m      \u001b[32m885.9328\u001b[0m     +  0.0005  0.2150\n",
      "     10      \u001b[36m516.1533\u001b[0m      \u001b[32m883.5185\u001b[0m     +  0.0001  0.3098\n",
      "     11      600.8266      \u001b[32m837.7632\u001b[0m     +  0.0050  0.2173\n",
      "     12      662.1545      959.6150        0.0049  0.3055\n",
      "     13      539.6804      \u001b[32m816.1863\u001b[0m     +  0.0045  0.2218\n",
      "     14      \u001b[36m476.8866\u001b[0m      \u001b[32m799.1873\u001b[0m     +  0.0040  0.2137\n",
      "     15      \u001b[36m471.4184\u001b[0m      \u001b[32m780.8539\u001b[0m     +  0.0033  0.3201\n",
      "     16      \u001b[36m445.6737\u001b[0m      \u001b[32m759.3317\u001b[0m     +  0.0025  0.2497\n",
      "     17      \u001b[36m434.7334\u001b[0m      \u001b[32m744.3826\u001b[0m     +  0.0017  0.5279\n",
      "     18      \u001b[36m425.1383\u001b[0m      \u001b[32m739.0434\u001b[0m     +  0.0010  0.2647\n",
      "     19      \u001b[36m420.0975\u001b[0m      \u001b[32m736.5677\u001b[0m     +  0.0005  0.3280\n",
      "     20      \u001b[36m417.3922\u001b[0m      \u001b[32m735.8894\u001b[0m     +  0.0001  0.2088\n",
      "     21      461.0289      745.7095        0.0050  0.3208\n",
      "     22      517.9811      805.2117        0.0049  0.2127\n",
      "     23      499.7923      788.2459        0.0045  0.2184\n",
      "     24      440.1435      \u001b[32m724.6184\u001b[0m     +  0.0040  0.3158\n",
      "     25      419.1387      \u001b[32m724.5589\u001b[0m     +  0.0033  0.2370\n",
      "     26      \u001b[36m412.8298\u001b[0m      \u001b[32m711.2517\u001b[0m     +  0.0025  0.5383\n",
      "     27      \u001b[36m401.0654\u001b[0m      \u001b[32m707.6003\u001b[0m     +  0.0017  0.5290\n",
      "     28      \u001b[36m395.9814\u001b[0m      \u001b[32m705.2535\u001b[0m     +  0.0010  0.5949\n",
      "     29      \u001b[36m391.7642\u001b[0m      \u001b[32m704.2670\u001b[0m     +  0.0005  0.2170\n",
      "     30      \u001b[36m389.6365\u001b[0m      \u001b[32m704.0890\u001b[0m     +  0.0001  0.2137\n",
      "     31      422.9965      711.6134        0.0050  0.3090\n",
      "     32      469.5721      759.0014        0.0049  0.2223\n",
      "     33      467.1820      749.1691        0.0045  0.3444\n",
      "     34      421.7016      \u001b[32m687.2189\u001b[0m     +  0.0040  0.2299\n",
      "     35      397.1448      698.4298        0.0033  0.3158\n",
      "     36      393.7682      687.6596        0.0025  0.2012\n",
      "     37      \u001b[36m382.8103\u001b[0m      \u001b[32m684.2564\u001b[0m     +  0.0017  0.1990\n",
      "     38      \u001b[36m378.6478\u001b[0m      685.1268        0.0010  0.3037\n",
      "     39      \u001b[36m374.6848\u001b[0m      685.0299        0.0005  0.2106\n",
      "     40      \u001b[36m372.8184\u001b[0m      685.1422        0.0001  0.3067\n",
      "     41      401.7511      696.4406        0.0050  0.2382\n",
      "     42      445.9679      729.5089        0.0049  0.5762\n",
      "     43      452.8064      728.9701        0.0045  0.4864\n",
      "     44      412.8410      \u001b[32m672.1334\u001b[0m     +  0.0040  0.4998\n",
      "     45      383.7106      682.6816        0.0033  0.2049\n",
      "     46      382.0070      673.2130        0.0025  0.1974\n",
      "     47      \u001b[36m371.2951\u001b[0m      \u001b[32m672.1324\u001b[0m     +  0.0017  0.2976\n",
      "     48      \u001b[36m367.7132\u001b[0m      674.0967        0.0010  0.1974\n",
      "     49      \u001b[36m363.8937\u001b[0m      673.8751        0.0005  0.3071\n",
      "     50      \u001b[36m362.2372\u001b[0m      674.1061        0.0001  0.2002\n",
      "     51      388.4279      677.7796        0.0050  0.3274\n",
      "     52      428.4180      710.9927        0.0049  0.2103\n",
      "     53      436.2548      711.9246        0.0045  0.3078\n",
      "     54      401.7177      \u001b[32m655.4938\u001b[0m     +  0.0040  0.2045\n",
      "     55      372.5914      661.8534        0.0033  0.2129\n",
      "     56      371.4260      655.7568        0.0025  0.3101\n",
      "     57      \u001b[36m361.4391\u001b[0m      657.8830        0.0017  0.2066\n",
      "     58      \u001b[36m357.8835\u001b[0m      659.6038        0.0010  0.3307\n",
      "     59      \u001b[36m354.3077\u001b[0m      659.2652        0.0005  0.2476\n",
      "     60      \u001b[36m352.8015\u001b[0m      659.6746        0.0001  0.6677\n",
      "     61      377.9536      665.7468        0.0050  0.2992\n",
      "     62      415.1314      693.9707        0.0049  0.3222\n",
      "     63      427.4314      692.7696        0.0045  0.2083\n",
      "     64      394.3298      \u001b[32m642.8775\u001b[0m     +  0.0040  0.2226\n",
      "     65      365.7447      653.7291        0.0033  0.3158\n",
      "     66      364.0005      644.5953        0.0025  0.2104\n",
      "     67      354.6673      648.2486        0.0017  0.3043\n",
      "     68      \u001b[36m351.0746\u001b[0m      652.6974        0.0010  0.2062\n",
      "     69      \u001b[36m347.6312\u001b[0m      653.0698        0.0005  0.2983\n",
      "     70      \u001b[36m346.2257\u001b[0m      653.7398        0.0001  0.2226\n",
      "     71      369.9664      655.0479        0.0050  0.3047\n",
      "     72      405.6179      679.3854        0.0049  0.2033\n",
      "     73      419.0179      678.1413        0.0045  0.2116\n",
      "     74      389.3362      \u001b[32m628.8884\u001b[0m     +  0.0040  0.3008\n",
      "     75      358.9737      636.2978        0.0033  0.2080\n",
      "     76      356.7487      630.4868        0.0025  0.3653\n",
      "     77      348.4431      635.3464        0.0017  0.2059\n",
      "     78      \u001b[36m344.5096\u001b[0m      638.2416        0.0010  0.3042\n",
      "     79      \u001b[36m341.2433\u001b[0m      638.1322        0.0005  0.3059\n",
      "     80      \u001b[36m339.8931\u001b[0m      638.7855        0.0001  0.3284\n",
      "     81      363.7140      638.0475        0.0050  0.2138\n",
      "     82      396.1428      654.6039        0.0049  0.2073\n",
      "     83      409.7771      662.2562        0.0045  0.3184\n",
      "     84      384.1747      \u001b[32m609.9257\u001b[0m     +  0.0040  0.2187\n",
      "     85      353.7785      624.2400        0.0033  0.3232\n",
      "     86      349.3473      611.9950        0.0025  0.2016\n",
      "     87      342.6127      618.0092        0.0017  0.3039\n",
      "     88      \u001b[36m337.7967\u001b[0m      618.1131        0.0010  0.2079\n",
      "     89      \u001b[36m334.7261\u001b[0m      618.3684        0.0005  0.3142\n",
      "     90      \u001b[36m333.2685\u001b[0m      619.1834        0.0001  0.2239\n",
      "     91      357.8084      613.5733        0.0050  0.1988\n",
      "     92      387.8699      630.5120        0.0049  0.3210\n",
      "     93      399.9323      656.5101        0.0045  0.2062\n",
      "     94      382.6858      \u001b[32m585.2568\u001b[0m     +  0.0040  0.3039\n",
      "     95      351.6740      603.4277        0.0033  0.2239\n",
      "     96      339.7005      586.6275        0.0025  0.3002\n",
      "     97      336.3566      593.1804        0.0017  0.2012\n",
      "     98      \u001b[36m329.1393\u001b[0m      591.2393        0.0010  0.3021\n",
      "     99      \u001b[36m326.5738\u001b[0m      594.9146        0.0005  0.2038\n",
      "    100      \u001b[36m324.8988\u001b[0m      595.4550        0.0001  0.1979\n",
      "    101      351.5397      598.7479        0.0050  0.2996\n",
      "    102      377.6182      613.6757        0.0049  0.2064\n",
      "    103      388.6755      631.8091        0.0045  0.2996\n",
      "    104      376.8268      \u001b[32m567.6776\u001b[0m     +  0.0040  0.1990\n",
      "    105      348.6366      596.7707        0.0033  0.3002\n",
      "    106      331.6211      569.5285        0.0025  0.2097\n",
      "    107      329.0904      577.5610        0.0017  0.3006\n",
      "    108      \u001b[36m322.1839\u001b[0m      579.1613        0.0010  0.2452\n",
      "    109      \u001b[36m319.7024\u001b[0m      582.6959        0.0005  0.1991\n",
      "    110      \u001b[36m318.0993\u001b[0m      582.7509        0.0001  0.3021\n",
      "    111      342.8279      579.1456        0.0050  0.1997\n",
      "    112      366.5304      599.2718        0.0049  0.3140\n",
      "    113      378.4743      604.5947        0.0045  0.2078\n",
      "    114      371.5833      \u001b[32m558.2892\u001b[0m     +  0.0040  0.3092\n",
      "    115      343.1228      575.5116        0.0033  0.2537\n",
      "    116      323.9814      559.3180        0.0025  0.4239\n",
      "    117      319.7763      563.2512        0.0017  0.2167\n",
      "    118      \u001b[36m314.3271\u001b[0m      565.6119        0.0010  0.2131\n",
      "    119      \u001b[36m311.4392\u001b[0m      570.2321        0.0005  0.2974\n",
      "    120      \u001b[36m309.8091\u001b[0m      569.7127        0.0001  0.2032\n",
      "    121      333.7721      566.4325        0.0050  0.3132\n",
      "    122      355.3016      592.2134        0.0049  0.2090\n",
      "    123      365.0367      589.9108        0.0045  0.3134\n",
      "    124      370.4587      565.4184        0.0040  0.2274\n",
      "    125      340.9469      \u001b[32m554.6547\u001b[0m     +  0.0033  0.3084\n",
      "    126      317.2081      565.4232        0.0025  0.2059\n",
      "    127      312.0697      560.6606        0.0017  0.2039\n",
      "    128      \u001b[36m308.0177\u001b[0m      561.6860        0.0010  0.3040\n",
      "    129      \u001b[36m304.9615\u001b[0m      565.8395        0.0005  0.1994\n",
      "    130      \u001b[36m303.4328\u001b[0m      565.1964        0.0001  0.3340\n",
      "    131      325.8607      559.6893        0.0050  0.1996\n",
      "    132      345.3047      581.6502        0.0049  0.3120\n",
      "    133      354.8074      575.5735        0.0045  0.2012\n",
      "    134      363.8166      571.5183        0.0040  0.3201\n",
      "    135      339.8555      \u001b[32m551.4626\u001b[0m     +  0.0033  0.2094\n",
      "    136      314.1282      565.6553        0.0025  0.2026\n",
      "    137      306.3344      561.4515        0.0017  0.3029\n",
      "    138      \u001b[36m303.2561\u001b[0m      563.3867        0.0010  0.2014\n",
      "    139      \u001b[36m299.8098\u001b[0m      567.4957        0.0005  0.3138\n",
      "    140      \u001b[36m298.2369\u001b[0m      566.1944        0.0001  0.2043\n",
      "    141      318.1345      555.2038        0.0050  0.3114\n",
      "    142      335.4006      579.8339        0.0049  0.1976\n",
      "    143      341.5341      562.2056        0.0045  0.3023\n",
      "    144      355.2728      571.8660        0.0040  0.2070\n",
      "    145      333.3654      \u001b[32m525.7881\u001b[0m     +  0.0033  0.2242\n",
      "    146      311.4760      572.0184        0.0025  0.3067\n",
      "    147      299.6392      556.5149        0.0017  0.2039\n",
      "    148      \u001b[36m298.1469\u001b[0m      563.4995        0.0010  0.3064\n",
      "    149      \u001b[36m294.1732\u001b[0m      562.0036        0.0005  0.2109\n",
      "    150      \u001b[36m292.8328\u001b[0m      561.0609        0.0001  0.3153\n",
      "    151      312.9216      554.8680        0.0050  0.2549\n",
      "    152      327.3782      570.0889        0.0049  0.3535\n",
      "    153      332.6062      556.9491        0.0045  0.2333\n",
      "    154      345.4202      570.4637        0.0040  0.2409\n",
      "    155      331.2574      \u001b[32m517.8981\u001b[0m     +  0.0033  0.3036\n",
      "    156      310.0440      567.1915        0.0025  0.1993\n",
      "    157      295.0549      557.9070        0.0017  0.2992\n",
      "    158      293.0182      564.1977        0.0010  0.1999\n",
      "    159      \u001b[36m289.3254\u001b[0m      561.1955        0.0005  0.3000\n",
      "    160      \u001b[36m287.9413\u001b[0m      560.0536        0.0001  0.1998\n",
      "    161      307.2133      551.7690        0.0050  0.3069\n",
      "    162      320.7443      566.0365        0.0049  0.2089\n",
      "    163      325.6510      554.8441        0.0045  0.2024\n",
      "    164      334.2003      571.0562        0.0040  0.3037\n",
      "    165      329.3681      519.3429        0.0033  0.2093\n",
      "    166      312.0494      567.9859        0.0025  0.2951\n",
      "    167      291.9694      557.6722        0.0017  0.2190\n",
      "    168      290.5077      562.9713        0.0010  0.3169\n",
      "    169      \u001b[36m285.3940\u001b[0m      554.0965        0.0005  0.2008\n",
      "    170      \u001b[36m283.9082\u001b[0m      554.5769        0.0001  0.3178\n",
      "    171      301.9057      553.6682        0.0050  0.2048\n",
      "    172      316.5077      563.9689        0.0049  0.2100\n",
      "    173      322.2694      555.7772        0.0045  0.3327\n",
      "    174      331.5702      570.5950        0.0040  0.2822\n",
      "    175      329.7662      \u001b[32m513.0464\u001b[0m     +  0.0033  0.3171\n",
      "    176      312.2766      575.5103        0.0025  0.2042\n",
      "    177      289.8225      559.2270        0.0017  0.2974\n",
      "    178      288.2166      564.6628        0.0010  0.2019\n",
      "    179      \u001b[36m282.2122\u001b[0m      555.4040        0.0005  0.3066\n",
      "    180      \u001b[36m280.6742\u001b[0m      554.2560        0.0001  0.2082\n",
      "    181      298.3593      540.5404        0.0050  0.1948\n",
      "    182      308.9863      556.4702        0.0049  0.3150\n",
      "    183      315.5199      543.1408        0.0045  0.2188\n",
      "    184      321.7041      553.7139        0.0040  0.3153\n",
      "    185      322.4786      \u001b[32m505.5582\u001b[0m     +  0.0033  0.1993\n",
      "    186      306.2117      565.4532        0.0025  0.3033\n",
      "    187      285.2278      556.5398        0.0017  0.2098\n",
      "    188      283.0408      555.2555        0.0010  0.3079\n",
      "    189      \u001b[36m278.5126\u001b[0m      545.7829        0.0005  0.2091\n",
      "    190      \u001b[36m277.0535\u001b[0m      546.4360        0.0001  0.2016\n",
      "    191      292.6984      543.3985        0.0050  0.3104\n",
      "    192      304.5349      548.0822        0.0049  0.2041\n",
      "    193      308.8287      541.1491        0.0045  0.3236\n",
      "    194      318.1342      556.0233        0.0040  0.2294\n",
      "    195      318.3823      \u001b[32m496.2180\u001b[0m     +  0.0033  0.3096\n",
      "    196      305.5329      573.7600        0.0025  0.2073\n",
      "    197      282.3979      556.8914        0.0017  0.3075\n",
      "    198      282.0575      557.4949        0.0010  0.2060\n",
      "    199      \u001b[36m275.7451\u001b[0m      545.0787        0.0005  0.2118\n",
      "    200      \u001b[36m274.1249\u001b[0m      545.3174        0.0001  0.3025\n",
      "    201      289.6823      547.1949        0.0050  0.2018\n",
      "    202      299.6200      550.0870        0.0049  0.3043\n",
      "    203      303.4973      535.4410        0.0045  0.2077\n",
      "    204      311.5542      550.4106        0.0040  0.3137\n",
      "    205      315.5703      501.8209        0.0033  0.2036\n",
      "    206      301.6328      567.4891        0.0025  0.3192\n",
      "    207      278.6204      553.6890        0.0017  0.2063\n",
      "    208      277.9644      556.0339        0.0010  0.2052\n",
      "    209      \u001b[36m272.7946\u001b[0m      542.5038        0.0005  0.3171\n",
      "    210      \u001b[36m271.1244\u001b[0m      542.9525        0.0001  0.2046\n",
      "    211      285.6275      546.3960        0.0050  0.2994\n",
      "    212      295.4475      549.8016        0.0049  0.2096\n",
      "    213      300.2773      529.3583        0.0045  0.3434\n",
      "    214      308.4464      550.1685        0.0040  0.2016\n",
      "    215      311.6644      \u001b[32m491.6266\u001b[0m     +  0.0033  0.3010\n",
      "    216      295.9749      572.1239        0.0025  0.2083\n",
      "    217      276.1178      557.3086        0.0017  0.2082\n",
      "    218      273.1315      557.5635        0.0010  0.2945\n",
      "    219      \u001b[36m269.4520\u001b[0m      545.5948        0.0005  0.2090\n",
      "    220      \u001b[36m268.0566\u001b[0m      546.0312        0.0001  0.3211\n",
      "    221      280.8007      541.9530        0.0050  0.2075\n",
      "    222      287.8946      556.1397        0.0049  0.3099\n",
      "    223      300.9292      526.9932        0.0045  0.2043\n",
      "    224      299.2411      525.4824        0.0040  0.3037\n",
      "    225      306.9390      513.5768        0.0033  0.2055\n",
      "    226      288.8118      544.5872        0.0025  0.2076\n",
      "    227      275.9252      560.5108        0.0017  0.3028\n",
      "    228      \u001b[36m267.9128\u001b[0m      563.2824        0.0010  0.1992\n",
      "    229      \u001b[36m267.2546\u001b[0m      551.7462        0.0005  0.3060\n",
      "    230      \u001b[36m265.4562\u001b[0m      553.2904        0.0001  0.2004\n",
      "    231      276.3545      546.4615        0.0050  0.3174\n",
      "    232      285.3121      542.9892        0.0049  0.2246\n",
      "    233      297.3157      531.6305        0.0045  0.5599\n",
      "    234      298.8217      536.2609        0.0040  0.4605\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m903.2464\u001b[0m      \u001b[32m955.2155\u001b[0m     +  0.0050  0.2198\n",
      "      2      \u001b[36m890.7465\u001b[0m     1214.5644        0.0049  0.3199\n",
      "      3      \u001b[36m670.2824\u001b[0m      964.0921        0.0045  0.2080\n",
      "      4      694.8513     1009.0508        0.0040  0.2146\n",
      "      5      \u001b[36m630.9603\u001b[0m      967.3897        0.0033  0.3242\n",
      "      6      \u001b[36m608.3884\u001b[0m      \u001b[32m940.0234\u001b[0m     +  0.0025  0.2419\n",
      "      7      \u001b[36m581.6283\u001b[0m      \u001b[32m925.1910\u001b[0m     +  0.0017  0.4136\n",
      "      8      \u001b[36m559.6270\u001b[0m      \u001b[32m907.1882\u001b[0m     +  0.0010  0.3588\n",
      "      9      \u001b[36m546.1100\u001b[0m      \u001b[32m898.0125\u001b[0m     +  0.0005  0.3296\n",
      "     10      \u001b[36m539.2870\u001b[0m      \u001b[32m895.5687\u001b[0m     +  0.0001  0.2234\n",
      "     11      619.5062      \u001b[32m881.1713\u001b[0m     +  0.0050  0.3153\n",
      "     12      638.1089      936.3255        0.0049  0.2078\n",
      "     13      \u001b[36m522.3925\u001b[0m      \u001b[32m801.7462\u001b[0m     +  0.0045  0.2059\n",
      "     14      \u001b[36m496.9888\u001b[0m      811.1423        0.0040  0.3228\n",
      "     15      \u001b[36m476.4848\u001b[0m      \u001b[32m772.4386\u001b[0m     +  0.0033  0.2066\n",
      "     16      \u001b[36m449.6800\u001b[0m      \u001b[32m746.9509\u001b[0m     +  0.0025  0.3228\n",
      "     17      \u001b[36m437.4174\u001b[0m      \u001b[32m735.9705\u001b[0m     +  0.0017  0.2096\n",
      "     18      \u001b[36m427.0842\u001b[0m      \u001b[32m728.7996\u001b[0m     +  0.0010  0.3486\n",
      "     19      \u001b[36m421.5666\u001b[0m      \u001b[32m725.2948\u001b[0m     +  0.0005  0.2129\n",
      "     20      \u001b[36m418.6567\u001b[0m      \u001b[32m724.4351\u001b[0m     +  0.0001  0.2214\n",
      "     21      464.8343      739.2727        0.0050  0.3226\n",
      "     22      526.7187      821.0825        0.0049  0.3136\n",
      "     23      500.9864      770.1312        0.0045  0.3846\n",
      "     24      436.4822      \u001b[32m710.8181\u001b[0m     +  0.0040  0.2273\n",
      "     25      423.7238      712.7790        0.0033  0.3507\n",
      "     26      \u001b[36m414.1252\u001b[0m      \u001b[32m701.2879\u001b[0m     +  0.0025  0.2115\n",
      "     27      \u001b[36m403.8629\u001b[0m      \u001b[32m697.7278\u001b[0m     +  0.0017  0.3223\n",
      "     28      \u001b[36m398.1025\u001b[0m      \u001b[32m696.4051\u001b[0m     +  0.0010  0.2192\n",
      "     29      \u001b[36m394.0445\u001b[0m      \u001b[32m695.8557\u001b[0m     +  0.0005  0.2075\n",
      "     30      \u001b[36m391.8846\u001b[0m      \u001b[32m695.7502\u001b[0m     +  0.0001  0.3230\n",
      "     31      424.7948      706.9631        0.0050  0.2032\n",
      "     32      469.4620      767.9515        0.0049  0.3236\n",
      "     33      465.2315      747.0520        0.0045  0.2128\n",
      "     34      418.3249      708.8309        0.0040  0.3121\n",
      "     35      401.5359      \u001b[32m679.3738\u001b[0m     +  0.0033  0.2154\n",
      "     36      395.1484      685.9448        0.0025  0.2102\n",
      "     37      \u001b[36m385.5707\u001b[0m      680.2621        0.0017  0.3241\n",
      "     38      \u001b[36m380.7210\u001b[0m      680.9351        0.0010  0.2107\n",
      "     39      \u001b[36m377.0739\u001b[0m      681.9310        0.0005  0.3067\n",
      "     40      \u001b[36m375.2185\u001b[0m      682.3228        0.0001  0.2033\n",
      "     41      404.1311      693.3496        0.0050  0.3078\n",
      "     42      445.6269      738.4936        0.0049  0.1995\n",
      "     43      449.8219      712.0100        0.0045  0.2121\n",
      "     44      406.8280      \u001b[32m663.7210\u001b[0m     +  0.0040  0.3418\n",
      "     45      386.4611      674.2588        0.0033  0.2083\n",
      "     46      383.3803      668.8738        0.0025  0.3127\n",
      "     47      \u001b[36m373.2847\u001b[0m      671.1148        0.0017  0.2044\n",
      "     48      \u001b[36m369.5211\u001b[0m      673.6494        0.0010  0.2980\n",
      "     49      \u001b[36m365.9197\u001b[0m      674.5718        0.0005  0.2098\n",
      "     50      \u001b[36m364.2186\u001b[0m      675.1129        0.0001  0.2987\n",
      "     51      390.6068      682.9382        0.0050  0.2252\n",
      "     52      429.2864      706.2965        0.0049  0.2124\n",
      "     53      435.8817      701.9390        0.0045  0.3225\n",
      "     54      400.0488      \u001b[32m655.3480\u001b[0m     +  0.0040  0.2049\n",
      "     55      376.4361      659.0089        0.0033  0.3198\n",
      "     56      374.3741      661.8098        0.0025  0.2078\n",
      "     57      364.9308      663.4381        0.0017  0.3010\n",
      "     58      \u001b[36m361.6360\u001b[0m      667.6585        0.0010  0.2067\n",
      "     59      \u001b[36m358.1000\u001b[0m      668.8755        0.0005  0.3099\n",
      "     60      \u001b[36m356.5396\u001b[0m      669.5747        0.0001  0.2039\n",
      "     61      381.5542      672.0430        0.0050  0.2015\n",
      "     62      418.4347      690.7377        0.0049  0.3162\n",
      "     63      426.4891      695.8165        0.0045  0.2152\n",
      "     64      393.8979      \u001b[32m637.9937\u001b[0m     +  0.0040  0.3103\n",
      "     65      368.8208      657.5871        0.0033  0.2025\n",
      "     66      367.7499      650.2958        0.0025  0.3126\n",
      "     67      358.5830      654.6267        0.0017  0.3263\n",
      "     68      \u001b[36m355.4589\u001b[0m      662.2636        0.0010  0.3640\n",
      "     69      \u001b[36m352.1037\u001b[0m      663.6409        0.0005  0.4408\n",
      "     70      \u001b[36m350.6460\u001b[0m      664.4427        0.0001  0.3793\n",
      "     71      374.0036      665.9423        0.0050  0.6057\n",
      "     72      408.0656      681.4649        0.0049  0.4279\n",
      "     73      418.8603      673.1405        0.0045  0.5276\n",
      "     74      387.2843      \u001b[32m634.8269\u001b[0m     +  0.0040  0.4536\n",
      "     75      361.8476      645.1810        0.0033  0.4290\n",
      "     76      361.2375      642.8539        0.0025  0.2204\n",
      "     77      352.7650      648.8164        0.0017  0.3563\n",
      "     78      \u001b[36m349.3938\u001b[0m      655.1592        0.0010  0.2019\n",
      "     79      \u001b[36m346.1861\u001b[0m      655.8863        0.0005  0.2119\n",
      "     80      \u001b[36m344.8188\u001b[0m      656.6950        0.0001  0.3053\n",
      "     81      368.1566      651.6353        0.0050  0.2008\n",
      "     82      398.5288      654.6449        0.0049  0.3076\n",
      "     83      413.3130      673.0290        0.0045  0.2056\n",
      "     84      382.3093      \u001b[32m628.4678\u001b[0m     +  0.0040  0.3084\n",
      "     85      357.0507      635.3444        0.0033  0.2050\n",
      "     86      355.1119      634.5915        0.0025  0.3003\n",
      "     87      347.7610      639.9000        0.0017  0.2108\n",
      "     88      \u001b[36m344.1795\u001b[0m      646.6486        0.0010  0.1953\n",
      "     89      \u001b[36m341.2530\u001b[0m      647.6782        0.0005  0.3067\n",
      "     90      \u001b[36m339.9341\u001b[0m      648.4854        0.0001  0.2070\n",
      "     91      362.0956      635.5000        0.0050  0.3243\n",
      "     92      389.2704      632.3254        0.0049  0.2118\n",
      "     93      400.9174      645.6676        0.0045  0.3146\n",
      "     94      378.4127      \u001b[32m605.9677\u001b[0m     +  0.0040  0.2057\n",
      "     95      352.3321      622.1044        0.0033  0.3034\n",
      "     96      347.5307      615.7163        0.0025  0.2179\n",
      "     97      341.7495      619.8919        0.0017  0.2170\n",
      "     98      \u001b[36m336.8489\u001b[0m      626.9208        0.0010  0.3160\n",
      "     99      \u001b[36m334.0101\u001b[0m      628.9384        0.0005  0.2026\n",
      "    100      \u001b[36m332.5248\u001b[0m      629.7717        0.0001  0.3185\n",
      "    101      356.5545      616.0834        0.0050  0.2108\n",
      "    102      380.3346      614.5491        0.0049  0.3183\n",
      "    103      398.0887      637.5033        0.0045  0.1995\n",
      "    104      378.9406      \u001b[32m581.2453\u001b[0m     +  0.0040  0.3142\n",
      "    105      349.0223      606.2848        0.0033  0.2057\n",
      "    106      338.8633      600.6802        0.0025  0.2049\n",
      "    107      335.5689      608.8342        0.0017  0.3122\n",
      "    108      \u001b[36m328.9850\u001b[0m      613.1696        0.0010  0.2217\n",
      "    109      \u001b[36m326.6885\u001b[0m      617.0298        0.0005  0.3066\n",
      "    110      \u001b[36m325.1917\u001b[0m      617.8283        0.0001  0.1995\n",
      "    111      348.4372      602.6718        0.0050  0.3073\n",
      "    112      371.5028      601.8652        0.0049  0.2145\n",
      "    113      389.2951      617.6801        0.0045  0.3146\n",
      "    114      373.2551      \u001b[32m565.9513\u001b[0m     +  0.0040  0.2179\n",
      "    115      343.0055      600.1814        0.0033  0.2131\n",
      "    116      331.0801      587.8258        0.0025  0.3395\n",
      "    117      328.6127      601.4358        0.0017  0.2077\n",
      "    118      \u001b[36m322.4328\u001b[0m      604.6127        0.0010  0.3094\n",
      "    119      \u001b[36m320.2317\u001b[0m      608.9314        0.0005  0.1974\n",
      "    120      \u001b[36m318.7491\u001b[0m      609.8400        0.0001  0.2988\n",
      "    121      341.2662      593.1147        0.0050  0.2084\n",
      "    122      363.0614      590.6886        0.0049  0.3112\n",
      "    123      380.3235      595.1151        0.0045  0.2133\n",
      "    124      371.4795      \u001b[32m563.5327\u001b[0m     +  0.0040  0.2101\n",
      "    125      338.9000      586.2892        0.0033  0.3065\n",
      "    126      325.3983      583.5573        0.0025  0.2126\n",
      "    127      323.1099      597.4647        0.0017  0.3005\n",
      "    128      \u001b[36m316.8542\u001b[0m      596.7722        0.0010  0.2038\n",
      "    129      \u001b[36m314.8234\u001b[0m      601.5051        0.0005  0.3275\n",
      "    130      \u001b[36m313.4118\u001b[0m      602.5449        0.0001  0.1994\n",
      "    131      335.3749      579.5540        0.0050  0.2945\n",
      "    132      354.0465      584.1051        0.0049  0.1957\n",
      "    133      370.4193      587.3240        0.0045  0.2071\n",
      "    134      366.5024      \u001b[32m558.9140\u001b[0m     +  0.0040  0.3010\n",
      "    135      337.2235      581.9223        0.0033  0.2029\n",
      "    136      319.0916      586.2779        0.0025  0.3279\n",
      "    137      317.4771      589.9197        0.0017  0.2120\n",
      "    138      \u001b[36m311.6627\u001b[0m      592.8882        0.0010  0.3059\n",
      "    139      \u001b[36m309.6292\u001b[0m      600.0182        0.0005  0.2153\n",
      "    140      \u001b[36m308.1836\u001b[0m      600.7086        0.0001  0.3097\n",
      "    141      329.3137      571.6876        0.0050  0.2037\n",
      "    142      346.0008      582.6557        0.0049  0.2063\n",
      "    143      362.8440      578.1889        0.0045  0.3064\n",
      "    144      360.5566      \u001b[32m554.4164\u001b[0m     +  0.0040  0.2012\n",
      "    145      333.8958      573.9197        0.0033  0.3155\n",
      "    146      314.1948      589.0317        0.0025  0.2029\n",
      "    147      312.3842      589.8140        0.0017  0.3060\n",
      "    148      \u001b[36m306.9489\u001b[0m      587.7827        0.0010  0.1995\n",
      "    149      \u001b[36m304.8932\u001b[0m      593.7404        0.0005  0.3008\n",
      "    150      \u001b[36m303.4931\u001b[0m      594.1856        0.0001  0.2050\n",
      "    151      323.6814      569.8639        0.0050  0.2023\n",
      "    152      338.8059      573.2368        0.0049  0.3112\n",
      "    153      354.3727      572.6459        0.0045  0.2016\n",
      "    154      354.8938      \u001b[32m548.0980\u001b[0m     +  0.0040  0.3011\n",
      "    155      331.7120      567.9155        0.0033  0.2057\n",
      "    156      309.8161      584.1971        0.0025  0.4347\n",
      "    157      307.2432      582.9849        0.0017  0.4828\n",
      "    158      \u001b[36m302.7251\u001b[0m      581.8653        0.0010  0.5449\n",
      "    159      \u001b[36m300.4111\u001b[0m      589.2445        0.0005  0.1999\n",
      "    160      \u001b[36m299.0097\u001b[0m      589.2886        0.0001  0.2054\n",
      "    161      318.7730      569.1520        0.0050  0.3009\n",
      "    162      331.5542      566.7533        0.0049  0.2009\n",
      "    163      346.9564      571.3202        0.0045  0.3189\n",
      "    164      351.4089      \u001b[32m546.5550\u001b[0m     +  0.0040  0.2035\n",
      "    165      329.7711      564.4350        0.0033  0.3129\n",
      "    166      305.7328      586.7379        0.0025  0.2232\n",
      "    167      302.5577      582.5109        0.0017  0.3163\n",
      "    168      \u001b[36m298.8581\u001b[0m      580.6409        0.0010  0.2085\n",
      "    169      \u001b[36m296.0728\u001b[0m      587.5646        0.0005  0.1997\n",
      "    170      \u001b[36m294.7101\u001b[0m      587.0889        0.0001  0.3040\n",
      "    171      313.9026      566.3124        0.0050  0.2012\n",
      "    172      325.0244      564.9412        0.0049  0.3040\n",
      "    173      337.7491      562.5330        0.0045  0.2305\n",
      "    174      345.4495      547.3403        0.0040  0.4379\n",
      "    175      328.1649      \u001b[32m542.2088\u001b[0m     +  0.0033  0.2244\n",
      "    176      304.0384      600.6219        0.0025  0.5183\n",
      "    177      297.5288      585.0977        0.0017  0.2584\n",
      "    178      295.2059      584.3246        0.0010  0.2070\n",
      "    179      \u001b[36m291.8209\u001b[0m      588.7243        0.0005  0.3081\n",
      "    180      \u001b[36m290.5440\u001b[0m      587.7996        0.0001  0.2219\n",
      "    181      308.6906      563.1122        0.0050  0.3176\n",
      "    182      318.8775      565.3583        0.0049  0.2146\n",
      "    183      330.2776      557.4941        0.0045  0.3157\n",
      "    184      338.2686      546.7507        0.0040  0.3432\n",
      "    185      324.7277      \u001b[32m536.3244\u001b[0m     +  0.0033  0.6805\n",
      "    186      302.3842      598.5515        0.0025  0.5233\n",
      "    187      292.6085      578.1754        0.0017  0.2977\n",
      "    188      291.8057      581.8857        0.0010  0.3711\n",
      "    189      \u001b[36m287.8613\u001b[0m      583.3461        0.0005  0.2936\n",
      "    190      \u001b[36m286.6748\u001b[0m      582.5445        0.0001  0.3006\n",
      "    191      304.4657      566.0200        0.0050  0.2066\n",
      "    192      313.9920      566.3117        0.0049  0.3061\n",
      "    193      323.5837      546.2462        0.0045  0.2051\n",
      "    194      332.5163      549.7474        0.0040  0.3081\n",
      "    195      323.4297      \u001b[32m529.9014\u001b[0m     +  0.0033  0.2130\n",
      "    196      303.2886      606.1939        0.0025  0.2072\n",
      "    197      289.1116      580.1915        0.0017  0.3173\n",
      "    198      289.1760      586.8790        0.0010  0.2038\n",
      "    199      \u001b[36m284.2992\u001b[0m      583.6400        0.0005  0.3043\n",
      "    200      \u001b[36m283.1788\u001b[0m      582.7214        0.0001  0.2256\n",
      "    201      299.6327      563.8211        0.0050  0.3107\n",
      "    202      310.1709      561.8278        0.0049  0.2105\n",
      "    203      314.5480      555.7744        0.0045  0.3016\n",
      "    204      324.7757      550.3387        0.0040  0.2016\n",
      "    205      321.5094      \u001b[32m529.4540\u001b[0m     +  0.0033  0.2068\n",
      "    206      304.8000      609.2293        0.0025  0.3268\n",
      "    207      287.4462      585.0985        0.0017  0.2987\n",
      "    208      286.3871      592.1639        0.0010  0.5397\n",
      "    209      \u001b[36m281.9422\u001b[0m      584.8420        0.0005  0.2036\n",
      "    210      \u001b[36m280.7323\u001b[0m      584.3873        0.0001  0.2979\n",
      "    211      295.2921      560.8485        0.0050  0.2039\n",
      "    212      305.0820      570.7994        0.0049  0.3080\n",
      "    213      308.8441      549.0110        0.0045  0.2083\n",
      "    214      319.0167      547.0480        0.0040  0.2104\n",
      "    215      316.8205      \u001b[32m525.2369\u001b[0m     +  0.0033  0.3156\n",
      "    216      297.7080      597.8395        0.0025  0.1991\n",
      "    217      281.9300      579.7043        0.0017  0.3090\n",
      "    218      281.4392      583.0981        0.0010  0.2165\n",
      "    219      \u001b[36m277.5920\u001b[0m      577.4897        0.0005  0.3075\n",
      "    220      \u001b[36m276.5421\u001b[0m      577.4711        0.0001  0.2102\n",
      "    221      290.6969      559.3751        0.0050  0.3047\n",
      "    222      298.7518      565.4755        0.0049  0.2105\n",
      "    223      301.4657      560.1000        0.0045  0.2286\n",
      "    224      309.5675      543.1951        0.0040  0.3031\n",
      "    225      314.0603      \u001b[32m521.9723\u001b[0m     +  0.0033  0.2175\n",
      "    226      294.6947      594.9807        0.0025  0.3448\n",
      "    227      278.9312      591.2579        0.0017  0.2135\n",
      "    228      276.8300      591.6044        0.0010  0.3218\n",
      "    229      \u001b[36m274.3398\u001b[0m      578.1171        0.0005  0.2025\n",
      "    230      \u001b[36m273.1431\u001b[0m      578.7889        0.0001  0.3045\n",
      "    231      285.6240      564.5101        0.0050  0.2078\n",
      "    232      293.2477      563.3363        0.0049  0.2223\n",
      "    233      298.7732      548.0040        0.0045  0.3000\n",
      "    234      303.4887      545.8596        0.0040  0.2069\n",
      "    235      310.0876      \u001b[32m517.4521\u001b[0m     +  0.0033  0.3066\n",
      "    236      296.8342      619.1943        0.0025  0.2037\n",
      "    237      278.4114      581.8443        0.0017  0.2987\n",
      "    238      275.5301      588.6649        0.0010  0.2008\n",
      "    239      \u001b[36m272.8290\u001b[0m      573.7678        0.0005  0.3157\n",
      "    240      \u001b[36m271.3311\u001b[0m      575.6945        0.0001  0.2012\n",
      "    241      282.4068      563.2737        0.0050  0.2770\n",
      "    242      289.2024      577.7239        0.0049  0.5939\n",
      "    243      295.5087      552.4154        0.0045  0.3991\n",
      "    244      299.1955      535.2467        0.0040  0.5724\n",
      "    245      305.2243      519.8869        0.0033  0.4782\n",
      "    246      290.3229      593.4129        0.0025  0.3635\n",
      "    247      276.6572      611.5706        0.0017  0.2052\n",
      "    248      271.7529      602.5743        0.0010  0.3029\n",
      "    249      \u001b[36m269.9622\u001b[0m      581.5325        0.0005  0.2057\n",
      "    250      \u001b[36m268.0959\u001b[0m      583.8340        0.0001  0.1983\n",
      "    251      277.7345      576.1624        0.0050  0.3172\n",
      "    252      285.9361      575.4099        0.0049  0.2193\n",
      "    253      292.3677      546.0225        0.0045  0.2979\n",
      "    254      295.6682      548.4159        0.0040  0.2050\n",
      "    255      300.3022      \u001b[32m516.1766\u001b[0m     +  0.0033  0.3155\n",
      "    256      285.4978      595.7561        0.0025  0.2024\n",
      "    257      274.1956      597.5230        0.0017  0.3138\n",
      "    258      268.7328      588.3162        0.0010  0.1972\n",
      "    259      \u001b[36m267.7694\u001b[0m      568.8523        0.0005  0.2102\n",
      "    260      \u001b[36m265.5177\u001b[0m      572.6075        0.0001  0.3130\n",
      "    261      274.3478      579.5791        0.0050  0.3407\n",
      "    262      283.5489      581.0462        0.0049  0.4803\n",
      "    263      292.0174      547.1333        0.0045  0.1989\n",
      "    264      287.0871      550.3094        0.0040  0.3053\n",
      "    265      293.8333      \u001b[32m516.0800\u001b[0m     +  0.0033  0.1999\n",
      "    266      282.3254      587.8852        0.0025  0.3008\n",
      "    267      272.4435      596.2674        0.0017  0.1995\n",
      "    268      266.3348      581.9126        0.0010  0.2138\n",
      "    269      265.5998      566.3106        0.0005  0.3292\n",
      "    270      \u001b[36m263.0285\u001b[0m      570.9191        0.0001  0.2059\n",
      "    271      271.3484      583.9752        0.0050  0.3098\n",
      "    272      280.0783      582.4619        0.0049  0.1983\n",
      "    273      287.8616      554.5377        0.0045  0.3013\n",
      "    274      284.0066      535.1865        0.0040  0.1992\n",
      "    275      288.1851      520.5403        0.0033  0.3074\n",
      "    276      278.0926      563.3839        0.0025  0.2109\n",
      "    277      273.5803      629.8399        0.0017  0.1991\n",
      "    278      266.3056      585.9284        0.0010  0.3162\n",
      "    279      265.0900      568.5975        0.0005  0.2225\n",
      "    280      \u001b[36m261.2509\u001b[0m      573.3657        0.0001  0.3239\n",
      "    281      269.2536      609.7456        0.0050  0.2073\n",
      "    282      281.3184      570.7162        0.0049  0.2893\n",
      "    283      282.3070      548.8349        0.0045  0.1995\n",
      "    284      278.0849      533.4256        0.0040  0.3021\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m899.6308\u001b[0m      \u001b[32m979.6699\u001b[0m     +  0.0050  0.3031\n",
      "      2      929.0188     1269.2008        0.0049  0.2278\n",
      "      3      \u001b[36m662.1933\u001b[0m      \u001b[32m942.0232\u001b[0m     +  0.0045  0.2104\n",
      "      4      698.5738     1032.1921        0.0040  0.3070\n",
      "      5      \u001b[36m612.3457\u001b[0m      957.7404        0.0033  0.2207\n",
      "      6      \u001b[36m590.5502\u001b[0m      \u001b[32m928.9670\u001b[0m     +  0.0025  0.3129\n",
      "      7      \u001b[36m555.4154\u001b[0m      \u001b[32m906.6209\u001b[0m     +  0.0017  0.2232\n",
      "      8      \u001b[36m530.8753\u001b[0m      \u001b[32m886.7767\u001b[0m     +  0.0010  0.3140\n",
      "      9      \u001b[36m514.9278\u001b[0m      \u001b[32m874.4629\u001b[0m     +  0.0005  0.2145\n",
      "     10      \u001b[36m507.1207\u001b[0m      \u001b[32m871.3712\u001b[0m     +  0.0001  0.3132\n",
      "     11      597.7152      \u001b[32m805.3253\u001b[0m     +  0.0050  0.2100\n",
      "     12      694.9903     1019.4993        0.0049  0.2126\n",
      "     13      529.6071      \u001b[32m801.9339\u001b[0m     +  0.0045  0.3151\n",
      "     14      \u001b[36m481.8898\u001b[0m      \u001b[32m795.9544\u001b[0m     +  0.0040  0.2075\n",
      "     15      \u001b[36m475.7539\u001b[0m      \u001b[32m783.9928\u001b[0m     +  0.0033  0.3154\n",
      "     16      \u001b[36m449.8710\u001b[0m      \u001b[32m763.8722\u001b[0m     +  0.0025  0.2111\n",
      "     17      \u001b[36m441.5983\u001b[0m      \u001b[32m754.3272\u001b[0m     +  0.0017  0.3103\n",
      "     18      \u001b[36m432.4989\u001b[0m      \u001b[32m749.8324\u001b[0m     +  0.0010  0.2228\n",
      "     19      \u001b[36m427.9098\u001b[0m      \u001b[32m747.4900\u001b[0m     +  0.0005  0.2112\n",
      "     20      \u001b[36m425.4602\u001b[0m      \u001b[32m746.8982\u001b[0m     +  0.0001  0.3070\n",
      "     21      466.7529      763.3196        0.0050  0.2163\n",
      "     22      514.0260      814.1490        0.0049  0.3138\n",
      "     23      491.9620      782.6816        0.0045  0.2086\n",
      "     24      442.6423      \u001b[32m731.7862\u001b[0m     +  0.0040  0.3239\n",
      "     25      426.5351      \u001b[32m729.6164\u001b[0m     +  0.0033  0.2663\n",
      "     26      \u001b[36m418.3804\u001b[0m      \u001b[32m720.1660\u001b[0m     +  0.0025  0.2395\n",
      "     27      \u001b[36m407.6243\u001b[0m      \u001b[32m713.1971\u001b[0m     +  0.0017  0.5244\n",
      "     28      \u001b[36m401.8895\u001b[0m      \u001b[32m710.0018\u001b[0m     +  0.0010  0.2132\n",
      "     29      \u001b[36m397.6634\u001b[0m      \u001b[32m708.8867\u001b[0m     +  0.0005  0.3067\n",
      "     30      \u001b[36m395.4591\u001b[0m      \u001b[32m708.6819\u001b[0m     +  0.0001  0.2090\n",
      "     31      428.2433      752.9815        0.0050  0.3187\n",
      "     32      505.2726      784.8187        0.0049  0.2197\n",
      "     33      509.3678      785.7937        0.0045  0.3337\n",
      "     34      435.3044      \u001b[32m706.2734\u001b[0m     +  0.0040  0.2244\n",
      "     35      404.0577      \u001b[32m705.2275\u001b[0m     +  0.0033  0.2079\n",
      "     36      402.5456      \u001b[32m700.2387\u001b[0m     +  0.0025  0.3220\n",
      "     37      \u001b[36m390.5746\u001b[0m      \u001b[32m693.2440\u001b[0m     +  0.0017  0.2163\n",
      "     38      \u001b[36m386.6634\u001b[0m      \u001b[32m691.5810\u001b[0m     +  0.0010  0.3119\n",
      "     39      \u001b[36m382.7990\u001b[0m      \u001b[32m690.9004\u001b[0m     +  0.0005  0.2179\n",
      "     40      \u001b[36m380.9019\u001b[0m      \u001b[32m690.8567\u001b[0m     +  0.0001  0.3004\n",
      "     41      407.3219      714.4246        0.0050  0.2066\n",
      "     42      447.5687      742.7240        0.0049  0.3000\n",
      "     43      448.4240      723.0197        0.0045  0.2166\n",
      "     44      409.4548      \u001b[32m675.3933\u001b[0m     +  0.0040  0.2366\n",
      "     45      389.1726      682.4862        0.0033  0.3005\n",
      "     46      385.7437      \u001b[32m671.0460\u001b[0m     +  0.0025  0.2002\n",
      "     47      \u001b[36m375.3951\u001b[0m      \u001b[32m665.4429\u001b[0m     +  0.0017  0.3276\n",
      "     48      \u001b[36m371.1243\u001b[0m      668.4637        0.0010  0.2011\n",
      "     49      \u001b[36m367.4305\u001b[0m      668.0917        0.0005  0.3091\n",
      "     50      \u001b[36m365.6572\u001b[0m      668.1209        0.0001  0.2040\n",
      "     51      391.4849      716.2440        0.0050  0.3016\n",
      "     52      436.9785      748.5646        0.0049  0.2165\n",
      "     53      451.6848      714.3327        0.0045  0.2058\n",
      "     54      407.3011      \u001b[32m661.7421\u001b[0m     +  0.0040  0.3197\n",
      "     55      375.8688      \u001b[32m659.5704\u001b[0m     +  0.0033  0.2061\n",
      "     56      375.5391      \u001b[32m656.5629\u001b[0m     +  0.0025  0.3072\n",
      "     57      \u001b[36m364.9279\u001b[0m      \u001b[32m649.1933\u001b[0m     +  0.0017  0.2034\n",
      "     58      \u001b[36m361.4156\u001b[0m      653.1409        0.0010  0.3007\n",
      "     59      \u001b[36m357.7318\u001b[0m      653.8232        0.0005  0.2054\n",
      "     60      \u001b[36m356.1915\u001b[0m      654.2066        0.0001  0.3224\n",
      "     61      379.4174      694.3119        0.0050  0.4163\n",
      "     62      420.4768      713.4803        0.0049  0.2468\n",
      "     63      435.0681      698.3174        0.0045  0.4162\n",
      "     64      399.5393      \u001b[32m642.6712\u001b[0m     +  0.0040  0.2075\n",
      "     65      367.0190      643.6685        0.0033  0.2978\n",
      "     66      366.0726      \u001b[32m638.0392\u001b[0m     +  0.0025  0.2076\n",
      "     67      357.0753      \u001b[32m635.1153\u001b[0m     +  0.0017  0.3108\n",
      "     68      \u001b[36m353.2009\u001b[0m      644.9902        0.0010  0.2057\n",
      "     69      \u001b[36m349.9509\u001b[0m      646.5025        0.0005  0.2971\n",
      "     70      \u001b[36m348.5477\u001b[0m      647.1555        0.0001  0.2115\n",
      "     71      371.3259      674.1462        0.0050  0.2048\n",
      "     72      408.7227      699.4413        0.0049  0.3319\n",
      "     73      425.5265      682.0710        0.0045  0.2043\n",
      "     74      395.2906      \u001b[32m631.2911\u001b[0m     +  0.0040  0.3071\n",
      "     75      360.0187      \u001b[32m630.5103\u001b[0m     +  0.0033  0.2039\n",
      "     76      358.1176      632.1893        0.0025  0.3005\n",
      "     77      350.7151      \u001b[32m628.9451\u001b[0m     +  0.0017  0.1969\n",
      "     78      \u001b[36m346.4762\u001b[0m      641.9088        0.0010  0.3058\n",
      "     79      \u001b[36m343.4415\u001b[0m      643.0891        0.0005  0.2072\n",
      "     80      \u001b[36m342.1016\u001b[0m      643.6578        0.0001  0.2019\n",
      "     81      365.5283      658.4637        0.0050  0.3361\n",
      "     82      399.4504      687.6360        0.0049  0.2927\n",
      "     83      420.5384      675.2981        0.0045  0.3546\n",
      "     84      390.6819      \u001b[32m618.2912\u001b[0m     +  0.0040  0.1989\n",
      "     85      354.2400      620.4588        0.0033  0.3112\n",
      "     86      351.7017      620.0680        0.0025  0.2048\n",
      "     87      345.5947      \u001b[32m617.6529\u001b[0m     +  0.0017  0.2971\n",
      "     88      \u001b[36m339.9314\u001b[0m      630.0964        0.0010  0.2042\n",
      "     89      \u001b[36m337.1080\u001b[0m      630.8453        0.0005  0.1992\n",
      "     90      \u001b[36m335.6798\u001b[0m      631.5986        0.0001  0.2979\n",
      "     91      359.5277      638.1973        0.0050  0.2150\n",
      "     92      390.0955      677.2141        0.0049  0.2990\n",
      "     93      409.4651      647.1206        0.0045  0.2003\n",
      "     94      388.5750      \u001b[32m614.1468\u001b[0m     +  0.0040  0.3035\n",
      "     95      348.8088      \u001b[32m598.4705\u001b[0m     +  0.0033  0.2131\n",
      "     96      343.0254      615.9907        0.0025  0.3084\n",
      "     97      341.5251      613.8498        0.0017  0.2104\n",
      "     98      \u001b[36m331.5647\u001b[0m      611.6146        0.0010  0.2050\n",
      "     99      \u001b[36m329.6521\u001b[0m      619.0052        0.0005  0.3175\n",
      "    100      \u001b[36m328.0546\u001b[0m      619.5963        0.0001  0.1911\n",
      "    101      352.2711      612.1059        0.0050  0.3619\n",
      "    102      376.3581      648.1268        0.0049  0.4508\n",
      "    103      397.1824      629.4986        0.0045  0.3909\n",
      "    104      381.0032      \u001b[32m577.8617\u001b[0m     +  0.0040  0.2112\n",
      "    105      345.1153      578.9952        0.0033  0.5153\n",
      "    106      331.6791      596.9889        0.0025  0.4955\n",
      "    107      \u001b[36m327.5535\u001b[0m      585.8176        0.0017  0.3881\n",
      "    108      \u001b[36m321.3863\u001b[0m      589.1693        0.0010  0.2998\n",
      "    109      \u001b[36m318.6447\u001b[0m      595.6450        0.0005  0.2137\n",
      "    110      \u001b[36m317.0391\u001b[0m      595.5907        0.0001  0.3130\n",
      "    111      341.7770      588.4689        0.0050  0.2054\n",
      "    112      361.0805      619.1997        0.0049  0.3139\n",
      "    113      381.3193      614.5195        0.0045  0.2221\n",
      "    114      379.5785      \u001b[32m570.4992\u001b[0m     +  0.0040  0.3009\n",
      "    115      341.4742      \u001b[32m561.9600\u001b[0m     +  0.0033  0.2068\n",
      "    116      324.3099      594.1448        0.0025  0.1965\n",
      "    117      317.8569      577.6358        0.0017  0.3102\n",
      "    118      \u001b[36m313.2134\u001b[0m      580.5011        0.0010  0.2153\n",
      "    119      \u001b[36m310.5491\u001b[0m      586.2858        0.0005  0.3073\n",
      "    120      \u001b[36m309.0570\u001b[0m      585.9029        0.0001  0.2054\n",
      "    121      332.5187      570.7364        0.0050  0.2987\n",
      "    122      349.7648      608.2095        0.0049  0.2083\n",
      "    123      368.9110      603.9009        0.0045  0.3069\n",
      "    124      373.4604      561.9920        0.0040  0.2001\n",
      "    125      335.2172      \u001b[32m542.2759\u001b[0m     +  0.0033  0.2049\n",
      "    126      318.5910      597.6799        0.0025  0.3298\n",
      "    127      309.3910      581.9178        0.0017  0.2475\n",
      "    128      \u001b[36m305.8136\u001b[0m      584.7859        0.0010  0.3214\n",
      "    129      \u001b[36m303.2824\u001b[0m      583.6775        0.0005  0.2039\n",
      "    130      \u001b[36m301.9749\u001b[0m      583.7732        0.0001  0.3051\n",
      "    131      323.6370      564.0085        0.0050  0.2008\n",
      "    132      340.1141      588.1931        0.0049  0.3108\n",
      "    133      357.5779      595.3438        0.0045  0.2246\n",
      "    134      367.3855      562.8237        0.0040  0.2466\n",
      "    135      331.1772      \u001b[32m534.4216\u001b[0m     +  0.0033  0.3419\n",
      "    136      316.1302      602.4010        0.0025  0.2309\n",
      "    137      303.7602      579.0302        0.0017  0.3156\n",
      "    138      \u001b[36m301.2083\u001b[0m      582.7370        0.0010  0.2079\n",
      "    139      \u001b[36m298.5101\u001b[0m      579.9192        0.0005  0.2995\n",
      "    140      \u001b[36m297.2633\u001b[0m      580.2550        0.0001  0.2156\n",
      "    141      317.0582      560.7430        0.0050  0.3131\n",
      "    142      331.5309      567.3335        0.0049  0.2101\n",
      "    143      345.4164      573.6990        0.0045  0.2007\n",
      "    144      358.2589      562.6010        0.0040  0.3062\n",
      "    145      332.5851      \u001b[32m531.6890\u001b[0m     +  0.0033  0.2083\n",
      "    146      314.6040      642.1214        0.0025  0.3278\n",
      "    147      300.1219      592.2604        0.0017  0.2145\n",
      "    148      298.0109      597.5788        0.0010  0.2975\n",
      "    149      \u001b[36m293.8663\u001b[0m      593.7288        0.0005  0.2054\n",
      "    150      \u001b[36m292.6650\u001b[0m      592.5549        0.0001  0.3054\n",
      "    151      311.3565      559.4183        0.0050  0.2132\n",
      "    152      321.5606      564.1979        0.0049  0.2054\n",
      "    153      335.8165      556.1043        0.0045  0.3073\n",
      "    154      345.2755      551.1260        0.0040  0.2068\n",
      "    155      326.9664      \u001b[32m519.9456\u001b[0m     +  0.0033  0.3356\n",
      "    156      311.6500      624.6217        0.0025  0.2640\n",
      "    157      295.6459      584.5488        0.0017  0.3284\n",
      "    158      293.2130      589.3445        0.0010  0.2015\n",
      "    159      \u001b[36m289.5195\u001b[0m      581.2049        0.0005  0.3003\n",
      "    160      \u001b[36m288.3345\u001b[0m      581.5119        0.0001  0.2031\n",
      "    161      305.4539      564.9373        0.0050  0.2024\n",
      "    162      315.7171      567.1694        0.0049  0.2990\n",
      "    163      326.9525      549.4507        0.0045  0.1991\n",
      "    164      335.9804      539.2590        0.0040  0.3076\n",
      "    165      324.9697      520.5837        0.0033  0.2013\n",
      "    166      312.3193      621.9014        0.0025  0.3037\n",
      "    167      293.3274      583.9931        0.0017  0.2035\n",
      "    168      290.2404      589.1921        0.0010  0.3055\n",
      "    169      \u001b[36m286.0891\u001b[0m      579.8843        0.0005  0.2062\n",
      "    170      \u001b[36m284.6288\u001b[0m      581.2502        0.0001  0.2054\n",
      "    171      300.7501      560.6384        0.0050  0.3063\n",
      "    172      310.5535      574.3676        0.0049  0.2096\n",
      "    173      323.9640      549.8377        0.0045  0.3156\n",
      "    174      329.8914      542.9303        0.0040  0.2063\n",
      "    175      322.1938      \u001b[32m516.0520\u001b[0m     +  0.0033  0.3165\n",
      "    176      305.7824      622.0219        0.0025  0.2565\n",
      "    177      289.6267      585.9893        0.0017  0.3226\n",
      "    178      285.8140      588.6961        0.0010  0.2256\n",
      "    179      \u001b[36m283.0329\u001b[0m      575.8615        0.0005  0.2069\n",
      "    180      \u001b[36m281.5532\u001b[0m      577.9196        0.0001  0.3051\n",
      "    181      295.7645      571.6921        0.0050  0.2122\n",
      "    182      306.1976      561.2236        0.0049  0.3064\n",
      "    183      318.6413      544.6864        0.0045  0.2026\n",
      "    184      326.6810      539.6157        0.0040  0.2986\n",
      "    185      322.1361      522.9296        0.0033  0.2002\n",
      "    186      307.8551      616.0247        0.0025  0.3366\n",
      "    187      288.8076      582.0702        0.0017  0.2068\n",
      "    188      284.9193      584.0230        0.0010  0.2159\n",
      "    189      \u001b[36m280.5409\u001b[0m      570.8349        0.0005  0.3145\n",
      "    190      \u001b[36m278.9551\u001b[0m      573.3438        0.0001  0.2119\n",
      "    191      292.3912      589.6676        0.0050  0.2937\n",
      "    192      302.6981      560.9133        0.0049  0.2044\n",
      "    193      311.7146      539.8967        0.0045  0.3091\n",
      "    194      318.2529      534.8387        0.0040  0.2072\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m892.1009\u001b[0m      \u001b[32m996.8578\u001b[0m     +  0.0050  0.2101\n",
      "      2      927.3213     1250.7474        0.0049  0.3354\n",
      "      3      \u001b[36m667.9276\u001b[0m      \u001b[32m944.2763\u001b[0m     +  0.0045  0.2215\n",
      "      4      702.0198     1018.0483        0.0040  0.3232\n",
      "      5      \u001b[36m613.0263\u001b[0m      \u001b[32m943.2880\u001b[0m     +  0.0033  0.2178\n",
      "      6      \u001b[36m591.0293\u001b[0m      \u001b[32m923.1759\u001b[0m     +  0.0025  0.2106\n",
      "      7      \u001b[36m556.1055\u001b[0m      \u001b[32m903.7923\u001b[0m     +  0.0017  0.3109\n",
      "      8      \u001b[36m532.8135\u001b[0m      \u001b[32m882.0443\u001b[0m     +  0.0010  0.2426\n",
      "      9      \u001b[36m518.8359\u001b[0m      \u001b[32m872.6435\u001b[0m     +  0.0005  0.3611\n",
      "     10      \u001b[36m511.8038\u001b[0m      \u001b[32m870.1658\u001b[0m     +  0.0001  0.2147\n",
      "     11      591.1549      \u001b[32m834.0864\u001b[0m     +  0.0050  0.2083\n",
      "     12      651.8110      945.2467        0.0049  0.3133\n",
      "     13      526.7406      834.0879        0.0045  0.2054\n",
      "     14      \u001b[36m476.9742\u001b[0m      \u001b[32m785.9367\u001b[0m     +  0.0040  0.3253\n",
      "     15      \u001b[36m469.7821\u001b[0m      \u001b[32m779.5755\u001b[0m     +  0.0033  0.2731\n",
      "     16      \u001b[36m447.1979\u001b[0m      \u001b[32m756.7586\u001b[0m     +  0.0025  0.4128\n",
      "     17      \u001b[36m435.8654\u001b[0m      \u001b[32m745.5382\u001b[0m     +  0.0017  0.2119\n",
      "     18      \u001b[36m427.0684\u001b[0m      \u001b[32m739.6786\u001b[0m     +  0.0010  0.3239\n",
      "     19      \u001b[36m422.0848\u001b[0m      \u001b[32m737.1477\u001b[0m     +  0.0005  0.2051\n",
      "     20      \u001b[36m419.4469\u001b[0m      \u001b[32m736.5038\u001b[0m     +  0.0001  0.2106\n",
      "     21      461.4255      753.7778        0.0050  0.3047\n",
      "     22      520.0244      790.5006        0.0049  0.2152\n",
      "     23      499.6335      796.9547        0.0045  0.3058\n",
      "     24      442.3772      \u001b[32m717.1117\u001b[0m     +  0.0040  0.2155\n",
      "     25      423.2620      719.4252        0.0033  0.3136\n",
      "     26      \u001b[36m417.0260\u001b[0m      \u001b[32m713.2607\u001b[0m     +  0.0025  0.2154\n",
      "     27      \u001b[36m406.0596\u001b[0m      \u001b[32m706.0034\u001b[0m     +  0.0017  0.2139\n",
      "     28      \u001b[36m401.0434\u001b[0m      \u001b[32m702.9394\u001b[0m     +  0.0010  0.3042\n",
      "     29      \u001b[36m397.0274\u001b[0m      \u001b[32m702.0946\u001b[0m     +  0.0005  0.2182\n",
      "     30      \u001b[36m394.9763\u001b[0m      \u001b[32m701.9290\u001b[0m     +  0.0001  0.3086\n",
      "     31      425.0882      717.3113        0.0050  0.2008\n",
      "     32      467.8994      754.8449        0.0049  0.3081\n",
      "     33      466.0268      746.4225        0.0045  0.2136\n",
      "     34      427.1342      \u001b[32m695.7608\u001b[0m     +  0.0040  0.3134\n",
      "     35      402.3961      \u001b[32m690.1769\u001b[0m     +  0.0033  0.2388\n",
      "     36      398.3102      \u001b[32m685.0039\u001b[0m     +  0.0025  0.2068\n",
      "     37      \u001b[36m388.5846\u001b[0m      \u001b[32m684.2649\u001b[0m     +  0.0017  0.3079\n",
      "     38      \u001b[36m383.9742\u001b[0m      684.2709        0.0010  0.2073\n",
      "     39      \u001b[36m380.1636\u001b[0m      \u001b[32m684.0818\u001b[0m     +  0.0005  0.3136\n",
      "     40      \u001b[36m378.2634\u001b[0m      684.1676        0.0001  0.2494\n",
      "     41      406.8859      700.3940        0.0050  0.4274\n",
      "     42      447.5030      726.4588        0.0049  0.2018\n",
      "     43      453.9322      721.2490        0.0045  0.2504\n",
      "     44      417.8699      \u001b[32m672.7407\u001b[0m     +  0.0040  0.5489\n",
      "     45      389.1204      \u001b[32m668.8503\u001b[0m     +  0.0033  0.4721\n",
      "     46      386.4406      \u001b[32m665.2825\u001b[0m     +  0.0025  0.2987\n",
      "     47      \u001b[36m376.7084\u001b[0m      \u001b[32m664.8605\u001b[0m     +  0.0017  0.2099\n",
      "     48      \u001b[36m372.9201\u001b[0m      665.6406        0.0010  0.3174\n",
      "     49      \u001b[36m369.3136\u001b[0m      665.7266        0.0005  0.2049\n",
      "     50      \u001b[36m367.6435\u001b[0m      666.0267        0.0001  0.2062\n",
      "     51      392.8331      676.2786        0.0050  0.3080\n",
      "     52      429.4627      701.0794        0.0049  0.2051\n",
      "     53      440.4793      701.7655        0.0045  0.2998\n",
      "     54      410.2906      \u001b[32m646.5694\u001b[0m     +  0.0040  0.1959\n",
      "     55      378.8986      650.1057        0.0033  0.2994\n",
      "     56      376.6233      \u001b[32m639.6037\u001b[0m     +  0.0025  0.2059\n",
      "     57      367.7763      646.2304        0.0017  0.3024\n",
      "     58      \u001b[36m362.6246\u001b[0m      642.7012        0.0010  0.2031\n",
      "     59      \u001b[36m359.1745\u001b[0m      641.6137        0.0005  0.2018\n",
      "     60      \u001b[36m357.4218\u001b[0m      641.9080        0.0001  0.3375\n",
      "     61      383.9192      656.3928        0.0050  0.2047\n",
      "     62      412.1529      656.3825        0.0049  0.3180\n",
      "     63      428.4829      698.7231        0.0045  0.2174\n",
      "     64      410.1626      \u001b[32m619.0744\u001b[0m     +  0.0040  0.3479\n",
      "     65      370.6263      \u001b[32m612.2109\u001b[0m     +  0.0033  0.2138\n",
      "     66      367.1909      615.1927        0.0025  0.3192\n",
      "     67      358.8293      619.3838        0.0017  0.3250\n",
      "     68      \u001b[36m351.3456\u001b[0m      615.2428        0.0010  0.2099\n",
      "     69      \u001b[36m348.2831\u001b[0m      616.3759        0.0005  0.3022\n",
      "     70      \u001b[36m346.5523\u001b[0m      617.4111        0.0001  0.2024\n",
      "     71      372.3278      628.4545        0.0050  0.3007\n",
      "     72      401.8378      633.2194        0.0049  0.2033\n",
      "     73      416.1733      661.8940        0.0045  0.2974\n",
      "     74      394.9146      \u001b[32m589.5678\u001b[0m     +  0.0040  0.2036\n",
      "     75      368.8487      604.5994        0.0033  0.3030\n",
      "     76      352.9207      593.8659        0.0025  0.2133\n",
      "     77      350.0622      595.4280        0.0017  0.2019\n",
      "     78      \u001b[36m341.5584\u001b[0m      598.7629        0.0010  0.3058\n",
      "     79      \u001b[36m339.0540\u001b[0m      603.9758        0.0005  0.2040\n",
      "     80      \u001b[36m337.1686\u001b[0m      604.6300        0.0001  0.2991\n",
      "     81      361.8606      607.1660        0.0050  0.2271\n",
      "     82      386.6981      618.6500        0.0049  0.3532\n",
      "     83      402.9463      635.4222        0.0045  0.2104\n",
      "     84      394.8160      \u001b[32m577.7150\u001b[0m     +  0.0040  0.3008\n",
      "     85      359.5870      588.3799        0.0033  0.2034\n",
      "     86      344.6985      580.2052        0.0025  0.2059\n",
      "     87      341.2669      587.7426        0.0017  0.3056\n",
      "     88      \u001b[36m333.2801\u001b[0m      588.8404        0.0010  0.1981\n",
      "     89      \u001b[36m331.0747\u001b[0m      593.2373        0.0005  0.3206\n",
      "     90      \u001b[36m329.3335\u001b[0m      593.9146        0.0001  0.2002\n",
      "     91      353.7405      594.5061        0.0050  0.2941\n",
      "     92      377.0370      604.1026        0.0049  0.2062\n",
      "     93      393.4070      623.0799        0.0045  0.3154\n",
      "     94      390.6709      \u001b[32m571.4133\u001b[0m     +  0.0040  0.2065\n",
      "     95      354.6598      572.8639        0.0033  0.2121\n",
      "     96      336.1878      586.4121        0.0025  0.3013\n",
      "     97      333.7632      581.3723        0.0017  0.2039\n",
      "     98      \u001b[36m326.6958\u001b[0m      582.7379        0.0010  0.3024\n",
      "     99      \u001b[36m324.2872\u001b[0m      588.1932        0.0005  0.2167\n",
      "    100      \u001b[36m322.6359\u001b[0m      588.8101        0.0001  0.3093\n",
      "    101      346.0522      584.3432        0.0050  0.2249\n",
      "    102      366.7800      598.8852        0.0049  0.3302\n",
      "    103      382.8349      611.7226        0.0045  0.2071\n",
      "    104      386.6055      \u001b[32m562.8220\u001b[0m     +  0.0040  0.2044\n",
      "    105      351.2159      566.7731        0.0033  0.2957\n",
      "    106      329.3758      582.1161        0.0025  0.2067\n",
      "    107      327.6838      578.3001        0.0017  0.4565\n",
      "    108      \u001b[36m320.7022\u001b[0m      576.2044        0.0010  0.2475\n",
      "    109      \u001b[36m318.3859\u001b[0m      582.4259        0.0005  0.3039\n",
      "    110      \u001b[36m316.7899\u001b[0m      583.0477        0.0001  0.2113\n",
      "    111      339.4155      577.5495        0.0050  0.2983\n",
      "    112      358.2130      591.0686        0.0049  0.2068\n",
      "    113      372.9547      595.8694        0.0045  0.2171\n",
      "    114      380.4796      564.7557        0.0040  0.3042\n",
      "    115      346.5777      \u001b[32m561.7330\u001b[0m     +  0.0033  0.1993\n",
      "    116      323.6430      584.2104        0.0025  0.2983\n",
      "    117      321.5182      576.9380        0.0017  0.2083\n",
      "    118      \u001b[36m315.3010\u001b[0m      576.5719        0.0010  0.3181\n",
      "    119      \u001b[36m312.9052\u001b[0m      583.5111        0.0005  0.2063\n",
      "    120      \u001b[36m311.3462\u001b[0m      583.6777        0.0001  0.3296\n",
      "    121      333.1282      571.5219        0.0050  0.2108\n",
      "    122      350.7966      584.8352        0.0049  0.2062\n",
      "    123      366.8015      583.6978        0.0045  0.3093\n",
      "    124      370.7695      564.1416        0.0040  0.1990\n",
      "    125      344.0085      \u001b[32m553.6411\u001b[0m     +  0.0033  0.3009\n",
      "    126      318.8088      585.2196        0.0025  0.1989\n",
      "    127      315.3657      573.8856        0.0017  0.3018\n",
      "    128      \u001b[36m310.5411\u001b[0m      577.4133        0.0010  0.2054\n",
      "    129      \u001b[36m307.5868\u001b[0m      583.9708        0.0005  0.3217\n",
      "    130      \u001b[36m306.0603\u001b[0m      583.4080        0.0001  0.2044\n",
      "    131      327.2970      562.0535        0.0050  0.2030\n",
      "    132      342.5270      575.4541        0.0049  0.3074\n",
      "    133      358.6264      576.1422        0.0045  0.2070\n",
      "    134      359.3976      559.0681        0.0040  0.3089\n",
      "    135      348.8103      \u001b[32m540.8625\u001b[0m     +  0.0033  0.2009\n",
      "    136      318.5013      589.2556        0.0025  0.3070\n",
      "    137      310.4644      569.0089        0.0017  0.2064\n",
      "    138      307.0843      579.3580        0.0010  0.2991\n",
      "    139      \u001b[36m303.6242\u001b[0m      583.6008        0.0005  0.2338\n",
      "    140      \u001b[36m302.1576\u001b[0m      583.1899        0.0001  0.2264\n",
      "    141      322.7795      568.1111        0.0050  0.3227\n",
      "    142      339.4796      570.7450        0.0049  0.2097\n",
      "    143      351.7195      566.9698        0.0045  0.3176\n",
      "    144      360.5803      566.3204        0.0040  0.2155\n",
      "    145      342.9068      542.0887        0.0033  0.3008\n",
      "    146      313.8988      610.7991        0.0025  0.2057\n",
      "    147      306.3855      590.2050        0.0017  0.3061\n",
      "    148      302.6349      585.4939        0.0010  0.2424\n",
      "    149      \u001b[36m299.0468\u001b[0m      589.1162        0.0005  0.2285\n",
      "    150      \u001b[36m297.6840\u001b[0m      588.0554        0.0001  0.3075\n",
      "    151      317.1904      568.8793        0.0050  0.2156\n",
      "    152      331.1128      561.9579        0.0049  0.3028\n",
      "    153      343.6871      563.3312        0.0045  0.2029\n",
      "    154      354.4753      559.1579        0.0040  0.2988\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m889.3794\u001b[0m      \u001b[32m971.9566\u001b[0m     +  0.0050  0.3043\n",
      "      2      910.7832     1217.6847        0.0049  0.3766\n",
      "      3      \u001b[36m669.1076\u001b[0m      \u001b[32m948.9118\u001b[0m     +  0.0045  0.4615\n",
      "      4      697.0442     1008.4604        0.0040  0.2292\n",
      "      5      \u001b[36m620.7062\u001b[0m      \u001b[32m943.0454\u001b[0m     +  0.0033  0.2148\n",
      "      6      \u001b[36m595.9050\u001b[0m      \u001b[32m917.0070\u001b[0m     +  0.0025  0.3113\n",
      "      7      \u001b[36m564.4474\u001b[0m      \u001b[32m901.3350\u001b[0m     +  0.0017  0.2132\n",
      "      8      \u001b[36m542.7495\u001b[0m      \u001b[32m883.9663\u001b[0m     +  0.0010  0.3203\n",
      "      9      \u001b[36m530.2076\u001b[0m      \u001b[32m875.9442\u001b[0m     +  0.0005  0.2202\n",
      "     10      \u001b[36m523.9294\u001b[0m      \u001b[32m873.8570\u001b[0m     +  0.0001  0.3123\n",
      "     11      602.8970      \u001b[32m869.4663\u001b[0m     +  0.0050  0.2077\n",
      "     12      636.6177      937.9959        0.0049  0.2230\n",
      "     13      531.1126      \u001b[32m826.7450\u001b[0m     +  0.0045  0.3067\n",
      "     14      \u001b[36m497.0498\u001b[0m      \u001b[32m820.6198\u001b[0m     +  0.0040  0.2128\n",
      "     15      \u001b[36m485.0919\u001b[0m      \u001b[32m796.3287\u001b[0m     +  0.0033  0.3071\n",
      "     16      \u001b[36m462.3764\u001b[0m      \u001b[32m771.5334\u001b[0m     +  0.0025  0.2101\n",
      "     17      \u001b[36m451.5297\u001b[0m      \u001b[32m760.9615\u001b[0m     +  0.0017  0.3126\n",
      "     18      \u001b[36m442.1275\u001b[0m      \u001b[32m753.1383\u001b[0m     +  0.0010  0.2236\n",
      "     19      \u001b[36m436.7089\u001b[0m      \u001b[32m749.0508\u001b[0m     +  0.0005  0.2148\n",
      "     20      \u001b[36m433.7404\u001b[0m      \u001b[32m748.0160\u001b[0m     +  0.0001  0.3049\n",
      "     21      478.9960      754.3596        0.0050  0.2122\n",
      "     22      535.8229      847.8821        0.0049  0.3159\n",
      "     23      504.5238      777.5570        0.0045  0.2068\n",
      "     24      448.4980      \u001b[32m736.7425\u001b[0m     +  0.0040  0.3158\n",
      "     25      438.8545      \u001b[32m730.8755\u001b[0m     +  0.0033  0.3842\n",
      "     26      \u001b[36m427.4457\u001b[0m      \u001b[32m714.0903\u001b[0m     +  0.0025  0.3185\n",
      "     27      \u001b[36m417.2301\u001b[0m      \u001b[32m706.7971\u001b[0m     +  0.0017  0.2109\n",
      "     28      \u001b[36m410.4234\u001b[0m      \u001b[32m702.3737\u001b[0m     +  0.0010  0.2220\n",
      "     29      \u001b[36m406.0266\u001b[0m      \u001b[32m700.6968\u001b[0m     +  0.0005  0.3312\n",
      "     30      \u001b[36m403.6856\u001b[0m      \u001b[32m700.3212\u001b[0m     +  0.0001  0.2160\n",
      "     31      436.5269      746.4959        0.0050  0.3221\n",
      "     32      479.3047      796.4792        0.0049  0.2108\n",
      "     33      474.0446      734.7758        0.0045  0.2963\n",
      "     34      428.0660      \u001b[32m693.6711\u001b[0m     +  0.0040  0.2074\n",
      "     35      412.6960      \u001b[32m685.3127\u001b[0m     +  0.0033  0.2100\n",
      "     36      405.5581      \u001b[32m682.3138\u001b[0m     +  0.0025  0.3087\n",
      "     37      \u001b[36m395.1578\u001b[0m      \u001b[32m675.1058\u001b[0m     +  0.0017  0.2054\n",
      "     38      \u001b[36m390.1233\u001b[0m      \u001b[32m673.8867\u001b[0m     +  0.0010  0.3001\n",
      "     39      \u001b[36m386.3378\u001b[0m      674.0010        0.0005  0.1994\n",
      "     40      \u001b[36m384.3918\u001b[0m      674.1136        0.0001  0.3054\n",
      "     41      412.4968      722.2544        0.0050  0.2056\n",
      "     42      454.7128      744.1441        0.0049  0.2079\n",
      "     43      454.8123      731.0752        0.0045  0.3501\n",
      "     44      414.8587      \u001b[32m652.2520\u001b[0m     +  0.0040  0.3588\n",
      "     45      395.1401      674.1799        0.0033  0.3433\n",
      "     46      391.8467      653.3027        0.0025  0.1921\n",
      "     47      \u001b[36m381.2491\u001b[0m      \u001b[32m651.4193\u001b[0m     +  0.0017  0.3094\n",
      "     48      \u001b[36m377.1736\u001b[0m      655.8149        0.0010  0.2044\n",
      "     49      \u001b[36m373.7120\u001b[0m      656.8698        0.0005  0.2974\n",
      "     50      \u001b[36m372.0065\u001b[0m      657.3227        0.0001  0.2039\n",
      "     51      397.6861      701.3715        0.0050  0.2042\n",
      "     52      437.2654      740.7263        0.0049  0.3014\n",
      "     53      443.8488      693.6493        0.0045  0.1992\n",
      "     54      405.9477      \u001b[32m641.0418\u001b[0m     +  0.0040  0.3141\n",
      "     55      383.2966      644.9838        0.0033  0.2047\n",
      "     56      381.4535      644.2834        0.0025  0.3069\n",
      "     57      \u001b[36m371.6440\u001b[0m      \u001b[32m639.5229\u001b[0m     +  0.0017  0.2137\n",
      "     58      \u001b[36m368.0997\u001b[0m      646.9790        0.0010  0.3118\n",
      "     59      \u001b[36m364.7695\u001b[0m      648.6998        0.0005  0.1977\n",
      "     60      \u001b[36m363.2493\u001b[0m      649.3595        0.0001  0.1977\n",
      "     61      386.9575      682.1655        0.0050  0.3048\n",
      "     62      422.5931      714.5422        0.0049  0.2201\n",
      "     63      431.8560      682.6549        0.0045  0.4067\n",
      "     64      400.5601      \u001b[32m625.1899\u001b[0m     +  0.0040  0.2190\n",
      "     65      373.6982      636.5495        0.0033  0.3042\n",
      "     66      373.1279      626.1415        0.0025  0.2002\n",
      "     67      363.8178      630.6843        0.0017  0.3006\n",
      "     68      \u001b[36m360.3517\u001b[0m      638.7515        0.0010  0.2204\n",
      "     69      \u001b[36m357.2800\u001b[0m      640.4159        0.0005  0.2021\n",
      "     70      \u001b[36m355.8707\u001b[0m      641.4723        0.0001  0.3058\n",
      "     71      379.1181      665.6069        0.0050  0.1980\n",
      "     72      410.8985      684.9048        0.0049  0.2983\n",
      "     73      423.2877      677.3567        0.0045  0.1992\n",
      "     74      397.9087      \u001b[32m621.8640\u001b[0m     +  0.0040  0.3417\n",
      "     75      367.0138      623.9663        0.0033  0.3381\n",
      "     76      366.4612      \u001b[32m613.0500\u001b[0m     +  0.0025  0.4607\n",
      "     77      357.4602      \u001b[32m612.7496\u001b[0m     +  0.0017  0.2147\n",
      "     78      \u001b[36m352.9343\u001b[0m      621.9910        0.0010  0.2043\n",
      "     79      \u001b[36m349.6280\u001b[0m      620.7633        0.0005  0.3169\n",
      "     80      \u001b[36m347.9887\u001b[0m      620.9841        0.0001  0.2302\n",
      "     81      372.3132      629.4080        0.0050  0.3230\n",
      "     82      398.5454      663.8047        0.0049  0.2432\n",
      "     83      414.4847      656.7706        0.0045  0.3144\n",
      "     84      394.1663      \u001b[32m574.5369\u001b[0m     +  0.0040  0.2064\n",
      "     85      365.0218      615.8279        0.0033  0.3026\n",
      "     86      350.3196      577.7274        0.0025  0.2026\n",
      "     87      348.6139      602.1894        0.0017  0.2066\n",
      "     88      \u001b[36m339.8317\u001b[0m      596.6608        0.0010  0.2977\n",
      "     89      \u001b[36m337.6293\u001b[0m      603.2535        0.0005  0.1986\n",
      "     90      \u001b[36m335.9466\u001b[0m      604.3085        0.0001  0.3012\n",
      "     91      362.1159      614.2458        0.0050  0.2077\n",
      "     92      383.8576      640.8259        0.0049  0.2975\n",
      "     93      398.6614      626.2456        0.0045  0.2053\n",
      "     94      387.8423      \u001b[32m571.8954\u001b[0m     +  0.0040  0.3118\n",
      "     95      356.6226      589.7306        0.0033  0.2066\n",
      "     96      340.8211      577.4405        0.0025  0.2051\n",
      "     97      338.2723      583.9825        0.0017  0.3091\n",
      "     98      \u001b[36m331.6521\u001b[0m      589.8666        0.0010  0.2058\n",
      "     99      \u001b[36m329.2756\u001b[0m      595.4759        0.0005  0.3024\n",
      "    100      \u001b[36m327.6740\u001b[0m      596.1399        0.0001  0.2064\n",
      "    101      352.1254      597.4029        0.0050  0.3155\n",
      "    102      371.6697      616.2913        0.0049  0.2333\n",
      "    103      389.5039      607.9888        0.0045  0.3072\n",
      "    104      387.0745      \u001b[32m570.1241\u001b[0m     +  0.0040  0.2054\n",
      "    105      353.3086      580.9204        0.0033  0.2006\n",
      "    106      333.8399      600.7103        0.0025  0.3032\n",
      "    107      331.6148      586.2043        0.0017  0.2076\n",
      "    108      \u001b[36m325.1537\u001b[0m      588.0552        0.0010  0.3068\n",
      "    109      \u001b[36m322.7235\u001b[0m      595.6815        0.0005  0.2090\n",
      "    110      \u001b[36m321.1821\u001b[0m      596.2985        0.0001  0.3052\n",
      "    111      344.5965      594.4556        0.0050  0.2062\n",
      "    112      362.3033      588.4049        0.0049  0.2974\n",
      "    113      377.6871      601.8773        0.0045  0.2078\n",
      "    114      381.1928      \u001b[32m563.3980\u001b[0m     +  0.0040  0.2006\n",
      "    115      350.2321      570.1553        0.0033  0.3124\n",
      "    116      328.4614      626.0714        0.0025  0.2091\n",
      "    117      326.2617      604.7681        0.0017  0.3080\n",
      "    118      \u001b[36m319.8521\u001b[0m      596.5698        0.0010  0.2074\n",
      "    119      \u001b[36m317.3237\u001b[0m      603.3963        0.0005  0.2970\n",
      "    120      \u001b[36m315.8272\u001b[0m      603.5607        0.0001  0.1988\n",
      "    121      338.0700      578.0909        0.0050  0.3092\n",
      "    122      353.4761      580.4495        0.0049  0.2351\n",
      "    123      366.9316      580.0002        0.0045  0.2030\n",
      "    124      373.1928      \u001b[32m557.3053\u001b[0m     +  0.0040  0.3096\n",
      "    125      345.2621      560.9472        0.0033  0.2073\n",
      "    126      324.1106      624.4042        0.0025  0.3137\n",
      "    127      319.3743      603.9716        0.0017  0.2039\n",
      "    128      \u001b[36m314.9959\u001b[0m      597.9593        0.0010  0.3020\n",
      "    129      \u001b[36m312.1667\u001b[0m      602.6732        0.0005  0.2234\n",
      "    130      \u001b[36m310.7570\u001b[0m      602.1820        0.0001  0.4764\n",
      "    131      333.0919      573.7094        0.0050  0.3602\n",
      "    132      346.4024      572.6454        0.0049  0.1971\n",
      "    133      358.7880      578.8521        0.0045  0.3066\n",
      "    134      367.3457      \u001b[32m554.2598\u001b[0m     +  0.0040  0.1999\n",
      "    135      345.7239      554.7988        0.0033  0.3169\n",
      "    136      321.4800      643.7853        0.0025  0.2031\n",
      "    137      315.3946      615.9986        0.0017  0.3001\n",
      "    138      311.4543      611.6742        0.0010  0.2106\n",
      "    139      \u001b[36m308.2267\u001b[0m      615.0412        0.0005  0.3040\n",
      "    140      \u001b[36m306.8362\u001b[0m      613.7292        0.0001  0.2188\n",
      "    141      327.6611      567.9695        0.0050  0.2278\n",
      "    142      338.9907      579.8430        0.0049  0.3139\n",
      "    143      351.3348      566.4521        0.0045  0.2106\n",
      "    144      361.1593      558.9216        0.0040  0.2963\n",
      "    145      342.4519      \u001b[32m549.4048\u001b[0m     +  0.0033  0.1988\n",
      "    146      317.7115      641.1245        0.0025  0.3050\n",
      "    147      310.4404      607.1330        0.0017  0.2220\n",
      "    148      307.4986      605.0838        0.0010  0.3016\n",
      "    149      \u001b[36m304.0164\u001b[0m      609.1878        0.0005  0.2004\n",
      "    150      \u001b[36m302.7101\u001b[0m      608.2198        0.0001  0.2170\n",
      "    151      322.5337      570.4120        0.0050  0.2941\n",
      "    152      333.6065      577.8983        0.0049  0.2042\n",
      "    153      344.3532      571.3996        0.0045  0.3065\n",
      "    154      353.5289      554.1459        0.0040  0.2010\n",
      "    155      339.2219      \u001b[32m545.8685\u001b[0m     +  0.0033  0.3019\n",
      "    156      316.3124      655.8496        0.0025  0.2042\n",
      "    157      306.7932      619.0567        0.0017  0.3035\n",
      "    158      304.3924      621.1663        0.0010  0.2052\n",
      "    159      \u001b[36m300.4444\u001b[0m      620.8973        0.0005  0.2060\n",
      "    160      \u001b[36m299.1863\u001b[0m      619.0178        0.0001  0.3088\n",
      "    161      317.9913      566.5461        0.0050  0.2135\n",
      "    162      328.0560      580.1869        0.0049  0.3038\n",
      "    163      337.8245      563.0730        0.0045  0.2042\n",
      "    164      347.6336      558.8081        0.0040  0.3076\n",
      "    165      337.5305      \u001b[32m539.6675\u001b[0m     +  0.0033  0.2060\n",
      "    166      315.5600      655.1155        0.0025  0.2979\n",
      "    167      302.6849      607.9448        0.0017  0.1986\n",
      "    168      301.0935      609.4435        0.0010  0.2028\n",
      "    169      \u001b[36m296.6063\u001b[0m      610.0557        0.0005  0.2994\n",
      "    170      \u001b[36m295.3623\u001b[0m      608.2078        0.0001  0.2070\n",
      "    171      313.8574      566.7276        0.0050  0.2991\n",
      "    172      321.8685      569.7146        0.0049  0.2015\n",
      "    173      329.8655      564.3593        0.0045  0.3203\n",
      "    174      339.3692      556.9080        0.0040  0.2064\n",
      "    175      337.3037      \u001b[32m534.1426\u001b[0m     +  0.0033  0.3066\n",
      "    176      312.5503      651.6916        0.0025  0.2127\n",
      "    177      298.8662      605.7482        0.0017  0.2051\n",
      "    178      297.4409      608.0200        0.0010  0.3253\n",
      "    179      \u001b[36m293.0746\u001b[0m      602.3126        0.0005  0.2044\n",
      "    180      \u001b[36m291.7402\u001b[0m      601.0198        0.0001  0.3029\n",
      "    181      309.7564      565.6397        0.0050  0.2415\n",
      "    182      318.1017      570.2091        0.0049  0.2999\n",
      "    183      332.8605      569.5422        0.0045  0.2094\n",
      "    184      330.2092      543.8544        0.0040  0.2986\n",
      "    185      331.2723      540.0486        0.0033  0.2156\n",
      "    186      312.7264      605.6194        0.0025  0.2202\n",
      "    187      296.0442      615.6983        0.0017  0.3204\n",
      "    188      293.7061      613.3485        0.0010  0.2023\n",
      "    189      \u001b[36m290.2026\u001b[0m      600.5502        0.0005  0.2900\n",
      "    190      \u001b[36m288.9986\u001b[0m      600.1824        0.0001  0.2181\n",
      "    191      305.0135      570.8688        0.0050  0.3134\n",
      "    192      317.5748      568.3255        0.0049  0.2074\n",
      "    193      325.4944      572.7781        0.0045  0.2986\n",
      "    194      332.2246      554.2209        0.0040  0.2171\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m893.1558\u001b[0m     \u001b[32m1079.3431\u001b[0m     +  0.0050  0.3688\n",
      "      2      \u001b[36m839.3169\u001b[0m     1133.3650        0.0049  0.5644\n",
      "      3      \u001b[36m674.0464\u001b[0m      \u001b[32m967.2488\u001b[0m     +  0.0045  0.2349\n",
      "      4      693.0818     1000.3300        0.0040  0.2340\n",
      "      5      \u001b[36m630.5574\u001b[0m      \u001b[32m940.6925\u001b[0m     +  0.0033  0.3145\n",
      "      6      \u001b[36m603.8215\u001b[0m      \u001b[32m923.6435\u001b[0m     +  0.0025  0.2073\n",
      "      7      \u001b[36m574.3616\u001b[0m      \u001b[32m899.9202\u001b[0m     +  0.0017  0.3128\n",
      "      8      \u001b[36m553.1697\u001b[0m      \u001b[32m885.3031\u001b[0m     +  0.0010  0.2065\n",
      "      9      \u001b[36m539.6737\u001b[0m      \u001b[32m877.8648\u001b[0m     +  0.0005  0.3215\n",
      "     10      \u001b[36m532.9172\u001b[0m      \u001b[32m875.6708\u001b[0m     +  0.0001  0.2145\n",
      "     11      617.0968      \u001b[32m853.6921\u001b[0m     +  0.0050  0.3126\n",
      "     12      657.2422      972.6343        0.0049  0.2126\n",
      "     13      \u001b[36m532.8981\u001b[0m      \u001b[32m807.7254\u001b[0m     +  0.0045  0.2016\n",
      "     14      \u001b[36m496.0038\u001b[0m      810.0803        0.0040  0.3031\n",
      "     15      \u001b[36m482.6170\u001b[0m      \u001b[32m780.9068\u001b[0m     +  0.0033  0.2075\n",
      "     16      \u001b[36m457.3487\u001b[0m      \u001b[32m759.7005\u001b[0m     +  0.0025  0.3122\n",
      "     17      \u001b[36m445.6664\u001b[0m      \u001b[32m750.8907\u001b[0m     +  0.0017  0.2132\n",
      "     18      \u001b[36m435.9988\u001b[0m      \u001b[32m746.1754\u001b[0m     +  0.0010  0.3122\n",
      "     19      \u001b[36m430.7286\u001b[0m      \u001b[32m743.7925\u001b[0m     +  0.0005  0.2115\n",
      "     20      \u001b[36m427.9625\u001b[0m      \u001b[32m743.2413\u001b[0m     +  0.0001  0.2063\n",
      "     21      471.6821      750.9877        0.0050  0.3260\n",
      "     22      529.9775      815.5444        0.0049  0.2205\n",
      "     23      506.0311      811.5185        0.0045  0.3180\n",
      "     24      451.3946      \u001b[32m708.4445\u001b[0m     +  0.0040  0.2192\n",
      "     25      430.0704      724.8848        0.0033  0.3895\n",
      "     26      \u001b[36m423.7400\u001b[0m      721.0175        0.0025  0.2173\n",
      "     27      \u001b[36m412.5482\u001b[0m      711.9886        0.0017  0.3049\n",
      "     28      \u001b[36m407.3506\u001b[0m      708.6390        0.0010  0.2247\n",
      "     29      \u001b[36m403.3501\u001b[0m      \u001b[32m707.7713\u001b[0m     +  0.0005  0.2144\n",
      "     30      \u001b[36m401.3252\u001b[0m      \u001b[32m707.6870\u001b[0m     +  0.0001  0.3331\n",
      "     31      432.0777      729.2982        0.0050  0.2153\n",
      "     32      476.3536      760.5287        0.0049  0.3086\n",
      "     33      472.3189      742.1029        0.0045  0.2068\n",
      "     34      428.6159      \u001b[32m701.8561\u001b[0m     +  0.0040  0.3006\n",
      "     35      409.6619      \u001b[32m697.8556\u001b[0m     +  0.0033  0.2127\n",
      "     36      404.7861      \u001b[32m688.8939\u001b[0m     +  0.0025  0.2008\n",
      "     37      \u001b[36m394.4132\u001b[0m      \u001b[32m685.1850\u001b[0m     +  0.0017  0.3120\n",
      "     38      \u001b[36m389.9677\u001b[0m      685.6371        0.0010  0.2100\n",
      "     39      \u001b[36m386.2760\u001b[0m      685.8527        0.0005  0.3047\n",
      "     40      \u001b[36m384.4410\u001b[0m      686.0568        0.0001  0.2005\n",
      "     41      411.8894      706.3324        0.0050  0.3035\n",
      "     42      456.4836      747.8653        0.0049  0.1960\n",
      "     43      465.1740      749.0395        0.0045  0.2033\n",
      "     44      425.7994      \u001b[32m680.7102\u001b[0m     +  0.0040  0.3094\n",
      "     45      396.2007      \u001b[32m679.9026\u001b[0m     +  0.0033  0.2154\n",
      "     46      392.9782      \u001b[32m676.8598\u001b[0m     +  0.0025  0.3080\n",
      "     47      \u001b[36m383.5102\u001b[0m      \u001b[32m675.6577\u001b[0m     +  0.0017  0.2379\n",
      "     48      \u001b[36m379.6005\u001b[0m      678.0144        0.0010  0.5943\n",
      "     49      \u001b[36m376.0163\u001b[0m      678.6672        0.0005  0.3168\n",
      "     50      \u001b[36m374.3750\u001b[0m      679.1380        0.0001  0.3232\n",
      "     51      399.6894      695.7696        0.0050  0.2057\n",
      "     52      440.4685      730.7645        0.0049  0.1909\n",
      "     53      451.8351      709.2370        0.0045  0.3034\n",
      "     54      409.0784      \u001b[32m664.8636\u001b[0m     +  0.0040  0.2034\n",
      "     55      387.1375      669.8829        0.0033  0.2985\n",
      "     56      385.4734      \u001b[32m660.8133\u001b[0m     +  0.0025  0.2020\n",
      "     57      374.8921      662.4982        0.0017  0.3006\n",
      "     58      \u001b[36m371.4305\u001b[0m      666.9303        0.0010  0.1969\n",
      "     59      \u001b[36m367.8987\u001b[0m      667.9555        0.0005  0.2992\n",
      "     60      \u001b[36m366.3177\u001b[0m      668.5989        0.0001  0.1981\n",
      "     61      389.4512      686.4947        0.0050  0.2023\n",
      "     62      429.1093      698.9807        0.0049  0.3083\n",
      "     63      442.5424      689.9919        0.0045  0.2547\n",
      "     64      405.2499      \u001b[32m653.5941\u001b[0m     +  0.0040  0.4780\n",
      "     65      377.4933      \u001b[32m652.6449\u001b[0m     +  0.0033  0.2102\n",
      "     66      377.8803      \u001b[32m645.1553\u001b[0m     +  0.0025  0.2943\n",
      "     67      367.2243      653.7619        0.0017  0.2028\n",
      "     68      \u001b[36m363.9007\u001b[0m      660.4315        0.0010  0.2984\n",
      "     69      \u001b[36m360.3709\u001b[0m      660.8862        0.0005  0.1970\n",
      "     70      \u001b[36m358.8944\u001b[0m      661.6621        0.0001  0.2068\n",
      "     71      382.3626      665.1502        0.0050  0.2988\n",
      "     72      418.7485      686.2516        0.0049  0.2098\n",
      "     73      436.4842      684.5456        0.0045  0.3071\n",
      "     74      398.7420      \u001b[32m638.2384\u001b[0m     +  0.0040  0.2008\n",
      "     75      371.6670      648.7583        0.0033  0.3295\n",
      "     76      370.6527      642.8685        0.0025  0.2482\n",
      "     77      361.4566      649.9025        0.0017  0.4987\n",
      "     78      \u001b[36m357.9342\u001b[0m      657.8939        0.0010  0.2049\n",
      "     79      \u001b[36m354.6663\u001b[0m      659.2966        0.0005  0.1969\n",
      "     80      \u001b[36m353.2652\u001b[0m      660.1897        0.0001  0.3334\n",
      "     81      375.5211      655.2518        0.0050  0.2968\n",
      "     82      410.4625      672.4581        0.0049  0.5497\n",
      "     83      429.4840      668.1095        0.0045  0.2108\n",
      "     84      392.6874      \u001b[32m625.4783\u001b[0m     +  0.0040  0.2969\n",
      "     85      365.2919      644.2304        0.0033  0.1973\n",
      "     86      364.4987      632.9140        0.0025  0.3176\n",
      "     87      355.7194      639.0534        0.0017  0.2009\n",
      "     88      \u001b[36m351.7479\u001b[0m      648.9120        0.0010  0.1964\n",
      "     89      \u001b[36m348.5345\u001b[0m      649.9775        0.0005  0.3161\n",
      "     90      \u001b[36m347.0843\u001b[0m      650.7542        0.0001  0.2122\n",
      "     91      369.3120      636.7863        0.0050  0.3077\n",
      "     92      404.4719      656.4430        0.0049  0.2018\n",
      "     93      421.4069      654.1022        0.0045  0.2987\n",
      "     94      391.8069      \u001b[32m617.9141\u001b[0m     +  0.0040  0.1961\n",
      "     95      357.4381      618.0066        0.0033  0.2991\n",
      "     96      356.8580      \u001b[32m596.8848\u001b[0m     +  0.0025  0.2730\n",
      "     97      347.7757      610.0173        0.0017  0.3361\n",
      "     98      \u001b[36m340.2972\u001b[0m      607.2115        0.0010  0.3906\n",
      "     99      \u001b[36m337.2137\u001b[0m      610.0676        0.0005  0.2195\n",
      "    100      \u001b[36m335.3444\u001b[0m      611.0321        0.0001  0.3141\n",
      "    101      361.4696      611.1434        0.0050  0.2045\n",
      "    102      396.6802      629.0595        0.0049  0.3132\n",
      "    103      413.3606      661.1795        0.0045  0.2050\n",
      "    104      395.6542      622.4303        0.0040  0.3067\n",
      "    105      358.6145      659.0240        0.0033  0.2082\n",
      "    106      354.1043      619.2363        0.0025  0.2149\n",
      "    107      349.6995      639.8529        0.0017  0.3058\n",
      "    108      340.6598      630.4233        0.0010  0.2149\n",
      "    109      337.6046      631.9166        0.0005  0.3211\n",
      "    110      335.5331      632.2121        0.0001  0.3518\n",
      "    111      357.7617      \u001b[32m593.5691\u001b[0m     +  0.0050  0.3957\n",
      "    112      384.8238      620.4071        0.0049  0.2029\n",
      "    113      403.2213      617.3941        0.0045  0.3021\n",
      "    114      380.9574      \u001b[32m559.2497\u001b[0m     +  0.0040  0.2082\n",
      "    115      345.5969      598.7562        0.0033  0.2026\n",
      "    116      337.5697      \u001b[32m557.3238\u001b[0m     +  0.0025  0.3120\n",
      "    117      \u001b[36m330.7317\u001b[0m      582.7017        0.0017  0.2142\n",
      "    118      \u001b[36m323.4253\u001b[0m      578.2584        0.0010  0.4601\n",
      "    119      \u001b[36m320.5499\u001b[0m      582.7100        0.0005  0.2056\n",
      "    120      \u001b[36m318.7309\u001b[0m      583.1284        0.0001  0.3226\n",
      "    121      347.8461      585.2101        0.0050  0.2016\n",
      "    122      373.2630      598.5336        0.0049  0.3054\n",
      "    123      388.0183      606.5155        0.0045  0.2146\n",
      "    124      370.7046      \u001b[32m540.4178\u001b[0m     +  0.0040  0.2051\n",
      "    125      342.2839      590.5466        0.0033  0.3079\n",
      "    126      329.5801      550.2997        0.0025  0.1993\n",
      "    127      320.7965      578.1751        0.0017  0.2978\n",
      "    128      \u001b[36m315.7363\u001b[0m      575.4596        0.0010  0.2142\n",
      "    129      \u001b[36m312.4419\u001b[0m      575.6043        0.0005  0.3034\n",
      "    130      \u001b[36m310.8080\u001b[0m      576.1320        0.0001  0.2032\n",
      "    131      339.2052      577.4787        0.0050  0.3045\n",
      "    132      358.6646      575.7234        0.0049  0.2004\n",
      "    133      375.0764      585.1494        0.0045  0.2073\n",
      "    134      379.2778      547.4180        0.0040  0.3070\n",
      "    135      338.2807      564.8920        0.0033  0.2081\n",
      "    136      322.6046      586.4181        0.0025  0.3237\n",
      "    137      314.2433      563.4014        0.0017  0.2982\n",
      "    138      \u001b[36m309.3146\u001b[0m      564.5253        0.0010  0.5351\n",
      "    139      \u001b[36m305.7600\u001b[0m      571.5806        0.0005  0.2037\n",
      "    140      \u001b[36m304.0928\u001b[0m      570.9379        0.0001  0.3113\n",
      "    141      332.0258      579.5443        0.0050  0.2136\n",
      "    142      348.0996      565.5026        0.0049  0.2106\n",
      "    143      365.5681      578.9620        0.0045  0.3162\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m880.0524\u001b[0m      \u001b[32m988.6013\u001b[0m     +  0.0050  0.5048\n",
      "      2      901.3859     1226.8429        0.0049  0.4801\n",
      "      3      \u001b[36m676.9459\u001b[0m      \u001b[32m949.0715\u001b[0m     +  0.0045  0.4136\n",
      "      4      712.1609     1032.1602        0.0040  0.2091\n",
      "      5      \u001b[36m632.7790\u001b[0m      \u001b[32m948.1417\u001b[0m     +  0.0033  0.3405\n",
      "      6      \u001b[36m612.8298\u001b[0m      \u001b[32m936.8535\u001b[0m     +  0.0025  0.2128\n",
      "      7      \u001b[36m582.6246\u001b[0m      \u001b[32m921.0746\u001b[0m     +  0.0017  0.2119\n",
      "      8      \u001b[36m560.5258\u001b[0m      \u001b[32m898.8288\u001b[0m     +  0.0010  0.3105\n",
      "      9      \u001b[36m547.2322\u001b[0m      \u001b[32m889.0210\u001b[0m     +  0.0005  0.2154\n",
      "     10      \u001b[36m540.5106\u001b[0m      \u001b[32m886.4560\u001b[0m     +  0.0001  0.3183\n",
      "     11      621.3229      \u001b[32m869.1753\u001b[0m     +  0.0050  0.2206\n",
      "     12      652.2811      954.0523        0.0049  0.3090\n",
      "     13      \u001b[36m536.6733\u001b[0m      \u001b[32m819.5432\u001b[0m     +  0.0045  0.2079\n",
      "     14      \u001b[36m508.6615\u001b[0m      \u001b[32m804.1881\u001b[0m     +  0.0040  0.2156\n",
      "     15      \u001b[36m489.7507\u001b[0m      \u001b[32m784.7903\u001b[0m     +  0.0033  0.3168\n",
      "     16      \u001b[36m465.6362\u001b[0m      \u001b[32m764.0601\u001b[0m     +  0.0025  0.2224\n",
      "     17      \u001b[36m453.7507\u001b[0m      \u001b[32m749.2618\u001b[0m     +  0.0017  0.3147\n",
      "     18      \u001b[36m443.4830\u001b[0m      \u001b[32m745.0043\u001b[0m     +  0.0010  0.2045\n",
      "     19      \u001b[36m437.7568\u001b[0m      \u001b[32m741.8701\u001b[0m     +  0.0005  0.3176\n",
      "     20      \u001b[36m434.7605\u001b[0m      \u001b[32m741.0728\u001b[0m     +  0.0001  0.2134\n",
      "     21      484.2172      \u001b[32m732.0450\u001b[0m     +  0.0050  0.3156\n",
      "     22      552.8831      844.6739        0.0049  0.2177\n",
      "     23      508.7438      793.3227        0.0045  0.2132\n",
      "     24      446.2553      \u001b[32m708.7718\u001b[0m     +  0.0040  0.3272\n",
      "     25      441.4118      732.6732        0.0033  0.2153\n",
      "     26      \u001b[36m427.4543\u001b[0m      724.6112        0.0025  0.3103\n",
      "     27      \u001b[36m419.2710\u001b[0m      716.8298        0.0017  0.2136\n",
      "     28      \u001b[36m412.8419\u001b[0m      714.1173        0.0010  0.3165\n",
      "     29      \u001b[36m409.2629\u001b[0m      713.6586        0.0005  0.2693\n",
      "     30      \u001b[36m407.2721\u001b[0m      713.6158        0.0001  0.2658\n",
      "     31      439.5138      728.3791        0.0050  0.4909\n",
      "     32      479.5933      771.1132        0.0049  0.2009\n",
      "     33      469.8446      741.3613        0.0045  0.3134\n",
      "     34      426.1022      \u001b[32m696.1238\u001b[0m     +  0.0040  0.2181\n",
      "     35      414.5225      712.8481        0.0033  0.3118\n",
      "     36      407.8305      702.1217        0.0025  0.2082\n",
      "     37      \u001b[36m398.1259\u001b[0m      699.7517        0.0017  0.2062\n",
      "     38      \u001b[36m393.3396\u001b[0m      700.3954        0.0010  0.3096\n",
      "     39      \u001b[36m389.8461\u001b[0m      700.6123        0.0005  0.2144\n",
      "     40      \u001b[36m388.0007\u001b[0m      700.7890        0.0001  0.3067\n",
      "     41      416.5449      717.3923        0.0050  0.2063\n",
      "     42      459.4320      754.8355        0.0049  0.3128\n",
      "     43      465.5004      722.3262        0.0045  0.1967\n",
      "     44      416.8684      \u001b[32m686.9174\u001b[0m     +  0.0040  0.3057\n",
      "     45      400.0131      697.3207        0.0033  0.2074\n",
      "     46      396.3794      689.1979        0.0025  0.2071\n",
      "     47      \u001b[36m386.4787\u001b[0m      689.8750        0.0017  0.2965\n",
      "     48      \u001b[36m382.7607\u001b[0m      691.8074        0.0010  0.2473\n",
      "     49      \u001b[36m379.4966\u001b[0m      692.0545        0.0005  0.3247\n",
      "     50      \u001b[36m377.8566\u001b[0m      692.3361        0.0001  0.1995\n",
      "     51      402.4668      701.6184        0.0050  0.3015\n",
      "     52      441.5654      734.7549        0.0049  0.2046\n",
      "     53      453.5735      709.8629        0.0045  0.3183\n",
      "     54      407.5597      \u001b[32m679.2023\u001b[0m     +  0.0040  0.2285\n",
      "     55      388.6811      687.9476        0.0033  0.2112\n",
      "     56      386.7635      \u001b[32m678.8680\u001b[0m     +  0.0025  0.3003\n",
      "     57      \u001b[36m376.8202\u001b[0m      682.5795        0.0017  0.2056\n",
      "     58      \u001b[36m373.4546\u001b[0m      687.0892        0.0010  0.3241\n",
      "     59      \u001b[36m370.2210\u001b[0m      688.0228        0.0005  0.2030\n",
      "     60      \u001b[36m368.7244\u001b[0m      688.6687        0.0001  0.3180\n",
      "     61      392.5951      696.4090        0.0050  0.2078\n",
      "     62      430.7317      718.3549        0.0049  0.3113\n",
      "     63      444.4500      703.4898        0.0045  0.2169\n",
      "     64      400.3040      \u001b[32m669.0457\u001b[0m     +  0.0040  0.2020\n",
      "     65      379.6441      685.7227        0.0033  0.3068\n",
      "     66      379.8443      674.4936        0.0025  0.2196\n",
      "     67      369.5372      680.9780        0.0017  0.3164\n",
      "     68      \u001b[36m366.2765\u001b[0m      686.6456        0.0010  0.2140\n",
      "     69      \u001b[36m362.9607\u001b[0m      686.9971        0.0005  0.2979\n",
      "     70      \u001b[36m361.5709\u001b[0m      687.7485        0.0001  0.2062\n",
      "     71      384.3386      690.6717        0.0050  0.3073\n",
      "     72      419.9530      700.1485        0.0049  0.2003\n",
      "     73      432.4977      690.1873        0.0045  0.2043\n",
      "     74      395.1501      \u001b[32m661.8344\u001b[0m     +  0.0040  0.3200\n",
      "     75      371.6943      677.7327        0.0033  0.3037\n",
      "     76      372.1716      670.9796        0.0025  0.5622\n",
      "     77      363.0976      679.2788        0.0017  0.4788\n",
      "     78      \u001b[36m359.6166\u001b[0m      685.1648        0.0010  0.3097\n",
      "     79      \u001b[36m356.5452\u001b[0m      686.2091        0.0005  0.2058\n",
      "     80      \u001b[36m355.2471\u001b[0m      687.2169        0.0001  0.3117\n",
      "     81      377.6193      682.3752        0.0050  0.1985\n",
      "     82      409.8675      679.9143        0.0049  0.1958\n",
      "     83      424.0673      685.7536        0.0045  0.3021\n",
      "     84      392.9117      \u001b[32m655.4344\u001b[0m     +  0.0040  0.2093\n",
      "     85      365.3026      676.3045        0.0033  0.3246\n",
      "     86      365.4092      669.4112        0.0025  0.2082\n",
      "     87      357.9306      678.7751        0.0017  0.3260\n",
      "     88      \u001b[36m353.8034\u001b[0m      685.9184        0.0010  0.2030\n",
      "     89      \u001b[36m350.9769\u001b[0m      687.1169        0.0005  0.3176\n",
      "     90      \u001b[36m349.7239\u001b[0m      688.1508        0.0001  0.2001\n",
      "     91      371.4207      673.8680        0.0050  0.2028\n",
      "     92      400.9149      670.5277        0.0049  0.3099\n",
      "     93      415.6326      676.7258        0.0045  0.1989\n",
      "     94      387.3060      \u001b[32m650.2420\u001b[0m     +  0.0040  0.3008\n",
      "     95      359.7966      673.9690        0.0033  0.2085\n",
      "     96      358.9991      665.1548        0.0025  0.3001\n",
      "     97      352.4663      677.6192        0.0017  0.1974\n",
      "     98      \u001b[36m347.9600\u001b[0m      684.2505        0.0010  0.3120\n",
      "     99      \u001b[36m345.3138\u001b[0m      685.9407        0.0005  0.2169\n",
      "    100      \u001b[36m344.0820\u001b[0m      687.1418        0.0001  0.2028\n",
      "    101      366.0507      669.6719        0.0050  0.3033\n",
      "    102      393.5234      658.0487        0.0049  0.1990\n",
      "    103      408.4386      672.1016        0.0045  0.3226\n",
      "    104      384.4359      \u001b[32m643.7868\u001b[0m     +  0.0040  0.2008\n",
      "    105      355.3675      673.5017        0.0033  0.3860\n",
      "    106      352.0873      659.9039        0.0025  0.2011\n",
      "    107      347.6343      674.7130        0.0017  0.3006\n",
      "    108      \u001b[36m342.2302\u001b[0m      678.7421        0.0010  0.1998\n",
      "    109      \u001b[36m339.7600\u001b[0m      681.2355        0.0005  0.2028\n",
      "    110      \u001b[36m338.4574\u001b[0m      682.4302        0.0001  0.3075\n",
      "    111      361.5627      661.3874        0.0050  0.2094\n",
      "    112      385.1626      647.9931        0.0049  0.2970\n",
      "    113      400.6977      660.7673        0.0045  0.2103\n",
      "    114      382.7841      \u001b[32m632.8183\u001b[0m     +  0.0040  0.3079\n",
      "    115      350.6745      664.7916        0.0033  0.2096\n",
      "    116      345.6440      649.7541        0.0025  0.3063\n",
      "    117      342.3638      668.7973        0.0017  0.2170\n",
      "    118      \u001b[36m335.9614\u001b[0m      671.2215        0.0010  0.1980\n",
      "    119      \u001b[36m333.6361\u001b[0m      673.6809        0.0005  0.3118\n",
      "    120      \u001b[36m332.3059\u001b[0m      674.7570        0.0001  0.2072\n",
      "    121      356.1389      648.0264        0.0050  0.3088\n",
      "    122      377.6873      635.1460        0.0049  0.1979\n",
      "    123      395.0777      649.0352        0.0045  0.3094\n",
      "    124      381.5414      \u001b[32m614.3472\u001b[0m     +  0.0040  0.2195\n",
      "    125      347.0693      656.0998        0.0033  0.3771\n",
      "    126      339.6860      641.0756        0.0025  0.2039\n",
      "    127      336.3111      653.5325        0.0017  0.1998\n",
      "    128      \u001b[36m329.6999\u001b[0m      658.0412        0.0010  0.3018\n",
      "    129      \u001b[36m327.2415\u001b[0m      661.4095        0.0005  0.2171\n",
      "    130      \u001b[36m325.7811\u001b[0m      662.1985        0.0001  0.3021\n",
      "    131      350.3069      628.4366        0.0050  0.2081\n",
      "    132      369.6714      618.7247        0.0049  0.3211\n",
      "    133      383.8721      627.3745        0.0045  0.2153\n",
      "    134      376.3703      \u001b[32m589.8568\u001b[0m     +  0.0040  0.3120\n",
      "    135      344.7492      637.5157        0.0033  0.2078\n",
      "    136      330.9415      632.3013        0.0025  0.1998\n",
      "    137      327.2874      635.5419        0.0017  0.3274\n",
      "    138      \u001b[36m321.6516\u001b[0m      637.2431        0.0010  0.2087\n",
      "    139      \u001b[36m319.0308\u001b[0m      642.0966        0.0005  0.4078\n",
      "    140      \u001b[36m317.5419\u001b[0m      642.2210        0.0001  0.3376\n",
      "    141      343.2404      610.9396        0.0050  0.3056\n",
      "    142      358.7582      601.0003        0.0049  0.2074\n",
      "    143      373.2630      607.4164        0.0045  0.3234\n",
      "    144      370.6580      \u001b[32m578.1969\u001b[0m     +  0.0040  0.2099\n",
      "    145      342.5517      624.6801        0.0033  0.2033\n",
      "    146      323.9759      633.5928        0.0025  0.3252\n",
      "    147      318.0700      623.9136        0.0017  0.2099\n",
      "    148      \u001b[36m314.4343\u001b[0m      628.9071        0.0010  0.2985\n",
      "    149      \u001b[36m311.2502\u001b[0m      632.7852        0.0005  0.2007\n",
      "    150      \u001b[36m309.8055\u001b[0m      632.2833        0.0001  0.3088\n",
      "    151      334.2740      604.9800        0.0050  0.2122\n",
      "    152      348.6263      588.4102        0.0049  0.3048\n",
      "    153      361.0592      591.1136        0.0045  0.2119\n",
      "    154      362.6515      \u001b[32m572.2149\u001b[0m     +  0.0040  0.2355\n",
      "    155      342.2649      606.3667        0.0033  0.4463\n",
      "    156      317.8603      640.2756        0.0025  0.2127\n",
      "    157      310.8850      612.4363        0.0017  0.3058\n",
      "    158      \u001b[36m308.6840\u001b[0m      620.6593        0.0010  0.2048\n",
      "    159      \u001b[36m304.4894\u001b[0m      622.2385        0.0005  0.3048\n",
      "    160      \u001b[36m303.1052\u001b[0m      620.8270        0.0001  0.2020\n",
      "    161      326.3829      592.1766        0.0050  0.3054\n",
      "    162      337.7392      587.5093        0.0049  0.2168\n",
      "    163      347.3752      575.4580        0.0045  0.3903\n",
      "    164      355.3872      \u001b[32m572.1636\u001b[0m     +  0.0040  0.3056\n",
      "    165      339.1558      \u001b[32m569.1258\u001b[0m     +  0.0033  0.1988\n",
      "    166      316.7294      654.3043        0.0025  0.3093\n",
      "    167      304.6736      605.6261        0.0017  0.2039\n",
      "    168      \u001b[36m302.6219\u001b[0m      615.8496        0.0010  0.3085\n",
      "    169      \u001b[36m298.4434\u001b[0m      615.1648        0.0005  0.2073\n",
      "    170      \u001b[36m297.1473\u001b[0m      613.6794        0.0001  0.3177\n",
      "    171      318.5033      587.0755        0.0050  0.1999\n",
      "    172      328.7495      581.8564        0.0049  0.2025\n",
      "    173      334.4333      \u001b[32m563.9627\u001b[0m     +  0.0045  0.2964\n",
      "    174      343.6558      575.4069        0.0040  0.2041\n",
      "    175      342.5327      \u001b[32m559.7979\u001b[0m     +  0.0033  0.3158\n",
      "    176      319.1293      670.4136        0.0025  0.2047\n",
      "    177      302.0823      603.1878        0.0017  0.2982\n",
      "    178      300.8941      616.8677        0.0010  0.2080\n",
      "    179      \u001b[36m294.2806\u001b[0m      608.7160        0.0005  0.3191\n",
      "    180      \u001b[36m293.0830\u001b[0m      607.6523        0.0001  0.2076\n",
      "    181      310.5006      583.2739        0.0050  0.2151\n",
      "    182      320.5407      583.5020        0.0049  0.4390\n",
      "    183      324.4654      \u001b[32m559.6457\u001b[0m     +  0.0045  0.2093\n",
      "    184      330.8224      565.8808        0.0040  0.3009\n",
      "    185      333.7033      \u001b[32m544.1830\u001b[0m     +  0.0033  0.2346\n",
      "    186      313.8613      655.3027        0.0025  0.3082\n",
      "    187      296.0966      594.3678        0.0017  0.2120\n",
      "    188      293.0992      600.4655        0.0010  0.3028\n",
      "    189      \u001b[36m288.6584\u001b[0m      594.9392        0.0005  0.2048\n",
      "    190      \u001b[36m287.4306\u001b[0m      595.5197        0.0001  0.2097\n",
      "    191      303.8191      588.8105        0.0050  0.3057\n",
      "    192      311.7889      583.9319        0.0049  0.1981\n",
      "    193      319.9202      557.2960        0.0045  0.3024\n",
      "    194      322.5597      556.8128        0.0040  0.2059\n",
      "    195      327.4976      \u001b[32m539.2016\u001b[0m     +  0.0033  0.3123\n",
      "    196      310.0186      647.3623        0.0025  0.2130\n",
      "    197      291.0992      601.7978        0.0017  0.3091\n",
      "    198      289.0121      601.9587        0.0010  0.2046\n",
      "    199      \u001b[36m284.5539\u001b[0m      586.7042        0.0005  0.2101\n",
      "    200      \u001b[36m283.2742\u001b[0m      588.5873        0.0001  0.3201\n",
      "    201      297.4981      574.7284        0.0050  0.2716\n",
      "    202      306.9615      592.9917        0.0049  0.3766\n",
      "    203      316.4149      556.0497        0.0045  0.2011\n",
      "    204      319.6478      553.9423        0.0040  0.3032\n",
      "    205      321.5523      \u001b[32m527.4567\u001b[0m     +  0.0033  0.2018\n",
      "    206      306.6565      655.5505        0.0025  0.3098\n",
      "    207      287.9512      596.3092        0.0017  0.2047\n",
      "    208      285.3802      595.3230        0.0010  0.2036\n",
      "    209      \u001b[36m281.3039\u001b[0m      580.3212        0.0005  0.3119\n",
      "    210      \u001b[36m280.0245\u001b[0m      582.8914        0.0001  0.2029\n",
      "    211      292.1672      586.1472        0.0050  0.3263\n",
      "    212      302.1997      578.5890        0.0049  0.2133\n",
      "    213      307.8645      552.9669        0.0045  0.3067\n",
      "    214      314.6926      554.1222        0.0040  0.2005\n",
      "    215      318.9379      529.4420        0.0033  0.2993\n",
      "    216      303.0654      643.3228        0.0025  0.2199\n",
      "    217      284.4149      596.5790        0.0017  0.2114\n",
      "    218      281.4617      591.9776        0.0010  0.2982\n",
      "    219      \u001b[36m278.3980\u001b[0m      577.9746        0.0005  0.2062\n",
      "    220      \u001b[36m276.8684\u001b[0m      581.6707        0.0001  0.3168\n",
      "    221      288.0372      582.1985        0.0050  0.2479\n",
      "    222      297.8781      593.2534        0.0049  0.2973\n",
      "    223      309.4610      550.0495        0.0045  0.2021\n",
      "    224      314.2874      558.8165        0.0040  0.2986\n",
      "    225      316.6856      \u001b[32m523.5026\u001b[0m     +  0.0033  0.2104\n",
      "    226      300.4725      668.5812        0.0025  0.2048\n",
      "    227      281.4801      595.7122        0.0017  0.3063\n",
      "    228      279.2239      595.7970        0.0010  0.2060\n",
      "    229      \u001b[36m275.4476\u001b[0m      582.5777        0.0005  0.3099\n",
      "    230      \u001b[36m274.1122\u001b[0m      585.4376        0.0001  0.2055\n",
      "    231      284.6504      582.6076        0.0050  0.3114\n",
      "    232      293.0404      594.0649        0.0049  0.2045\n",
      "    233      302.8311      552.9127        0.0045  0.2982\n",
      "    234      307.5554      554.4345        0.0040  0.2059\n",
      "    235      312.9578      527.9489        0.0033  0.2153\n",
      "    236      298.0197      643.2681        0.0025  0.3015\n",
      "    237      279.1308      599.2753        0.0017  0.2360\n",
      "    238      276.6117      592.4988        0.0010  0.3158\n",
      "    239      \u001b[36m273.1207\u001b[0m      576.5736        0.0005  0.2066\n",
      "    240      \u001b[36m271.3342\u001b[0m      580.8605        0.0001  0.3168\n",
      "    241      280.7029      585.7864        0.0050  0.2079\n",
      "    242      288.8968      592.9183        0.0049  0.2999\n",
      "    243      302.6003      545.8107        0.0045  0.1987\n",
      "    244      302.4194      561.8655        0.0040  0.1996\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m870.5033\u001b[0m     \u001b[32m1086.4711\u001b[0m     +  0.0050  0.3261\n",
      "      2      \u001b[36m815.4525\u001b[0m     1113.2874        0.0049  0.2447\n",
      "      3      \u001b[36m665.4343\u001b[0m      \u001b[32m948.8920\u001b[0m     +  0.0045  0.2077\n",
      "      4      667.1876      984.6009        0.0040  0.2932\n",
      "      5      \u001b[36m602.3066\u001b[0m      \u001b[32m919.0980\u001b[0m     +  0.0033  0.2081\n",
      "      6      \u001b[36m572.2076\u001b[0m      \u001b[32m893.1862\u001b[0m     +  0.0025  0.3034\n",
      "      7      \u001b[36m536.1632\u001b[0m      \u001b[32m863.7645\u001b[0m     +  0.0017  0.2065\n",
      "      8      \u001b[36m513.9335\u001b[0m      \u001b[32m846.8652\u001b[0m     +  0.0010  0.4779\n",
      "      9      \u001b[36m499.1961\u001b[0m      \u001b[32m838.5772\u001b[0m     +  0.0005  0.2487\n",
      "     10      \u001b[36m492.1505\u001b[0m      \u001b[32m836.1578\u001b[0m     +  0.0001  0.4479\n",
      "     11      572.8985      \u001b[32m799.2469\u001b[0m     +  0.0050  0.6376\n",
      "     12      688.8383      988.2401        0.0049  0.3772\n",
      "     13      556.0205      821.8872        0.0045  0.3140\n",
      "     14      \u001b[36m482.5355\u001b[0m      \u001b[32m786.8923\u001b[0m     +  0.0040  0.2414\n",
      "     15      \u001b[36m481.5697\u001b[0m      \u001b[32m782.6346\u001b[0m     +  0.0033  0.5260\n",
      "     16      \u001b[36m454.6228\u001b[0m      \u001b[32m759.6047\u001b[0m     +  0.0025  0.3310\n",
      "     17      \u001b[36m446.0139\u001b[0m      \u001b[32m751.5922\u001b[0m     +  0.0017  0.2161\n",
      "     18      \u001b[36m436.6584\u001b[0m      \u001b[32m747.5956\u001b[0m     +  0.0010  0.3091\n",
      "     19      \u001b[36m432.2269\u001b[0m      \u001b[32m745.9770\u001b[0m     +  0.0005  0.2061\n",
      "     20      \u001b[36m429.7316\u001b[0m      \u001b[32m745.6160\u001b[0m     +  0.0001  0.3161\n",
      "     21      468.8709      767.0691        0.0050  0.2099\n",
      "     22      515.7321      808.3166        0.0049  0.3164\n",
      "     23      494.6447      767.3950        0.0045  0.2129\n",
      "     24      446.7791      \u001b[32m729.6450\u001b[0m     +  0.0040  0.3084\n",
      "     25      432.9749      \u001b[32m728.0117\u001b[0m     +  0.0033  0.2978\n",
      "     26      \u001b[36m424.2349\u001b[0m      \u001b[32m720.7984\u001b[0m     +  0.0025  0.2412\n",
      "     27      \u001b[36m413.8025\u001b[0m      \u001b[32m717.3972\u001b[0m     +  0.0017  0.5677\n",
      "     28      \u001b[36m408.1699\u001b[0m      \u001b[32m716.6309\u001b[0m     +  0.0010  0.4415\n",
      "     29      \u001b[36m404.2882\u001b[0m      716.7653        0.0005  0.5472\n",
      "     30      \u001b[36m402.2266\u001b[0m      716.8846        0.0001  0.2076\n",
      "     31      434.4692      741.8215        0.0050  0.3036\n",
      "     32      479.5125      765.8750        0.0049  0.2117\n",
      "     33      477.9313      746.0742        0.0045  0.2117\n",
      "     34      436.8412      \u001b[32m706.2768\u001b[0m     +  0.0040  0.3128\n",
      "     35      409.8547      \u001b[32m695.2268\u001b[0m     +  0.0033  0.2048\n",
      "     36      406.6177      701.4515        0.0025  0.3065\n",
      "     37      \u001b[36m395.8196\u001b[0m      695.2982        0.0017  0.2077\n",
      "     38      \u001b[36m391.7801\u001b[0m      697.3631        0.0010  0.3010\n",
      "     39      \u001b[36m387.8886\u001b[0m      697.7791        0.0005  0.2037\n",
      "     40      \u001b[36m386.0752\u001b[0m      698.0590        0.0001  0.3086\n",
      "     41      414.6870      717.7398        0.0050  0.2072\n",
      "     42      454.9922      745.4655        0.0049  0.2335\n",
      "     43      457.0924      717.6609        0.0045  0.3222\n",
      "     44      418.2644      \u001b[32m684.4069\u001b[0m     +  0.0040  0.2066\n",
      "     45      402.9168      \u001b[32m678.1055\u001b[0m     +  0.0033  0.2941\n",
      "     46      395.7627      684.6508        0.0025  0.1997\n",
      "     47      \u001b[36m383.4221\u001b[0m      \u001b[32m673.1692\u001b[0m     +  0.0017  0.2938\n",
      "     48      \u001b[36m378.7897\u001b[0m      \u001b[32m666.2238\u001b[0m     +  0.0010  0.1980\n",
      "     49      \u001b[36m375.1369\u001b[0m      670.2606        0.0005  0.2056\n",
      "     50      \u001b[36m372.9257\u001b[0m      671.0133        0.0001  0.3097\n",
      "     51      401.0844      696.8099        0.0050  0.2032\n",
      "     52      438.4259      725.5832        0.0049  0.2976\n",
      "     53      452.7753      698.5934        0.0045  0.2126\n",
      "     54      412.3536      \u001b[32m657.6464\u001b[0m     +  0.0040  0.2984\n",
      "     55      381.9852      \u001b[32m643.2081\u001b[0m     +  0.0033  0.2053\n",
      "     56      384.8867      645.4940        0.0025  0.1985\n",
      "     57      \u001b[36m370.7000\u001b[0m      \u001b[32m637.2258\u001b[0m     +  0.0017  0.2939\n",
      "     58      \u001b[36m366.2023\u001b[0m      643.1787        0.0010  0.2014\n",
      "     59      \u001b[36m361.4242\u001b[0m      642.3116        0.0005  0.3145\n",
      "     60      \u001b[36m359.7501\u001b[0m      643.0528        0.0001  0.2028\n",
      "     61      389.9594      669.4796        0.0050  0.2991\n",
      "     62      422.1865      692.9805        0.0049  0.2187\n",
      "     63      437.1779      678.3011        0.0045  0.3383\n",
      "     64      399.3630      \u001b[32m610.2256\u001b[0m     +  0.0040  0.2058\n",
      "     65      377.0874      630.8583        0.0033  0.2317\n",
      "     66      367.4799      615.4331        0.0025  0.3569\n",
      "     67      \u001b[36m358.6988\u001b[0m      623.1566        0.0017  0.1911\n",
      "     68      \u001b[36m352.8414\u001b[0m      623.8503        0.0010  0.3078\n",
      "     69      \u001b[36m349.7385\u001b[0m      626.1495        0.0005  0.2074\n",
      "     70      \u001b[36m347.9531\u001b[0m      626.8885        0.0001  0.3074\n",
      "     71      376.2547      646.0222        0.0050  0.2002\n",
      "     72      405.6909      663.5457        0.0049  0.3073\n",
      "     73      426.2618      682.0376        0.0045  0.2041\n",
      "     74      396.1770      \u001b[32m590.3367\u001b[0m     +  0.0040  0.2059\n",
      "     75      368.4117      614.9644        0.0033  0.3049\n",
      "     76      357.1482      602.0710        0.0025  0.2134\n",
      "     77      349.2826      609.8288        0.0017  0.3032\n",
      "     78      \u001b[36m343.8526\u001b[0m      614.0008        0.0010  0.2004\n",
      "     79      \u001b[36m340.6634\u001b[0m      616.0820        0.0005  0.2960\n",
      "     80      \u001b[36m339.0084\u001b[0m      616.9485        0.0001  0.2010\n",
      "     81      366.3853      624.0939        0.0050  0.3106\n",
      "     82      393.6531      654.3133        0.0049  0.2397\n",
      "     83      416.7549      654.1575        0.0045  0.2093\n",
      "     84      386.6538      \u001b[32m583.8390\u001b[0m     +  0.0040  0.2981\n",
      "     85      357.9700      603.0384        0.0033  0.2060\n",
      "     86      348.1997      598.3069        0.0025  0.3079\n",
      "     87      341.5881      604.3012        0.0017  0.2069\n",
      "     88      \u001b[36m335.7101\u001b[0m      610.0545        0.0010  0.2969\n",
      "     89      \u001b[36m332.9864\u001b[0m      613.5768        0.0005  0.1958\n",
      "     90      \u001b[36m331.4116\u001b[0m      614.2338        0.0001  0.3113\n",
      "     91      357.8124      610.4244        0.0050  0.2061\n",
      "     92      380.9541      633.1537        0.0049  0.1935\n",
      "     93      400.0710      632.0029        0.0045  0.3282\n",
      "     94      386.2509      \u001b[32m574.2723\u001b[0m     +  0.0040  0.2026\n",
      "     95      351.8251      598.5984        0.0033  0.2955\n",
      "     96      338.2921      599.3411        0.0025  0.2070\n",
      "     97      334.2800      599.7885        0.0017  0.3005\n",
      "     98      \u001b[36m328.6805\u001b[0m      604.5505        0.0010  0.1965\n",
      "     99      \u001b[36m326.3563\u001b[0m      611.3197        0.0005  0.3059\n",
      "    100      \u001b[36m324.8109\u001b[0m      611.4589        0.0001  0.2023\n",
      "    101      349.8939      603.5882        0.0050  0.2153\n",
      "    102      369.8366      617.9654        0.0049  0.3815\n",
      "    103      387.9033      619.5708        0.0045  0.3111\n",
      "    104      379.5456      576.3681        0.0040  0.4643\n",
      "    105      347.6954      599.9832        0.0033  0.2062\n",
      "    106      331.6160      601.3036        0.0025  0.3200\n",
      "    107      327.9117      600.1577        0.0017  0.2033\n",
      "    108      \u001b[36m322.7994\u001b[0m      604.1477        0.0010  0.2928\n",
      "    109      \u001b[36m320.3644\u001b[0m      610.8365        0.0005  0.2086\n",
      "    110      \u001b[36m318.9008\u001b[0m      610.8206        0.0001  0.1982\n",
      "    111      343.9268      604.3773        0.0050  0.3151\n",
      "    112      361.8076      608.4477        0.0049  0.1983\n",
      "    113      379.2128      610.9810        0.0045  0.3087\n",
      "    114      374.8193      \u001b[32m569.5579\u001b[0m     +  0.0040  0.2043\n",
      "    115      343.8364      595.6430        0.0033  0.3127\n",
      "    116      326.9008      606.5596        0.0025  0.2098\n",
      "    117      322.0652      597.4320        0.0017  0.3075\n",
      "    118      \u001b[36m317.9604\u001b[0m      603.7496        0.0010  0.1980\n",
      "    119      \u001b[36m315.2671\u001b[0m      609.8538        0.0005  0.2089\n",
      "    120      \u001b[36m313.8883\u001b[0m      609.5797        0.0001  0.3127\n",
      "    121      337.8379      608.5190        0.0050  0.4450\n",
      "    122      353.5849      594.2082        0.0049  0.3767\n",
      "    123      369.7170      602.3004        0.0045  0.1985\n",
      "    124      368.6361      571.0651        0.0040  0.2935\n",
      "    125      342.6999      587.0655        0.0033  0.2107\n",
      "    126      322.8158      634.8399        0.0025  0.2930\n",
      "    127      316.8940      607.3888        0.0017  0.2066\n",
      "    128      \u001b[36m313.6488\u001b[0m      613.9757        0.0010  0.1993\n",
      "    129      \u001b[36m310.4105\u001b[0m      618.0570        0.0005  0.2969\n",
      "    130      \u001b[36m309.0810\u001b[0m      616.9701        0.0001  0.1984\n",
      "    131      332.1314      604.9538        0.0050  0.3029\n",
      "    132      346.1469      588.1742        0.0049  0.2054\n",
      "    133      359.9268      593.2297        0.0045  0.3049\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m878.8314\u001b[0m     \u001b[32m1028.5668\u001b[0m     +  0.0050  0.3007\n",
      "      2      \u001b[36m871.5208\u001b[0m     1210.3094        0.0049  0.2168\n",
      "      3      \u001b[36m665.7069\u001b[0m      \u001b[32m920.3331\u001b[0m     +  0.0045  0.3066\n",
      "      4      701.4399     1028.2938        0.0040  0.2058\n",
      "      5      \u001b[36m619.6792\u001b[0m      921.9416        0.0033  0.2101\n",
      "      6      \u001b[36m600.4888\u001b[0m      \u001b[32m918.6525\u001b[0m     +  0.0025  0.2988\n",
      "      7      \u001b[36m561.7288\u001b[0m      \u001b[32m893.2179\u001b[0m     +  0.0017  0.2078\n",
      "      8      \u001b[36m539.2660\u001b[0m      \u001b[32m871.4084\u001b[0m     +  0.0010  0.3013\n",
      "      9      \u001b[36m524.4012\u001b[0m      \u001b[32m862.9641\u001b[0m     +  0.0005  0.2118\n",
      "     10      \u001b[36m516.9697\u001b[0m      \u001b[32m860.6004\u001b[0m     +  0.0001  0.3884\n",
      "     11      603.4745      \u001b[32m821.1968\u001b[0m     +  0.0050  0.2020\n",
      "     12      685.7534     1016.5188        0.0049  0.1961\n",
      "     13      546.3878      \u001b[32m807.9531\u001b[0m     +  0.0045  0.3063\n",
      "     14      \u001b[36m492.3680\u001b[0m      809.5836        0.0040  0.2091\n",
      "     15      \u001b[36m484.7039\u001b[0m      \u001b[32m790.5436\u001b[0m     +  0.0033  0.3004\n",
      "     16      \u001b[36m459.4058\u001b[0m      \u001b[32m766.6605\u001b[0m     +  0.0025  0.2084\n",
      "     17      \u001b[36m448.1632\u001b[0m      \u001b[32m759.0541\u001b[0m     +  0.0017  0.3029\n",
      "     18      \u001b[36m438.8493\u001b[0m      \u001b[32m751.4821\u001b[0m     +  0.0010  0.1995\n",
      "     19      \u001b[36m433.7575\u001b[0m      \u001b[32m751.0484\u001b[0m     +  0.0005  0.2056\n",
      "     20      \u001b[36m430.9368\u001b[0m      \u001b[32m750.5355\u001b[0m     +  0.0001  0.3126\n",
      "     21      472.4608      764.9790        0.0050  0.2043\n",
      "     22      528.2543      819.5419        0.0049  0.3455\n",
      "     23      509.7507      798.4306        0.0045  0.2086\n",
      "     24      453.6173      \u001b[32m733.3739\u001b[0m     +  0.0040  0.2993\n",
      "     25      432.3235      734.3907        0.0033  0.2452\n",
      "     26      \u001b[36m426.1812\u001b[0m      \u001b[32m718.3110\u001b[0m     +  0.0025  0.4557\n",
      "     27      \u001b[36m414.4518\u001b[0m      \u001b[32m716.7828\u001b[0m     +  0.0017  0.3442\n",
      "     28      \u001b[36m409.0729\u001b[0m      \u001b[32m715.7236\u001b[0m     +  0.0010  0.2202\n",
      "     29      \u001b[36m404.9587\u001b[0m      \u001b[32m714.8689\u001b[0m     +  0.0005  0.3162\n",
      "     30      \u001b[36m402.8252\u001b[0m      \u001b[32m714.7332\u001b[0m     +  0.0001  0.2106\n",
      "     31      433.9542      749.6596        0.0050  0.3072\n",
      "     32      477.9424      778.3537        0.0049  0.2041\n",
      "     33      477.3128      750.8666        0.0045  0.3073\n",
      "     34      433.9252      \u001b[32m697.7976\u001b[0m     +  0.0040  0.2027\n",
      "     35      410.6433      \u001b[32m697.3037\u001b[0m     +  0.0033  0.2124\n",
      "     36      406.4067      \u001b[32m691.8954\u001b[0m     +  0.0025  0.3091\n",
      "     37      \u001b[36m395.8060\u001b[0m      \u001b[32m688.4707\u001b[0m     +  0.0017  0.2090\n",
      "     38      \u001b[36m391.4170\u001b[0m      689.3533        0.0010  0.3185\n",
      "     39      \u001b[36m387.5730\u001b[0m      689.6393        0.0005  0.2026\n",
      "     40      \u001b[36m385.7250\u001b[0m      689.9136        0.0001  0.2983\n",
      "     41      412.4621      721.5229        0.0050  0.1956\n",
      "     42      452.8226      761.8413        0.0049  0.2205\n",
      "     43      463.1900      725.4404        0.0045  0.2903\n",
      "     44      422.9900      \u001b[32m673.1868\u001b[0m     +  0.0040  0.2264\n",
      "     45      396.7645      \u001b[32m668.7945\u001b[0m     +  0.0033  0.3999\n",
      "     46      393.2205      \u001b[32m664.7325\u001b[0m     +  0.0025  0.2311\n",
      "     47      \u001b[36m382.8868\u001b[0m      \u001b[32m660.0778\u001b[0m     +  0.0017  0.6523\n",
      "     48      \u001b[36m377.7075\u001b[0m      \u001b[32m659.4731\u001b[0m     +  0.0010  0.4084\n",
      "     49      \u001b[36m373.8407\u001b[0m      660.1478        0.0005  0.2950\n",
      "     50      \u001b[36m371.9074\u001b[0m      660.6716        0.0001  0.1944\n",
      "     51      398.5822      702.1838        0.0050  0.1959\n",
      "     52      437.1333      699.6559        0.0049  0.2962\n",
      "     53      444.9444      705.8435        0.0045  0.2016\n",
      "     54      453.7874      723.0582        0.0040  0.3177\n",
      "     55      411.4101      683.0679        0.0033  0.2058\n",
      "     56      391.6765      701.0440        0.0025  0.3119\n",
      "     57      383.1427      692.8028        0.0017  0.2050\n",
      "     58      378.7041      694.9310        0.0010  0.2963\n",
      "     59      374.8757      694.2794        0.0005  0.1983\n",
      "     60      373.3696      694.6624        0.0001  0.2061\n",
      "     61      400.4438      711.2040        0.0050  0.3123\n",
      "     62      435.2585      733.7594        0.0049  0.2100\n",
      "     63      463.2771      736.7644        0.0045  0.3050\n",
      "     64      411.8767      676.0475        0.0040  0.2048\n",
      "     65      385.8998      687.6239        0.0033  0.3157\n",
      "     66      385.4961      674.2648        0.0025  0.2005\n",
      "     67      374.7357      673.7716        0.0017  0.3218\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Power: 2, Threshold: 0.05, Pearson: 0.8308779245422788, Spearman: 0.8574231151723816\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.05, Pearson: 0.8304391606361785, Spearman: 0.8561283056573967\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.05, Pearson: 0.8304391606361785, Spearman: 0.8561283056573967\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.1, Pearson: 0.8380750873969691, Spearman: 0.8621492998532895\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.1, Pearson: 0.8380750873969691, Spearman: 0.8621492998532895\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.1, Pearson: 0.8380750873969691, Spearman: 0.8621492998532895\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.2, Pearson: 0.8360095442251252, Spearman: 0.8599120339540993\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.2, Pearson: 0.8360095442251252, Spearman: 0.8599120339540993\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.2, Pearson: 0.8360095442251252, Spearman: 0.8599120339540993\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.3, Pearson: 0.8292202659907597, Spearman: 0.8546178923356027\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.3, Pearson: 0.8292202659907597, Spearman: 0.8546178923356027\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.3, Pearson: 0.8292202659907597, Spearman: 0.8546178923356027\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.5, Pearson: 0.8238660879912972, Spearman: 0.8495597155649753\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.5, Pearson: 0.8238660879912972, Spearman: 0.8495597155649753\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.5, Pearson: 0.8238660879912972, Spearman: 0.8495597155649753\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.7, Pearson: 0.7888153465342139, Spearman: 0.8324461193252513\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.7, Pearson: 0.7888153465342139, Spearman: 0.8324461193252513\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 2, Threshold: 0.7, Pearson: 0.7888153465342139, Spearman: 0.8324461193252513\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m918.0739\u001b[0m      \u001b[32m984.9147\u001b[0m     +  0.0050  0.3661\n",
      "      2      960.7531     1303.8948        0.0049  0.2040\n",
      "      3      \u001b[36m672.2071\u001b[0m      \u001b[32m935.8909\u001b[0m     +  0.0045  0.3007\n",
      "      4      707.2188     1050.4569        0.0040  0.2036\n",
      "      5      \u001b[36m628.4440\u001b[0m      958.6697        0.0033  0.1972\n",
      "      6      \u001b[36m602.5711\u001b[0m      936.9444        0.0025  0.3056\n",
      "      7      \u001b[36m562.1205\u001b[0m      \u001b[32m911.3466\u001b[0m     +  0.0017  0.1992\n",
      "      8      \u001b[36m533.3509\u001b[0m      \u001b[32m885.5523\u001b[0m     +  0.0010  0.3079\n",
      "      9      \u001b[36m514.9414\u001b[0m      \u001b[32m873.2853\u001b[0m     +  0.0005  0.1994\n",
      "     10      \u001b[36m506.0538\u001b[0m      \u001b[32m869.9303\u001b[0m     +  0.0001  0.3199\n",
      "     11      603.1085      \u001b[32m796.9779\u001b[0m     +  0.0050  0.2829\n",
      "     12      725.7858     1047.8542        0.0049  0.1996\n",
      "     13      535.7116      826.5982        0.0045  0.3310\n",
      "     14      \u001b[36m494.3715\u001b[0m      806.9786        0.0040  0.2018\n",
      "     15      \u001b[36m475.8480\u001b[0m      \u001b[32m785.6267\u001b[0m     +  0.0033  0.2945\n",
      "     16      \u001b[36m447.7315\u001b[0m      \u001b[32m751.9517\u001b[0m     +  0.0025  0.2046\n",
      "     17      \u001b[36m437.0033\u001b[0m      \u001b[32m741.1164\u001b[0m     +  0.0017  0.3099\n",
      "     18      \u001b[36m427.0476\u001b[0m      \u001b[32m735.0612\u001b[0m     +  0.0010  0.1978\n",
      "     19      \u001b[36m421.9160\u001b[0m      \u001b[32m731.4357\u001b[0m     +  0.0005  0.1937\n",
      "     20      \u001b[36m419.1243\u001b[0m      \u001b[32m730.4869\u001b[0m     +  0.0001  0.3038\n",
      "     21      465.1012      742.2210        0.0050  0.1958\n",
      "     22      533.5967      803.1232        0.0049  0.2883\n",
      "     23      506.7693      801.5345        0.0045  0.2010\n",
      "     24      440.9288      \u001b[32m719.3319\u001b[0m     +  0.0040  0.3000\n",
      "     25      422.2551      \u001b[32m718.6524\u001b[0m     +  0.0033  0.1973\n",
      "     26      \u001b[36m414.8358\u001b[0m      \u001b[32m701.7699\u001b[0m     +  0.0025  0.2957\n",
      "     27      \u001b[36m402.5982\u001b[0m      \u001b[32m694.6352\u001b[0m     +  0.0017  0.1934\n",
      "     28      \u001b[36m397.1536\u001b[0m      \u001b[32m691.7912\u001b[0m     +  0.0010  0.1985\n",
      "     29      \u001b[36m392.8927\u001b[0m      \u001b[32m690.5835\u001b[0m     +  0.0005  0.3082\n",
      "     30      \u001b[36m390.6897\u001b[0m      \u001b[32m690.2452\u001b[0m     +  0.0001  0.2021\n",
      "     31      425.4964      710.8165        0.0050  0.3007\n",
      "     32      475.6647      783.5028        0.0049  0.1999\n",
      "     33      471.1377      745.4203        0.0045  0.3074\n",
      "     34      417.9125      \u001b[32m684.7790\u001b[0m     +  0.0040  0.2048\n",
      "     35      399.4464      \u001b[32m680.9788\u001b[0m     +  0.0033  0.2085\n",
      "     36      394.6062      \u001b[32m670.3535\u001b[0m     +  0.0025  0.3086\n",
      "     37      \u001b[36m383.2736\u001b[0m      \u001b[32m665.5620\u001b[0m     +  0.0017  0.2048\n",
      "     38      \u001b[36m378.9213\u001b[0m      \u001b[32m665.1404\u001b[0m     +  0.0010  0.2961\n",
      "     39      \u001b[36m375.0488\u001b[0m      \u001b[32m664.7857\u001b[0m     +  0.0005  0.1951\n",
      "     40      \u001b[36m373.1333\u001b[0m      \u001b[32m664.7614\u001b[0m     +  0.0001  0.3038\n",
      "     41      403.5410      690.4146        0.0050  0.2027\n",
      "     42      450.7335      747.8510        0.0049  0.2041\n",
      "     43      455.5369      726.8485        0.0045  0.3970\n",
      "     44      405.6703      668.3738        0.0040  0.3329\n",
      "     45      383.8333      664.7669        0.0033  0.3722\n",
      "     46      381.2447      \u001b[32m653.0030\u001b[0m     +  0.0025  0.2796\n",
      "     47      \u001b[36m369.7990\u001b[0m      \u001b[32m652.7933\u001b[0m     +  0.0017  0.2989\n",
      "     48      \u001b[36m366.0524\u001b[0m      653.9813        0.0010  0.2081\n",
      "     49      \u001b[36m362.3092\u001b[0m      653.8714        0.0005  0.2971\n",
      "     50      \u001b[36m360.5682\u001b[0m      654.0946        0.0001  0.2091\n",
      "     51      388.4305      671.8036        0.0050  0.2045\n",
      "     52      433.1190      738.2247        0.0049  0.2929\n",
      "     53      446.7241      706.2599        0.0045  0.1985\n",
      "     54      395.9949      655.0851        0.0040  0.3011\n",
      "     55      371.8553      \u001b[32m642.6945\u001b[0m     +  0.0033  0.2041\n",
      "     56      370.9075      \u001b[32m639.0503\u001b[0m     +  0.0025  0.3105\n",
      "     57      \u001b[36m359.5339\u001b[0m      \u001b[32m638.5586\u001b[0m     +  0.0017  0.2094\n",
      "     58      \u001b[36m356.2361\u001b[0m      642.4836        0.0010  0.3031\n",
      "     59      \u001b[36m352.5919\u001b[0m      643.0346        0.0005  0.2182\n",
      "     60      \u001b[36m351.0302\u001b[0m      643.5019        0.0001  0.1994\n",
      "     61      377.0498      661.3329        0.0050  0.3061\n",
      "     62      418.0143      713.6096        0.0049  0.2041\n",
      "     63      431.4650      690.5740        0.0045  0.2904\n",
      "     64      386.5244      \u001b[32m633.7157\u001b[0m     +  0.0040  0.2063\n",
      "     65      361.9776      \u001b[32m630.2339\u001b[0m     +  0.0033  0.3014\n",
      "     66      361.7648      \u001b[32m625.6860\u001b[0m     +  0.0025  0.1953\n",
      "     67      351.0351      628.9057        0.0017  0.2945\n",
      "     68      \u001b[36m347.7095\u001b[0m      635.1368        0.0010  0.2087\n",
      "     69      \u001b[36m344.1518\u001b[0m      635.4025        0.0005  0.1995\n",
      "     70      \u001b[36m342.7326\u001b[0m      635.9514        0.0001  0.2967\n",
      "     71      367.9543      649.4191        0.0050  0.1994\n",
      "     72      406.2956      696.5005        0.0049  0.2996\n",
      "     73      423.6743      680.6644        0.0045  0.2056\n",
      "     74      382.9997      \u001b[32m618.4820\u001b[0m     +  0.0040  0.2946\n",
      "     75      353.2374      621.8822        0.0033  0.2059\n",
      "     76      353.3383      \u001b[32m614.3571\u001b[0m     +  0.0025  0.3072\n",
      "     77      344.0106      619.9883        0.0017  0.1981\n",
      "     78      \u001b[36m339.8415\u001b[0m      625.5981        0.0010  0.2028\n",
      "     79      \u001b[36m336.5070\u001b[0m      626.2081        0.0005  0.3009\n",
      "     80      \u001b[36m335.1181\u001b[0m      627.0920        0.0001  0.2012\n",
      "     81      359.4906      634.5220        0.0050  0.2979\n",
      "     82      397.7521      667.3005        0.0049  0.2055\n",
      "     83      415.6818      698.2155        0.0045  0.2952\n",
      "     84      423.2870      638.5603        0.0040  0.2058\n",
      "     85      357.5408      614.9006        0.0033  0.3638\n",
      "     86      355.4344      633.8321        0.0025  0.2069\n",
      "     87      343.2028      625.1035        0.0017  0.1972\n",
      "     88      336.6645      627.0226        0.0010  0.3124\n",
      "     89      \u001b[36m332.7583\u001b[0m      625.5288        0.0005  0.1952\n",
      "     90      \u001b[36m331.5217\u001b[0m      626.2210        0.0001  0.3002\n",
      "     91      354.0780      614.3632        0.0050  0.2070\n",
      "     92      382.1011      644.6880        0.0049  0.2964\n",
      "     93      395.4065      644.6703        0.0045  0.1969\n",
      "     94      364.6325      \u001b[32m583.2096\u001b[0m     +  0.0040  0.3112\n",
      "     95      340.4502      604.9286        0.0033  0.1926\n",
      "     96      338.2481      \u001b[32m580.8509\u001b[0m     +  0.0025  0.2090\n",
      "     97      \u001b[36m330.8910\u001b[0m      601.2719        0.0017  0.3077\n",
      "     98      \u001b[36m325.4260\u001b[0m      599.7081        0.0010  0.1995\n",
      "     99      \u001b[36m322.3942\u001b[0m      599.0592        0.0005  0.3089\n",
      "    100      \u001b[36m320.8261\u001b[0m      599.9452        0.0001  0.1991\n",
      "    101      347.0639      590.8324        0.0050  0.2915\n",
      "    102      373.4406      626.4272        0.0049  0.2072\n",
      "    103      393.0529      645.6898        0.0045  0.3045\n",
      "    104      368.7600      \u001b[32m554.2408\u001b[0m     +  0.0040  0.1971\n",
      "    105      336.8580      580.0074        0.0033  0.2326\n",
      "    106      326.3887      562.2279        0.0025  0.3469\n",
      "    107      322.3359      575.2358        0.0017  0.2015\n",
      "    108      \u001b[36m315.0939\u001b[0m      574.3329        0.0010  0.3120\n",
      "    109      \u001b[36m312.6704\u001b[0m      577.3627        0.0005  0.2089\n",
      "    110      \u001b[36m310.9948\u001b[0m      578.1341        0.0001  0.3005\n",
      "    111      337.6520      574.3910        0.0050  0.2008\n",
      "    112      360.6285      611.5063        0.0049  0.3060\n",
      "    113      380.8892      616.8466        0.0045  0.2055\n",
      "    114      364.2220      \u001b[32m542.6348\u001b[0m     +  0.0040  0.1977\n",
      "    115      329.6769      573.1977        0.0033  0.3021\n",
      "    116      316.9879      555.0285        0.0025  0.2013\n",
      "    117      313.4640      563.2832        0.0017  0.2902\n",
      "    118      \u001b[36m306.4203\u001b[0m      565.0562        0.0010  0.1960\n",
      "    119      \u001b[36m304.0404\u001b[0m      569.6292        0.0005  0.3010\n",
      "    120      \u001b[36m302.4546\u001b[0m      569.9102        0.0001  0.1985\n",
      "    121      327.3835      561.4277        0.0050  0.2928\n",
      "    122      349.2785      582.3775        0.0049  0.2267\n",
      "    123      366.2026      595.0217        0.0045  0.1931\n",
      "    124      360.3740      544.9182        0.0040  0.3312\n",
      "    125      331.6175      566.8089        0.0033  0.2342\n",
      "    126      310.2854      555.3105        0.0025  0.4583\n",
      "    127      304.4810      554.3641        0.0017  0.1917\n",
      "    128      \u001b[36m299.7839\u001b[0m      556.4791        0.0010  0.2915\n",
      "    129      \u001b[36m296.7407\u001b[0m      561.3418        0.0005  0.1891\n",
      "    130      \u001b[36m295.2075\u001b[0m      560.8614        0.0001  0.3083\n",
      "    131      319.7095      551.4754        0.0050  0.1985\n",
      "    132      336.8462      570.0120        0.0049  0.1972\n",
      "    133      352.0097      575.2985        0.0045  0.2966\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m911.6339\u001b[0m      \u001b[32m984.9355\u001b[0m     +  0.0050  0.4698\n",
      "      2      956.9901     1249.3614        0.0049  0.3239\n",
      "      3      \u001b[36m683.1588\u001b[0m      \u001b[32m980.4573\u001b[0m     +  0.0045  0.3483\n",
      "      4      722.6410     1033.8496        0.0040  0.1954\n",
      "      5      \u001b[36m633.8437\u001b[0m      \u001b[32m955.1306\u001b[0m     +  0.0033  0.2973\n",
      "      6      \u001b[36m607.1957\u001b[0m      \u001b[32m934.7450\u001b[0m     +  0.0025  0.2161\n",
      "      7      \u001b[36m566.7245\u001b[0m      \u001b[32m909.6501\u001b[0m     +  0.0017  0.2784\n",
      "      8      \u001b[36m539.1735\u001b[0m      \u001b[32m885.4240\u001b[0m     +  0.0010  0.6487\n",
      "      9      \u001b[36m522.4105\u001b[0m      \u001b[32m875.4972\u001b[0m     +  0.0005  0.3657\n",
      "     10      \u001b[36m514.1611\u001b[0m      \u001b[32m872.8410\u001b[0m     +  0.0001  0.3098\n",
      "     11      608.5868      \u001b[32m803.6800\u001b[0m     +  0.0050  0.2051\n",
      "     12      709.1238     1045.6039        0.0049  0.3013\n",
      "     13      527.8572      \u001b[32m792.7557\u001b[0m     +  0.0045  0.1917\n",
      "     14      \u001b[36m485.0615\u001b[0m      807.8828        0.0040  0.1984\n",
      "     15      \u001b[36m474.5394\u001b[0m      \u001b[32m780.5163\u001b[0m     +  0.0033  0.2969\n",
      "     16      \u001b[36m448.9562\u001b[0m      \u001b[32m758.0219\u001b[0m     +  0.0025  0.1936\n",
      "     17      \u001b[36m440.5524\u001b[0m      \u001b[32m749.9995\u001b[0m     +  0.0017  0.2869\n",
      "     18      \u001b[36m430.9892\u001b[0m      \u001b[32m743.5869\u001b[0m     +  0.0010  0.1933\n",
      "     19      \u001b[36m426.3362\u001b[0m      \u001b[32m739.5698\u001b[0m     +  0.0005  0.2922\n",
      "     20      \u001b[36m423.7259\u001b[0m      \u001b[32m738.5969\u001b[0m     +  0.0001  0.1954\n",
      "     21      464.1628      770.4309        0.0050  0.2893\n",
      "     22      514.4265      808.3161        0.0049  0.2031\n",
      "     23      484.4067      769.6888        0.0045  0.2015\n",
      "     24      436.3896      \u001b[32m720.2390\u001b[0m     +  0.0040  0.2940\n",
      "     25      425.9776      \u001b[32m717.3580\u001b[0m     +  0.0033  0.2010\n",
      "     26      \u001b[36m415.6833\u001b[0m      \u001b[32m704.7396\u001b[0m     +  0.0025  0.4149\n",
      "     27      \u001b[36m406.0268\u001b[0m      \u001b[32m699.9852\u001b[0m     +  0.0017  0.3009\n",
      "     28      \u001b[36m400.2892\u001b[0m      \u001b[32m696.7277\u001b[0m     +  0.0010  0.3359\n",
      "     29      \u001b[36m396.4707\u001b[0m      \u001b[32m695.2530\u001b[0m     +  0.0005  0.3695\n",
      "     30      \u001b[36m394.4118\u001b[0m      \u001b[32m694.8993\u001b[0m     +  0.0001  0.4248\n",
      "     31      424.9550      720.0646        0.0050  0.3538\n",
      "     32      465.9571      775.4361        0.0049  0.2101\n",
      "     33      459.8422      733.9406        0.0045  0.3010\n",
      "     34      420.6976      \u001b[32m680.1028\u001b[0m     +  0.0040  0.2076\n",
      "     35      399.6743      680.6612        0.0033  0.3158\n",
      "     36      394.7587      \u001b[32m671.7549\u001b[0m     +  0.0025  0.2282\n",
      "     37      \u001b[36m384.9105\u001b[0m      \u001b[32m667.1038\u001b[0m     +  0.0017  0.1953\n",
      "     38      \u001b[36m380.3241\u001b[0m      \u001b[32m666.4990\u001b[0m     +  0.0010  0.4586\n",
      "     39      \u001b[36m376.5745\u001b[0m      \u001b[32m666.1727\u001b[0m     +  0.0005  0.5056\n",
      "     40      \u001b[36m374.7169\u001b[0m      \u001b[32m666.1547\u001b[0m     +  0.0001  0.3722\n",
      "     41      402.2779      697.6303        0.0050  0.1905\n",
      "     42      442.7180      743.2650        0.0049  0.3014\n",
      "     43      444.7557      711.1374        0.0045  0.1901\n",
      "     44      405.0789      \u001b[32m654.0500\u001b[0m     +  0.0040  0.3013\n",
      "     45      384.0963      659.6226        0.0033  0.2019\n",
      "     46      380.8923      654.4683        0.0025  0.2087\n",
      "     47      \u001b[36m370.5573\u001b[0m      \u001b[32m653.4666\u001b[0m     +  0.0017  0.2897\n",
      "     48      \u001b[36m366.8294\u001b[0m      654.2393        0.0010  0.2000\n",
      "     49      \u001b[36m363.1580\u001b[0m      654.3973        0.0005  0.2993\n",
      "     50      \u001b[36m361.4902\u001b[0m      654.7307        0.0001  0.1958\n",
      "     51      386.6125      675.0252        0.0050  0.2999\n",
      "     52      424.7536      714.0534        0.0049  0.1947\n",
      "     53      434.7260      701.5995        0.0045  0.3110\n",
      "     54      397.3136      \u001b[32m623.5596\u001b[0m     +  0.0040  0.4708\n",
      "     55      372.3234      651.8649        0.0033  0.4585\n",
      "     56      370.9238      636.1635        0.0025  0.3069\n",
      "     57      \u001b[36m360.0529\u001b[0m      635.5762        0.0017  0.2023\n",
      "     58      \u001b[36m356.6549\u001b[0m      639.9023        0.0010  0.2912\n",
      "     59      \u001b[36m352.8662\u001b[0m      639.9524        0.0005  0.1941\n",
      "     60      \u001b[36m351.3112\u001b[0m      640.4003        0.0001  0.3063\n",
      "     61      376.0925      665.9080        0.0050  0.1971\n",
      "     62      412.8601      686.8813        0.0049  0.2915\n",
      "     63      424.6442      679.9173        0.0045  0.1994\n",
      "     64      390.7399      \u001b[32m612.9137\u001b[0m     +  0.0040  0.1979\n",
      "     65      363.9382      632.0365        0.0033  0.3111\n",
      "     66      361.2919      615.5485        0.0025  0.1983\n",
      "     67      351.8318      620.2363        0.0017  0.3015\n",
      "     68      \u001b[36m347.7133\u001b[0m      620.5197        0.0010  0.1990\n",
      "     69      \u001b[36m344.0088\u001b[0m      618.7404        0.0005  0.2937\n",
      "     70      \u001b[36m342.4509\u001b[0m      619.5147        0.0001  0.1983\n",
      "     71      365.5807      630.2656        0.0050  0.3196\n",
      "     72      391.8976      653.7080        0.0049  0.2212\n",
      "     73      404.9341      690.1738        0.0045  0.2127\n",
      "     74      435.2235      678.9150        0.0040  0.2963\n",
      "     75      379.4272      \u001b[32m605.5939\u001b[0m     +  0.0033  0.2064\n",
      "     76      352.0685      611.2533        0.0025  0.2983\n",
      "     77      349.6610      612.2856        0.0017  0.1994\n",
      "     78      \u001b[36m337.5440\u001b[0m      \u001b[32m592.6053\u001b[0m     +  0.0010  0.3030\n",
      "     79      \u001b[36m335.1918\u001b[0m      593.4639        0.0005  0.2042\n",
      "     80      \u001b[36m333.3129\u001b[0m      593.9995        0.0001  0.3035\n",
      "     81      358.6879      608.8237        0.0050  0.2172\n",
      "     82      386.6633      644.2831        0.0049  0.2111\n",
      "     83      405.6092      632.3322        0.0045  0.4755\n",
      "     84      374.0160      \u001b[32m555.6551\u001b[0m     +  0.0040  0.1990\n",
      "     85      347.2281      583.4639        0.0033  0.3054\n",
      "     86      337.0398      561.5960        0.0025  0.2081\n",
      "     87      \u001b[36m331.4696\u001b[0m      575.1162        0.0017  0.3083\n",
      "     88      \u001b[36m325.7255\u001b[0m      577.2624        0.0010  0.2064\n",
      "     89      \u001b[36m323.1905\u001b[0m      580.2110        0.0005  0.3054\n",
      "     90      \u001b[36m321.6385\u001b[0m      581.0208        0.0001  0.2080\n",
      "     91      346.0755      591.2136        0.0050  0.2158\n",
      "     92      372.0552      610.0893        0.0049  0.3148\n",
      "     93      390.3694      618.5190        0.0045  0.1953\n",
      "     94      374.2916      \u001b[32m551.8245\u001b[0m     +  0.0040  0.3045\n",
      "     95      341.2307      573.1947        0.0033  0.2044\n",
      "     96      327.0774      556.8369        0.0025  0.2953\n",
      "     97      324.3141      567.1309        0.0017  0.1981\n",
      "     98      \u001b[36m317.6984\u001b[0m      566.5782        0.0010  0.2991\n",
      "     99      \u001b[36m315.4675\u001b[0m      571.1661        0.0005  0.2068\n",
      "    100      \u001b[36m313.9664\u001b[0m      571.9487        0.0001  0.2031\n",
      "    101      337.9369      582.5345        0.0050  0.2987\n",
      "    102      359.6849      593.2619        0.0049  0.1972\n",
      "    103      378.2520      608.5300        0.0045  0.3065\n",
      "    104      370.6323      \u001b[32m539.5884\u001b[0m     +  0.0040  0.1931\n",
      "    105      337.1833      563.5209        0.0033  0.2937\n",
      "    106      319.3256      551.7499        0.0025  0.1985\n",
      "    107      317.4164      554.7401        0.0017  0.3013\n",
      "    108      \u001b[36m311.3884\u001b[0m      559.2007        0.0010  0.1931\n",
      "    109      \u001b[36m309.1613\u001b[0m      565.0258        0.0005  0.1941\n",
      "    110      \u001b[36m307.7083\u001b[0m      565.5138        0.0001  0.2975\n",
      "    111      330.5208      565.6020        0.0050  0.2219\n",
      "    112      349.3601      576.9870        0.0049  0.3311\n",
      "    113      365.4100      590.3706        0.0045  0.1995\n",
      "    114      365.9238      \u001b[32m538.4428\u001b[0m     +  0.0040  0.3057\n",
      "    115      335.1623      547.7722        0.0033  0.2048\n",
      "    116      312.9662      561.7955        0.0025  0.3004\n",
      "    117      311.1807      553.5668        0.0017  0.2074\n",
      "    118      \u001b[36m305.8585\u001b[0m      554.7067        0.0010  0.2009\n",
      "    119      \u001b[36m303.5701\u001b[0m      562.2122        0.0005  0.2986\n",
      "    120      \u001b[36m302.1787\u001b[0m      562.7113        0.0001  0.2072\n",
      "    121      323.5201      562.5760        0.0050  0.2975\n",
      "    122      340.4378      561.9828        0.0049  0.2060\n",
      "    123      355.9256      576.0541        0.0045  0.2919\n",
      "    124      362.7635      546.0519        0.0040  0.1978\n",
      "    125      333.6684      \u001b[32m535.7648\u001b[0m     +  0.0033  0.3080\n",
      "    126      309.4905      585.1097        0.0025  0.2053\n",
      "    127      306.8996      564.1049        0.0017  0.1984\n",
      "    128      \u001b[36m302.0592\u001b[0m      559.4446        0.0010  0.3068\n",
      "    129      \u001b[36m299.4394\u001b[0m      567.0655        0.0005  0.2098\n",
      "    130      \u001b[36m298.0696\u001b[0m      566.7183        0.0001  0.3159\n",
      "    131      318.6163      553.7169        0.0050  0.2170\n",
      "    132      331.3267      551.7597        0.0049  0.3283\n",
      "    133      343.2511      558.9547        0.0045  0.2448\n",
      "    134      353.3010      538.2811        0.0040  0.5593\n",
      "    135      330.1423      \u001b[32m527.0513\u001b[0m     +  0.0033  0.2056\n",
      "    136      305.8577      590.7080        0.0025  0.1958\n",
      "    137      301.6971      571.5715        0.0017  0.3058\n",
      "    138      298.2875      566.0409        0.0010  0.1961\n",
      "    139      \u001b[36m295.2776\u001b[0m      572.0173        0.0005  0.3049\n",
      "    140      \u001b[36m294.0105\u001b[0m      571.3689        0.0001  0.2069\n",
      "    141      313.7882      556.1420        0.0050  0.3076\n",
      "    142      325.1859      545.1210        0.0049  0.1970\n",
      "    143      335.9192      545.9748        0.0045  0.3029\n",
      "    144      344.7108      541.5811        0.0040  0.2075\n",
      "    145      327.7482      \u001b[32m521.7990\u001b[0m     +  0.0033  0.1990\n",
      "    146      304.9688      594.4136        0.0025  0.3015\n",
      "    147      297.3217      567.1408        0.0017  0.2001\n",
      "    148      294.5481      565.2492        0.0010  0.3133\n",
      "    149      \u001b[36m291.7062\u001b[0m      569.7062        0.0005  0.1929\n",
      "    150      \u001b[36m290.5226\u001b[0m      569.0208        0.0001  0.3124\n",
      "    151      309.3146      549.2916        0.0050  0.2088\n",
      "    152      321.0410      542.0840        0.0049  0.2948\n",
      "    153      327.8572      531.9591        0.0045  0.2014\n",
      "    154      337.6499      543.1112        0.0040  0.1980\n",
      "    155      331.0188      \u001b[32m513.7982\u001b[0m     +  0.0033  0.2985\n",
      "    156      304.0820      613.3381        0.0025  0.2021\n",
      "    157      294.5511      579.2691        0.0017  0.3074\n",
      "    158      292.2209      574.4040        0.0010  0.1982\n",
      "    159      \u001b[36m288.7808\u001b[0m      576.7907        0.0005  0.2986\n",
      "    160      \u001b[36m287.6147\u001b[0m      575.3829        0.0001  0.2027\n",
      "    161      305.6375      543.3348        0.0050  0.3052\n",
      "    162      316.2941      541.9261        0.0049  0.2042\n",
      "    163      320.9447      528.3688        0.0045  0.2056\n",
      "    164      329.8107      545.3169        0.0040  0.3072\n",
      "    165      325.9110      \u001b[32m510.4656\u001b[0m     +  0.0033  0.1998\n",
      "    166      303.4120      603.1443        0.0025  0.2915\n",
      "    167      290.5011      566.8535        0.0017  0.1980\n",
      "    168      288.5140      568.4599        0.0010  0.2997\n",
      "    169      \u001b[36m285.5565\u001b[0m      568.0292        0.0005  0.1971\n",
      "    170      \u001b[36m284.4463\u001b[0m      567.3310        0.0001  0.3157\n",
      "    171      301.5444      540.4587        0.0050  0.2250\n",
      "    172      311.2002      545.2639        0.0049  0.2128\n",
      "    173      317.3207      523.2573        0.0045  0.2963\n",
      "    174      324.4102      533.4157        0.0040  0.2071\n",
      "    175      323.7357      \u001b[32m506.9272\u001b[0m     +  0.0033  0.2877\n",
      "    176      302.3137      596.7774        0.0025  0.2016\n",
      "    177      287.5214      561.4542        0.0017  0.3033\n",
      "    178      285.9272      568.5119        0.0010  0.1980\n",
      "    179      \u001b[36m282.5292\u001b[0m      564.1014        0.0005  0.3013\n",
      "    180      \u001b[36m281.4585\u001b[0m      563.0623        0.0001  0.1989\n",
      "    181      297.7406      540.5859        0.0050  0.2024\n",
      "    182      306.6114      542.0106        0.0049  0.3233\n",
      "    183      313.1326      522.4446        0.0045  0.2070\n",
      "    184      317.9036      524.5094        0.0040  0.3085\n",
      "    185      320.8860      \u001b[32m506.7910\u001b[0m     +  0.0033  0.1960\n",
      "    186      303.4749      592.6033        0.0025  0.3034\n",
      "    187      285.8264      570.7588        0.0017  0.2217\n",
      "    188      284.0052      573.5275        0.0010  0.3005\n",
      "    189      \u001b[36m279.8274\u001b[0m      563.0684        0.0005  0.1991\n",
      "    190      \u001b[36m278.6672\u001b[0m      562.4929        0.0001  0.2051\n",
      "    191      294.4967      536.3026        0.0050  0.3305\n",
      "    192      303.9839      539.3881        0.0049  0.2598\n",
      "    193      310.0509      522.8967        0.0045  0.2980\n",
      "    194      313.1244      519.0340        0.0040  0.1978\n",
      "    195      317.8203      509.8471        0.0033  0.2947\n",
      "    196      302.7914      572.8843        0.0025  0.2159\n",
      "    197      285.1505      592.1306        0.0017  0.3056\n",
      "    198      282.3356      591.6742        0.0010  0.2109\n",
      "    199      \u001b[36m277.8053\u001b[0m      571.4975        0.0005  0.1972\n",
      "    200      \u001b[36m276.4394\u001b[0m      570.6762        0.0001  0.3105\n",
      "    201      290.5522      530.2980        0.0050  0.1964\n",
      "    202      301.8542      534.1897        0.0049  0.3059\n",
      "    203      306.2860      530.6202        0.0045  0.2013\n",
      "    204      311.0602      522.8087        0.0040  0.2987\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m897.7340\u001b[0m     \u001b[32m1017.3497\u001b[0m     +  0.0050  0.6338\n",
      "      2      906.8047     1197.6430        0.0049  0.3970\n",
      "      3      \u001b[36m664.0629\u001b[0m      \u001b[32m966.7148\u001b[0m     +  0.0045  0.5445\n",
      "      4      694.6450      987.0082        0.0040  0.2122\n",
      "      5      \u001b[36m617.3722\u001b[0m      \u001b[32m953.1357\u001b[0m     +  0.0033  0.2263\n",
      "      6      \u001b[36m590.4020\u001b[0m      \u001b[32m921.3331\u001b[0m     +  0.0025  0.3062\n",
      "      7      \u001b[36m555.1836\u001b[0m      \u001b[32m897.7021\u001b[0m     +  0.0017  0.1916\n",
      "      8      \u001b[36m529.7438\u001b[0m      \u001b[32m875.5931\u001b[0m     +  0.0010  0.2996\n",
      "      9      \u001b[36m514.0899\u001b[0m      \u001b[32m865.6766\u001b[0m     +  0.0005  0.2015\n",
      "     10      \u001b[36m506.2761\u001b[0m      \u001b[32m862.7260\u001b[0m     +  0.0001  0.3008\n",
      "     11      597.4417      \u001b[32m756.7818\u001b[0m     +  0.0050  0.1970\n",
      "     12      730.1427     1105.6180        0.0049  0.1965\n",
      "     13      548.1918      833.2970        0.0045  0.3142\n",
      "     14      \u001b[36m497.1799\u001b[0m      835.0263        0.0040  0.2050\n",
      "     15      \u001b[36m486.0161\u001b[0m      817.6984        0.0033  0.2882\n",
      "     16      \u001b[36m458.0050\u001b[0m      797.2724        0.0025  0.2108\n",
      "     17      \u001b[36m447.9844\u001b[0m      784.2277        0.0017  0.4443\n",
      "     18      \u001b[36m437.6449\u001b[0m      777.6559        0.0010  0.2212\n",
      "     19      \u001b[36m432.1351\u001b[0m      774.4953        0.0005  0.2059\n",
      "     20      \u001b[36m429.2734\u001b[0m      773.6951        0.0001  0.2976\n",
      "     21      476.4015      769.4555        0.0050  0.2017\n",
      "     22      535.1648      826.4935        0.0049  0.3051\n",
      "     23      502.4692      799.8583        0.0045  0.2009\n",
      "     24      445.2550      \u001b[32m746.3613\u001b[0m     +  0.0040  0.2943\n",
      "     25      431.7603      \u001b[32m742.7896\u001b[0m     +  0.0033  0.1923\n",
      "     26      \u001b[36m421.5985\u001b[0m      \u001b[32m731.2267\u001b[0m     +  0.0025  0.2938\n",
      "     27      \u001b[36m410.6129\u001b[0m      \u001b[32m724.4895\u001b[0m     +  0.0017  0.2107\n",
      "     28      \u001b[36m404.5440\u001b[0m      \u001b[32m721.7959\u001b[0m     +  0.0010  0.1974\n",
      "     29      \u001b[36m400.3381\u001b[0m      \u001b[32m720.8904\u001b[0m     +  0.0005  0.3129\n",
      "     30      \u001b[36m398.1166\u001b[0m      \u001b[32m720.7147\u001b[0m     +  0.0001  0.2010\n",
      "     31      432.9586      729.0330        0.0050  0.2946\n",
      "     32      480.2714      772.7541        0.0049  0.2021\n",
      "     33      473.8147      760.6475        0.0045  0.3025\n",
      "     34      427.7382      \u001b[32m710.5590\u001b[0m     +  0.0040  0.2005\n",
      "     35      405.0243      \u001b[32m706.1857\u001b[0m     +  0.0033  0.1988\n",
      "     36      400.2167      \u001b[32m699.7139\u001b[0m     +  0.0025  0.2958\n",
      "     37      \u001b[36m389.4499\u001b[0m      \u001b[32m694.6602\u001b[0m     +  0.0017  0.2047\n",
      "     38      \u001b[36m384.8140\u001b[0m      \u001b[32m694.2579\u001b[0m     +  0.0010  0.3004\n",
      "     39      \u001b[36m380.9442\u001b[0m      \u001b[32m694.2533\u001b[0m     +  0.0005  0.2178\n",
      "     40      \u001b[36m379.0269\u001b[0m      694.3934        0.0001  0.2968\n",
      "     41      409.0428      711.7843        0.0050  0.2111\n",
      "     42      453.4733      749.6558        0.0049  0.1990\n",
      "     43      457.8544      735.2883        0.0045  0.3210\n",
      "     44      413.4289      \u001b[32m681.9834\u001b[0m     +  0.0040  0.2263\n",
      "     45      388.7762      683.4570        0.0033  0.4711\n",
      "     46      386.2197      \u001b[32m678.8081\u001b[0m     +  0.0025  0.4067\n",
      "     47      \u001b[36m375.6164\u001b[0m      \u001b[32m674.3111\u001b[0m     +  0.0017  0.3025\n",
      "     48      \u001b[36m371.7881\u001b[0m      676.5652        0.0010  0.1986\n",
      "     49      \u001b[36m368.1801\u001b[0m      677.0049        0.0005  0.3087\n",
      "     50      \u001b[36m366.4841\u001b[0m      677.2707        0.0001  0.2066\n",
      "     51      393.6967      699.6136        0.0050  0.2003\n",
      "     52      434.7069      731.3419        0.0049  0.3176\n",
      "     53      441.1427      709.3850        0.0045  0.2062\n",
      "     54      399.9943      \u001b[32m663.4811\u001b[0m     +  0.0040  0.2952\n",
      "     55      377.8667      \u001b[32m662.6908\u001b[0m     +  0.0033  0.2235\n",
      "     56      376.2903      \u001b[32m659.7736\u001b[0m     +  0.0025  0.3940\n",
      "     57      \u001b[36m365.6631\u001b[0m      \u001b[32m657.6433\u001b[0m     +  0.0017  0.3006\n",
      "     58      \u001b[36m362.2840\u001b[0m      661.9710        0.0010  0.3647\n",
      "     59      \u001b[36m358.8583\u001b[0m      662.9340        0.0005  0.3849\n",
      "     60      \u001b[36m357.3163\u001b[0m      663.4052        0.0001  0.2769\n",
      "     61      382.4285      685.3273        0.0050  0.3946\n",
      "     62      422.3503      718.1755        0.0049  0.2655\n",
      "     63      432.5342      692.7627        0.0045  0.4779\n",
      "     64      392.6697      \u001b[32m648.5136\u001b[0m     +  0.0040  0.4248\n",
      "     65      369.1464      649.9599        0.0033  0.3640\n",
      "     66      368.6368      \u001b[32m645.9471\u001b[0m     +  0.0025  0.1996\n",
      "     67      358.3362      647.7619        0.0017  0.2963\n",
      "     68      \u001b[36m355.2836\u001b[0m      654.6577        0.0010  0.2083\n",
      "     69      \u001b[36m351.9437\u001b[0m      655.4274        0.0005  0.2052\n",
      "     70      \u001b[36m350.5264\u001b[0m      655.9977        0.0001  0.2999\n",
      "     71      374.5660      672.7301        0.0050  0.1987\n",
      "     72      411.7390      700.2772        0.0049  0.2953\n",
      "     73      423.3394      675.6028        0.0045  0.1953\n",
      "     74      388.0599      \u001b[32m635.4989\u001b[0m     +  0.0040  0.3057\n",
      "     75      362.0973      637.3162        0.0033  0.2052\n",
      "     76      362.6418      636.2342        0.0025  0.2978\n",
      "     77      352.6808      641.0780        0.0017  0.2170\n",
      "     78      \u001b[36m349.5640\u001b[0m      648.6272        0.0010  0.2066\n",
      "     79      \u001b[36m346.2986\u001b[0m      649.3282        0.0005  0.3085\n",
      "     80      \u001b[36m344.9552\u001b[0m      650.1418        0.0001  0.1920\n",
      "     81      368.4070      659.0942        0.0050  0.2994\n",
      "     82      402.5792      667.7226        0.0049  0.2047\n",
      "     83      415.5424      683.3437        0.0045  0.3099\n",
      "     84      386.8955      \u001b[32m613.9378\u001b[0m     +  0.0040  0.2044\n",
      "     85      358.4356      632.7381        0.0033  0.3066\n",
      "     86      354.2375      626.9693        0.0025  0.2159\n",
      "     87      347.7764      636.1883        0.0017  0.2031\n",
      "     88      \u001b[36m343.9601\u001b[0m      643.1957        0.0010  0.2955\n",
      "     89      \u001b[36m341.2379\u001b[0m      644.6855        0.0005  0.1951\n",
      "     90      \u001b[36m339.9520\u001b[0m      645.5374        0.0001  0.2995\n",
      "     91      363.0842      644.7936        0.0050  0.2123\n",
      "     92      393.0994      665.4081        0.0049  0.3023\n",
      "     93      408.0118      639.5904        0.0045  0.1982\n",
      "     94      379.7480      614.7365        0.0040  0.2964\n",
      "     95      351.0766      625.2728        0.0033  0.2007\n",
      "     96      349.2856      626.9795        0.0025  0.1987\n",
      "     97      342.8313      630.5348        0.0017  0.2988\n",
      "     98      \u001b[36m338.8198\u001b[0m      637.6978        0.0010  0.2081\n",
      "     99      \u001b[36m335.9963\u001b[0m      638.5137        0.0005  0.3165\n",
      "    100      \u001b[36m334.7109\u001b[0m      639.1821        0.0001  0.2003\n",
      "    101      360.5874      626.6761        0.0050  0.2969\n",
      "    102      386.2214      653.9018        0.0049  0.2003\n",
      "    103      404.7913      641.2959        0.0045  0.3073\n",
      "    104      386.2162      \u001b[32m607.2582\u001b[0m     +  0.0040  0.2036\n",
      "    105      349.1387      633.1577        0.0033  0.2135\n",
      "    106      344.9154      631.7759        0.0025  0.3127\n",
      "    107      340.6891      639.6808        0.0017  0.2092\n",
      "    108      335.4563      641.6079        0.0010  0.3223\n",
      "    109      \u001b[36m332.9317\u001b[0m      642.5651        0.0005  0.2027\n",
      "    110      \u001b[36m331.7072\u001b[0m      643.4352        0.0001  0.2964\n",
      "    111      352.9344      625.4887        0.0050  0.2020\n",
      "    112      377.1674      625.4846        0.0049  0.3020\n",
      "    113      389.0423      \u001b[32m598.5136\u001b[0m     +  0.0045  0.2008\n",
      "    114      370.0887      \u001b[32m592.9301\u001b[0m     +  0.0040  0.1955\n",
      "    115      344.2967      604.3058        0.0033  0.3063\n",
      "    116      336.6428      599.3908        0.0025  0.1999\n",
      "    117      332.1096      604.4940        0.0017  0.3184\n",
      "    118      \u001b[36m326.0609\u001b[0m      602.9879        0.0010  0.2048\n",
      "    119      \u001b[36m323.1685\u001b[0m      606.6421        0.0005  0.3142\n",
      "    120      \u001b[36m321.5019\u001b[0m      607.5527        0.0001  0.2098\n",
      "    121      346.3192      601.0902        0.0050  0.2986\n",
      "    122      368.3325      604.4597        0.0049  0.2096\n",
      "    123      383.5405      598.1211        0.0045  0.2025\n",
      "    124      369.2891      \u001b[32m549.0234\u001b[0m     +  0.0040  0.3053\n",
      "    125      338.5404      594.9169        0.0033  0.2054\n",
      "    126      327.1013      572.2117        0.0025  0.2988\n",
      "    127      322.5110      588.6447        0.0017  0.2165\n",
      "    128      \u001b[36m316.5003\u001b[0m      586.9979        0.0010  0.3157\n",
      "    129      \u001b[36m314.0500\u001b[0m      590.5326        0.0005  0.1991\n",
      "    130      \u001b[36m312.5453\u001b[0m      590.9007        0.0001  0.2942\n",
      "    131      336.5019      587.7704        0.0050  0.2066\n",
      "    132      357.4597      587.1702        0.0049  0.1966\n",
      "    133      372.7513      580.8338        0.0045  0.3100\n",
      "    134      364.8108      \u001b[32m541.4489\u001b[0m     +  0.0040  0.2022\n",
      "    135      332.8251      576.1810        0.0033  0.3005\n",
      "    136      318.8691      574.9971        0.0025  0.2168\n",
      "    137      314.3917      580.1664        0.0017  0.2952\n",
      "    138      \u001b[36m309.2426\u001b[0m      577.6402        0.0010  0.1933\n",
      "    139      \u001b[36m306.8134\u001b[0m      582.4536        0.0005  0.3260\n",
      "    140      \u001b[36m305.4079\u001b[0m      582.5087        0.0001  0.2268\n",
      "    141      327.3701      577.9257        0.0050  0.1999\n",
      "    142      344.5250      569.7818        0.0049  0.3095\n",
      "    143      359.1192      573.0146        0.0045  0.2074\n",
      "    144      362.3476      \u001b[32m540.5716\u001b[0m     +  0.0040  0.3113\n",
      "    145      333.6413      561.3757        0.0033  0.2032\n",
      "    146      312.0556      591.0826        0.0025  0.3209\n",
      "    147      307.3006      577.9960        0.0017  0.2104\n",
      "    148      \u001b[36m304.0185\u001b[0m      574.1518        0.0010  0.2918\n",
      "    149      \u001b[36m301.0799\u001b[0m      580.1162        0.0005  0.2081\n",
      "    150      \u001b[36m299.7252\u001b[0m      579.5196        0.0001  0.1977\n",
      "    151      319.8749      570.7702        0.0050  0.3077\n",
      "    152      335.2775      558.9897        0.0049  0.1977\n",
      "    153      348.2826      557.4354        0.0045  0.3110\n",
      "    154      351.1819      \u001b[32m533.6755\u001b[0m     +  0.0040  0.2013\n",
      "    155      329.5201      548.7466        0.0033  0.3114\n",
      "    156      310.1089      602.4073        0.0025  0.2010\n",
      "    157      300.7108      580.9890        0.0017  0.2927\n",
      "    158      \u001b[36m298.8396\u001b[0m      580.3607        0.0010  0.2020\n",
      "    159      \u001b[36m295.8003\u001b[0m      580.9024        0.0005  0.2365\n",
      "    160      \u001b[36m294.6015\u001b[0m      579.9050        0.0001  0.3082\n",
      "    161      314.1104      562.1555        0.0050  0.2004\n",
      "    162      327.7433      550.3069        0.0049  0.3060\n",
      "    163      337.0656      546.0840        0.0045  0.2252\n",
      "    164      345.2049      \u001b[32m532.1894\u001b[0m     +  0.0040  0.3000\n",
      "    165      327.1068      533.6950        0.0033  0.2053\n",
      "    166      309.7496      611.7618        0.0025  0.2975\n",
      "    167      296.0218      582.1313        0.0017  0.2043\n",
      "    168      294.7114      583.0655        0.0010  0.2065\n",
      "    169      \u001b[36m291.5107\u001b[0m      578.7729        0.0005  0.3020\n",
      "    170      \u001b[36m290.3539\u001b[0m      577.8434        0.0001  0.2103\n",
      "    171      308.1389      560.8021        0.0050  0.3049\n",
      "    172      321.4280      546.5962        0.0049  0.1972\n",
      "    173      328.4784      544.9336        0.0045  0.3118\n",
      "    174      338.3148      \u001b[32m529.8985\u001b[0m     +  0.0040  0.2039\n",
      "    175      324.5688      \u001b[32m525.4989\u001b[0m     +  0.0033  0.3021\n",
      "    176      309.2028      612.7030        0.0025  0.2140\n",
      "    177      292.4522      578.6785        0.0017  0.2049\n",
      "    178      291.5776      581.4279        0.0010  0.2940\n",
      "    179      \u001b[36m287.9058\u001b[0m      575.7338        0.0005  0.2639\n",
      "    180      \u001b[36m286.7546\u001b[0m      574.6597        0.0001  0.5305\n",
      "    181      303.4222      558.3775        0.0050  0.2752\n",
      "    182      315.4610      548.4909        0.0049  0.3055\n",
      "    183      320.6005      537.1344        0.0045  0.2036\n",
      "    184      331.0519      535.8360        0.0040  0.3021\n",
      "    185      328.4265      \u001b[32m518.5532\u001b[0m     +  0.0033  0.2003\n",
      "    186      308.7651      629.5503        0.0025  0.2125\n",
      "    187      289.9016      582.1402        0.0017  0.3012\n",
      "    188      289.4057      583.5105        0.0010  0.2066\n",
      "    189      \u001b[36m284.5483\u001b[0m      575.4278        0.0005  0.2992\n",
      "    190      \u001b[36m283.3970\u001b[0m      573.7436        0.0001  0.2099\n",
      "    191      298.5959      557.1348        0.0050  0.2951\n",
      "    192      308.2229      549.3029        0.0049  0.1998\n",
      "    193      313.1897      538.2773        0.0045  0.3063\n",
      "    194      319.9427      539.8423        0.0040  0.2099\n",
      "    195      323.7613      \u001b[32m514.9945\u001b[0m     +  0.0033  0.2069\n",
      "    196      304.0613      620.5519        0.0025  0.3021\n",
      "    197      285.6565      581.3526        0.0017  0.2063\n",
      "    198      284.8561      580.9067        0.0010  0.3942\n",
      "    199      \u001b[36m281.0547\u001b[0m      570.7315        0.0005  0.2045\n",
      "    200      \u001b[36m279.9196\u001b[0m      569.7818        0.0001  0.2925\n",
      "    201      293.6878      555.8686        0.0050  0.2014\n",
      "    202      303.0563      545.5835        0.0049  0.2942\n",
      "    203      309.3026      538.5122        0.0045  0.2010\n",
      "    204      315.0654      537.8611        0.0040  0.2019\n",
      "    205      320.6283      \u001b[32m513.1921\u001b[0m     +  0.0033  0.2944\n",
      "    206      301.2345      620.9549        0.0025  0.2057\n",
      "    207      282.6293      581.5852        0.0017  0.3124\n",
      "    208      281.5790      579.8749        0.0010  0.2073\n",
      "    209      \u001b[36m278.1291\u001b[0m      568.3519        0.0005  0.3037\n",
      "    210      \u001b[36m276.9905\u001b[0m      568.0085        0.0001  0.2050\n",
      "    211      289.8761      554.1549        0.0050  0.2993\n",
      "    212      298.8461      544.4426        0.0049  0.2016\n",
      "    213      305.9809      533.4044        0.0045  0.1984\n",
      "    214      308.2479      547.3845        0.0040  0.2977\n",
      "    215      317.4068      \u001b[32m508.0552\u001b[0m     +  0.0033  0.1977\n",
      "    216      301.3836      616.2014        0.0025  0.3053\n",
      "    217      280.9496      580.0353        0.0017  0.2117\n",
      "    218      278.2978      579.9051        0.0010  0.3204\n",
      "    219      \u001b[36m275.6619\u001b[0m      564.8042        0.0005  0.1976\n",
      "    220      \u001b[36m274.2675\u001b[0m      565.9557        0.0001  0.3037\n",
      "    221      285.4968      560.0895        0.0050  0.2018\n",
      "    222      295.6656      544.7914        0.0049  0.2070\n",
      "    223      302.3984      532.3878        0.0045  0.3144\n",
      "    224      303.4558      539.5037        0.0040  0.2276\n",
      "    225      313.6659      509.8737        0.0033  0.3049\n",
      "    226      298.5744      606.1105        0.0025  0.2004\n",
      "    227      280.8547      586.5399        0.0017  0.2986\n",
      "    228      275.7321      588.9237        0.0010  0.1973\n",
      "    229      \u001b[36m273.7772\u001b[0m      569.0343        0.0005  0.3141\n",
      "    230      \u001b[36m271.9819\u001b[0m      571.1423        0.0001  0.2067\n",
      "    231      281.1729      565.8949        0.0050  0.2081\n",
      "    232      294.6858      546.4767        0.0049  0.2999\n",
      "    233      301.8703      528.5390        0.0045  0.2047\n",
      "    234      301.7691      543.5430        0.0040  0.2932\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m927.2263\u001b[0m     \u001b[32m1024.6738\u001b[0m     +  0.0050  0.5867\n",
      "      2      \u001b[36m885.6539\u001b[0m     1213.0340        0.0049  0.3066\n",
      "      3      \u001b[36m673.0588\u001b[0m      \u001b[32m952.7693\u001b[0m     +  0.0045  0.3249\n",
      "      4      688.4205     1010.1187        0.0040  0.1918\n",
      "      5      \u001b[36m606.9441\u001b[0m      \u001b[32m944.9584\u001b[0m     +  0.0033  0.3143\n",
      "      6      \u001b[36m571.1404\u001b[0m      \u001b[32m916.3672\u001b[0m     +  0.0025  0.1976\n",
      "      7      \u001b[36m534.8844\u001b[0m      \u001b[32m885.3675\u001b[0m     +  0.0017  0.2935\n",
      "      8      \u001b[36m512.2698\u001b[0m      \u001b[32m870.1195\u001b[0m     +  0.0010  0.2009\n",
      "      9      \u001b[36m498.2070\u001b[0m      \u001b[32m862.3875\u001b[0m     +  0.0005  0.1956\n",
      "     10      \u001b[36m491.7000\u001b[0m      \u001b[32m860.0639\u001b[0m     +  0.0001  0.3065\n",
      "     11      576.8789      \u001b[32m818.8260\u001b[0m     +  0.0050  0.2000\n",
      "     12      681.8107      987.0896        0.0049  0.3046\n",
      "     13      551.9641      842.7868        0.0045  0.1995\n",
      "     14      \u001b[36m474.9851\u001b[0m      \u001b[32m800.5572\u001b[0m     +  0.0040  0.2976\n",
      "     15      477.2429      \u001b[32m797.0714\u001b[0m     +  0.0033  0.1898\n",
      "     16      \u001b[36m451.1267\u001b[0m      \u001b[32m775.4981\u001b[0m     +  0.0025  0.1946\n",
      "     17      \u001b[36m442.4711\u001b[0m      \u001b[32m766.2781\u001b[0m     +  0.0017  0.3034\n",
      "     18      \u001b[36m433.1832\u001b[0m      \u001b[32m760.8631\u001b[0m     +  0.0010  0.1954\n",
      "     19      \u001b[36m428.5047\u001b[0m      \u001b[32m758.3641\u001b[0m     +  0.0005  0.3004\n",
      "     20      \u001b[36m425.9034\u001b[0m      \u001b[32m757.7474\u001b[0m     +  0.0001  0.1933\n",
      "     21      468.6909      760.3625        0.0050  0.3018\n",
      "     22      522.6652      817.1988        0.0049  0.1943\n",
      "     23      498.7130      782.2713        0.0045  0.2931\n",
      "     24      444.1287      \u001b[32m739.4029\u001b[0m     +  0.0040  0.2006\n",
      "     25      430.5332      \u001b[32m734.9310\u001b[0m     +  0.0033  0.2014\n",
      "     26      \u001b[36m421.3925\u001b[0m      \u001b[32m725.9596\u001b[0m     +  0.0025  0.3056\n",
      "     27      \u001b[36m410.8896\u001b[0m      \u001b[32m721.1366\u001b[0m     +  0.0017  0.1913\n",
      "     28      \u001b[36m405.2166\u001b[0m      \u001b[32m719.1159\u001b[0m     +  0.0010  0.2925\n",
      "     29      \u001b[36m401.2150\u001b[0m      \u001b[32m718.3710\u001b[0m     +  0.0005  0.1975\n",
      "     30      \u001b[36m399.0989\u001b[0m      \u001b[32m718.2415\u001b[0m     +  0.0001  0.2887\n",
      "     31      431.8101      730.3892        0.0050  0.1976\n",
      "     32      479.5889      763.7791        0.0049  0.1982\n",
      "     33      474.0534      746.1058        0.0045  0.2839\n",
      "     34      426.3225      \u001b[32m707.2906\u001b[0m     +  0.0040  0.1936\n",
      "     35      406.4806      \u001b[32m702.0915\u001b[0m     +  0.0033  0.2946\n",
      "     36      402.0626      \u001b[32m699.3211\u001b[0m     +  0.0025  0.2469\n",
      "     37      \u001b[36m391.5346\u001b[0m      \u001b[32m696.6586\u001b[0m     +  0.0017  0.3604\n",
      "     38      \u001b[36m387.1512\u001b[0m      697.2933        0.0010  0.1956\n",
      "     39      \u001b[36m383.4358\u001b[0m      697.6385        0.0005  0.1944\n",
      "     40      \u001b[36m381.5777\u001b[0m      697.8850        0.0001  0.2900\n",
      "     41      409.7818      707.4339        0.0050  0.1951\n",
      "     42      453.3063      741.1185        0.0049  0.2994\n",
      "     43      458.5595      725.2662        0.0045  0.2340\n",
      "     44      413.1086      \u001b[32m683.9044\u001b[0m     +  0.0040  0.2989\n",
      "     45      391.6751      685.6346        0.0033  0.1942\n",
      "     46      389.1357      684.1844        0.0025  0.2985\n",
      "     47      \u001b[36m378.5687\u001b[0m      \u001b[32m682.4055\u001b[0m     +  0.0017  0.2081\n",
      "     48      \u001b[36m374.8093\u001b[0m      685.1200        0.0010  0.2008\n",
      "     49      \u001b[36m371.1915\u001b[0m      685.9001        0.0005  0.2987\n",
      "     50      \u001b[36m369.4915\u001b[0m      686.3856        0.0001  0.2075\n",
      "     51      395.6985      691.6755        0.0050  0.2998\n",
      "     52      437.3054      722.3437        0.0049  0.2058\n",
      "     53      448.0566      704.6344        0.0045  0.2969\n",
      "     54      404.1417      \u001b[32m667.5989\u001b[0m     +  0.0040  0.2045\n",
      "     55      381.2269      670.4710        0.0033  0.2984\n",
      "     56      379.5224      \u001b[32m666.3856\u001b[0m     +  0.0025  0.1973\n",
      "     57      \u001b[36m369.4335\u001b[0m      669.5911        0.0017  0.2004\n",
      "     58      \u001b[36m365.3708\u001b[0m      669.5726        0.0010  0.3021\n",
      "     59      \u001b[36m361.8648\u001b[0m      669.4839        0.0005  0.2030\n",
      "     60      \u001b[36m360.1568\u001b[0m      669.9669        0.0001  0.2974\n",
      "     61      386.8893      680.5201        0.0050  0.1924\n",
      "     62      429.3722      687.0246        0.0049  0.3100\n",
      "     63      442.2216      727.9098        0.0045  0.2433\n",
      "     64      462.4166      678.2942        0.0040  0.3122\n",
      "     65      388.6251      671.4785        0.0033  0.1968\n",
      "     66      383.2928      668.4543        0.0025  0.2047\n",
      "     67      366.4048      673.9267        0.0017  0.2945\n",
      "     68      363.9702      678.8864        0.0010  0.2003\n",
      "     69      \u001b[36m359.3058\u001b[0m      675.3471        0.0005  0.3169\n",
      "     70      \u001b[36m357.9101\u001b[0m      675.5888        0.0001  0.1971\n",
      "     71      378.5809      \u001b[32m664.0756\u001b[0m     +  0.0050  0.3029\n",
      "     72      410.7968      679.9042        0.0049  0.2006\n",
      "     73      419.3891      \u001b[32m661.0827\u001b[0m     +  0.0045  0.2961\n",
      "     74      383.1116      \u001b[32m650.9632\u001b[0m     +  0.0040  0.2019\n",
      "     75      367.2264      651.4970        0.0033  0.2026\n",
      "     76      366.9018      652.7487        0.0025  0.2935\n",
      "     77      \u001b[36m356.7558\u001b[0m      653.7316        0.0017  0.1986\n",
      "     78      \u001b[36m353.5877\u001b[0m      658.5511        0.0010  0.2967\n",
      "     79      \u001b[36m350.2790\u001b[0m      657.1450        0.0005  0.2007\n",
      "     80      \u001b[36m348.7785\u001b[0m      657.0946        0.0001  0.2922\n",
      "     81      375.0175      653.0118        0.0050  0.2133\n",
      "     82      406.1390      \u001b[32m649.3611\u001b[0m     +  0.0049  0.3007\n",
      "     83      410.4612      664.0586        0.0045  0.2204\n",
      "     84      400.6344      \u001b[32m644.0904\u001b[0m     +  0.0040  0.2117\n",
      "     85      361.5963      653.4755        0.0033  0.2882\n",
      "     86      359.8703      648.8840        0.0025  0.2003\n",
      "     87      353.3243      657.3600        0.0017  0.2999\n",
      "     88      348.8986      661.8372        0.0010  0.2076\n",
      "     89      \u001b[36m345.8133\u001b[0m      662.8346        0.0005  0.2980\n",
      "     90      \u001b[36m344.4463\u001b[0m      663.8095        0.0001  0.1982\n",
      "     91      367.2349      647.9267        0.0050  0.2988\n",
      "     92      397.1106      660.3110        0.0049  0.1996\n",
      "     93      413.1944      646.0585        0.0045  0.1988\n",
      "     94      381.2453      \u001b[32m630.6644\u001b[0m     +  0.0040  0.3007\n",
      "     95      354.4112      639.9631        0.0033  0.2030\n",
      "     96      353.5393      632.1978        0.0025  0.3054\n",
      "     97      345.9688      641.5921        0.0017  0.1987\n",
      "     98      \u001b[36m341.2188\u001b[0m      644.6464        0.0010  0.2975\n",
      "     99      \u001b[36m337.7942\u001b[0m      645.4230        0.0005  0.2017\n",
      "    100      \u001b[36m336.2153\u001b[0m      646.3431        0.0001  0.3451\n",
      "    101      361.9246      \u001b[32m621.9348\u001b[0m     +  0.0050  0.2009\n",
      "    102      389.1891      640.6600        0.0049  0.2040\n",
      "    103      409.4450      644.1501        0.0045  0.3152\n",
      "    104      384.7947      626.6073        0.0040  0.2156\n",
      "    105      348.8853      \u001b[32m607.1242\u001b[0m     +  0.0033  0.3076\n",
      "    106      345.7930      \u001b[32m600.5266\u001b[0m     +  0.0025  0.1982\n",
      "    107      338.2237      613.6878        0.0017  0.3003\n",
      "    108      \u001b[36m330.7897\u001b[0m      609.8806        0.0010  0.2059\n",
      "    109      \u001b[36m327.9949\u001b[0m      612.0447        0.0005  0.2913\n",
      "    110      \u001b[36m326.3606\u001b[0m      613.4653        0.0001  0.1949\n",
      "    111      353.7789      605.1893        0.0050  0.1979\n",
      "    112      382.5111      626.4403        0.0049  0.3079\n",
      "    113      401.1232      616.1451        0.0045  0.1921\n",
      "    114      375.0569      \u001b[32m561.2361\u001b[0m     +  0.0040  0.2946\n",
      "    115      344.7057      609.5525        0.0033  0.1985\n",
      "    116      332.7446      582.1499        0.0025  0.2906\n",
      "    117      328.7842      601.4736        0.0017  0.2051\n",
      "    118      \u001b[36m322.2532\u001b[0m      602.6301        0.0010  0.2909\n",
      "    119      \u001b[36m319.5889\u001b[0m      606.5762        0.0005  0.2002\n",
      "    120      \u001b[36m317.9562\u001b[0m      607.2138        0.0001  0.1997\n",
      "    121      344.4797      595.2193        0.0050  0.2915\n",
      "    122      369.4620      606.3703        0.0049  0.2015\n",
      "    123      390.3585      599.9924        0.0045  0.2958\n",
      "    124      370.9219      \u001b[32m549.2381\u001b[0m     +  0.0040  0.2127\n",
      "    125      340.6439      597.9044        0.0033  0.3350\n",
      "    126      323.2367      576.3749        0.0025  0.2036\n",
      "    127      321.3682      591.8170        0.0017  0.3090\n",
      "    128      \u001b[36m314.9358\u001b[0m      592.0072        0.0010  0.1995\n",
      "    129      \u001b[36m312.2515\u001b[0m      597.7024        0.0005  0.1983\n",
      "    130      \u001b[36m310.6228\u001b[0m      597.6341        0.0001  0.2965\n",
      "    131      337.4764      587.5710        0.0050  0.2059\n",
      "    132      356.2659      590.5036        0.0049  0.2915\n",
      "    133      377.9916      586.7671        0.0045  0.1988\n",
      "    134      368.8552      \u001b[32m545.4306\u001b[0m     +  0.0040  0.2962\n",
      "    135      337.1760      585.5621        0.0033  0.2014\n",
      "    136      315.9381      584.0401        0.0025  0.2960\n",
      "    137      313.5386      583.8415        0.0017  0.2023\n",
      "    138      \u001b[36m308.6233\u001b[0m      586.4844        0.0010  0.1953\n",
      "    139      \u001b[36m305.3892\u001b[0m      592.3454        0.0005  0.3029\n",
      "    140      \u001b[36m303.8915\u001b[0m      591.6006        0.0001  0.2015\n",
      "    141      330.1170      579.2624        0.0050  0.2983\n",
      "    142      345.2112      575.9194        0.0049  0.2021\n",
      "    143      365.7292      576.8460        0.0045  0.2965\n",
      "    144      367.0687      546.4262        0.0040  0.2143\n",
      "    145      337.5334      571.5008        0.0033  0.3266\n",
      "    146      311.5817      615.5100        0.0025  0.2020\n",
      "    147      307.2272      588.3833        0.0017  0.2039\n",
      "    148      \u001b[36m303.3480\u001b[0m      591.4343        0.0010  0.3225\n",
      "    149      \u001b[36m299.6078\u001b[0m      594.8628        0.0005  0.1998\n",
      "    150      \u001b[36m298.2620\u001b[0m      593.3307        0.0001  0.2966\n",
      "    151      322.3199      575.9379        0.0050  0.2080\n",
      "    152      335.8190      567.4039        0.0049  0.2929\n",
      "    153      354.7403      564.0707        0.0045  0.1999\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m911.5285\u001b[0m     \u001b[32m1075.4444\u001b[0m     +  0.0050  0.3190\n",
      "      2      \u001b[36m862.8629\u001b[0m     1180.0614        0.0049  0.2956\n",
      "      3      \u001b[36m648.9725\u001b[0m      \u001b[32m937.1926\u001b[0m     +  0.0045  0.1915\n",
      "      4      677.6369     1017.5888        0.0040  0.2960\n",
      "      5      \u001b[36m592.9490\u001b[0m      \u001b[32m918.7405\u001b[0m     +  0.0033  0.1980\n",
      "      6      \u001b[36m568.9356\u001b[0m      \u001b[32m899.3245\u001b[0m     +  0.0025  0.2030\n",
      "      7      \u001b[36m530.9402\u001b[0m      \u001b[32m867.1392\u001b[0m     +  0.0017  0.2957\n",
      "      8      \u001b[36m510.0494\u001b[0m      \u001b[32m847.0245\u001b[0m     +  0.0010  0.1980\n",
      "      9      \u001b[36m495.6771\u001b[0m      \u001b[32m837.9359\u001b[0m     +  0.0005  0.2981\n",
      "     10      \u001b[36m488.6531\u001b[0m      \u001b[32m835.2774\u001b[0m     +  0.0001  0.2100\n",
      "     11      570.3041      \u001b[32m785.1151\u001b[0m     +  0.0050  0.2089\n",
      "     12      674.5919      971.4968        0.0049  0.2939\n",
      "     13      550.3375      878.0485        0.0045  0.2022\n",
      "     14      \u001b[36m478.9748\u001b[0m      \u001b[32m774.0782\u001b[0m     +  0.0040  0.2948\n",
      "     15      \u001b[36m470.7771\u001b[0m      \u001b[32m769.0294\u001b[0m     +  0.0033  0.2021\n",
      "     16      \u001b[36m449.1843\u001b[0m      \u001b[32m752.6947\u001b[0m     +  0.0025  0.3146\n",
      "     17      \u001b[36m439.0236\u001b[0m      \u001b[32m742.7543\u001b[0m     +  0.0017  0.2047\n",
      "     18      \u001b[36m430.2184\u001b[0m      \u001b[32m736.1451\u001b[0m     +  0.0010  0.3118\n",
      "     19      \u001b[36m425.5305\u001b[0m      \u001b[32m733.3663\u001b[0m     +  0.0005  0.2027\n",
      "     20      \u001b[36m422.9368\u001b[0m      \u001b[32m732.7176\u001b[0m     +  0.0001  0.1931\n",
      "     21      461.5646      749.8207        0.0050  0.3050\n",
      "     22      512.2056      815.1732        0.0049  0.1976\n",
      "     23      497.8754      772.0038        0.0045  0.3006\n",
      "     24      445.5038      \u001b[32m719.1500\u001b[0m     +  0.0040  0.1968\n",
      "     25      427.3382      \u001b[32m718.6543\u001b[0m     +  0.0033  0.2951\n",
      "     26      \u001b[36m420.0053\u001b[0m      \u001b[32m708.6653\u001b[0m     +  0.0025  0.2005\n",
      "     27      \u001b[36m408.7238\u001b[0m      \u001b[32m702.1148\u001b[0m     +  0.0017  0.2000\n",
      "     28      \u001b[36m403.3719\u001b[0m      \u001b[32m700.5797\u001b[0m     +  0.0010  0.2979\n",
      "     29      \u001b[36m399.2245\u001b[0m      \u001b[32m700.2641\u001b[0m     +  0.0005  0.2004\n",
      "     30      \u001b[36m397.1024\u001b[0m      700.2883        0.0001  0.3062\n",
      "     31      428.2268      730.1846        0.0050  0.1994\n",
      "     32      474.0691      772.0978        0.0049  0.2944\n",
      "     33      479.7091      748.9499        0.0045  0.2030\n",
      "     34      432.9421      \u001b[32m696.3760\u001b[0m     +  0.0040  0.3304\n",
      "     35      406.9911      \u001b[32m695.2448\u001b[0m     +  0.0033  0.2209\n",
      "     36      403.1524      \u001b[32m688.6671\u001b[0m     +  0.0025  0.1933\n",
      "     37      \u001b[36m392.2703\u001b[0m      688.6961        0.0017  0.3092\n",
      "     38      \u001b[36m387.9250\u001b[0m      690.2472        0.0010  0.2055\n",
      "     39      \u001b[36m384.0324\u001b[0m      690.7581        0.0005  0.3018\n",
      "     40      \u001b[36m382.1659\u001b[0m      691.1267        0.0001  0.2075\n",
      "     41      409.4510      719.3760        0.0050  0.2996\n",
      "     42      453.4750      753.2421        0.0049  0.1987\n",
      "     43      464.1806      732.4463        0.0045  0.1993\n",
      "     44      421.1073      \u001b[32m683.1862\u001b[0m     +  0.0040  0.3048\n",
      "     45      393.4436      683.9922        0.0033  0.2046\n",
      "     46      391.5076      \u001b[32m679.1301\u001b[0m     +  0.0025  0.2951\n",
      "     47      \u001b[36m380.5498\u001b[0m      680.7157        0.0017  0.2011\n",
      "     48      \u001b[36m376.6456\u001b[0m      685.5908        0.0010  0.2998\n",
      "     49      \u001b[36m372.8374\u001b[0m      686.3467        0.0005  0.1969\n",
      "     50      \u001b[36m371.1131\u001b[0m      686.9054        0.0001  0.2000\n",
      "     51      397.7611      705.3095        0.0050  0.3052\n",
      "     52      440.5803      741.9661        0.0049  0.2018\n",
      "     53      458.3676      725.7279        0.0045  0.2921\n",
      "     54      414.2910      \u001b[32m665.8752\u001b[0m     +  0.0040  0.2058\n",
      "     55      383.8311      675.8046        0.0033  0.3373\n",
      "     56      383.3114      666.3036        0.0025  0.2009\n",
      "     57      372.1824      670.1315        0.0017  0.2939\n",
      "     58      \u001b[36m368.9808\u001b[0m      677.5535        0.0010  0.1950\n",
      "     59      \u001b[36m365.2659\u001b[0m      678.3396        0.0005  0.1988\n",
      "     60      \u001b[36m363.7288\u001b[0m      679.0130        0.0001  0.2991\n",
      "     61      387.6056      690.4060        0.0050  0.2007\n",
      "     62      426.2023      726.6072        0.0049  0.3051\n",
      "     63      442.1170      692.4343        0.0045  0.2068\n",
      "     64      405.9501      \u001b[32m658.7137\u001b[0m     +  0.0040  0.2938\n",
      "     65      375.1722      663.9855        0.0033  0.2004\n",
      "     66      374.7363      661.6174        0.0025  0.3034\n",
      "     67      365.2248      659.9201        0.0017  0.2111\n",
      "     68      \u001b[36m361.5872\u001b[0m      669.6123        0.0010  0.2176\n",
      "     69      \u001b[36m358.0776\u001b[0m      670.3597        0.0005  0.2934\n",
      "     70      \u001b[36m356.6405\u001b[0m      671.2398        0.0001  0.1972\n",
      "     71      380.1379      676.0025        0.0050  0.3062\n",
      "     72      416.6047      709.1418        0.0049  0.2041\n",
      "     73      437.3739      698.0363        0.0045  0.2980\n",
      "     74      403.9407      \u001b[32m648.3151\u001b[0m     +  0.0040  0.1992\n",
      "     75      369.4243      665.5051        0.0033  0.3441\n",
      "     76      369.1722      660.0586        0.0025  0.2742\n",
      "     77      360.5307      663.2992        0.0017  0.1969\n",
      "     78      357.1175      674.5014        0.0010  0.2940\n",
      "     79      \u001b[36m353.8833\u001b[0m      675.5414        0.0005  0.2210\n",
      "     80      \u001b[36m352.5846\u001b[0m      676.4919        0.0001  0.2885\n",
      "     81      374.2747      669.8897        0.0050  0.1967\n",
      "     82      408.4528      698.5324        0.0049  0.3045\n",
      "     83      422.1570      685.3856        0.0045  0.2006\n",
      "     84      402.3992      \u001b[32m628.5059\u001b[0m     +  0.0040  0.2963\n",
      "     85      367.7174      656.4877        0.0033  0.2057\n",
      "     86      360.8368      637.9337        0.0025  0.1990\n",
      "     87      357.4066      654.6619        0.0017  0.2919\n",
      "     88      \u001b[36m350.0039\u001b[0m      654.5666        0.0010  0.2045\n",
      "     89      \u001b[36m347.4070\u001b[0m      655.8060        0.0005  0.2923\n",
      "     90      \u001b[36m345.8442\u001b[0m      656.7692        0.0001  0.1960\n",
      "     91      371.8034      648.0452        0.0050  0.2967\n",
      "     92      401.9092      673.4920        0.0049  0.1992\n",
      "     93      416.7787      656.8903        0.0045  0.3334\n",
      "     94      392.3927      639.9577        0.0040  0.2033\n",
      "     95      357.9878      \u001b[32m627.8471\u001b[0m     +  0.0033  0.2463\n",
      "     96      354.8667      \u001b[32m619.4259\u001b[0m     +  0.0025  0.3092\n",
      "     97      351.5530      636.8647        0.0017  0.2008\n",
      "     98      \u001b[36m341.8238\u001b[0m      636.7723        0.0010  0.2938\n",
      "     99      \u001b[36m339.5876\u001b[0m      640.1906        0.0005  0.1979\n",
      "    100      \u001b[36m338.0415\u001b[0m      641.4833        0.0001  0.3012\n",
      "    101      364.1627      634.9546        0.0050  0.2061\n",
      "    102      390.6643      654.7432        0.0049  0.3021\n",
      "    103      408.2004      648.7399        0.0045  0.2092\n",
      "    104      396.6052      \u001b[32m618.7301\u001b[0m     +  0.0040  0.1987\n",
      "    105      354.9615      \u001b[32m607.2316\u001b[0m     +  0.0033  0.2888\n",
      "    106      344.8526      623.2598        0.0025  0.1978\n",
      "    107      341.7824      620.1552        0.0017  0.3178\n",
      "    108      \u001b[36m333.9706\u001b[0m      621.0898        0.0010  0.1968\n",
      "    109      \u001b[36m331.6146\u001b[0m      627.6732        0.0005  0.2961\n",
      "    110      \u001b[36m329.9794\u001b[0m      628.3220        0.0001  0.1995\n",
      "    111      354.0479      608.8524        0.0050  0.2988\n",
      "    112      377.2948      646.7858        0.0049  0.1981\n",
      "    113      393.4360      621.8404        0.0045  0.1969\n",
      "    114      384.6059      \u001b[32m584.5584\u001b[0m     +  0.0040  0.2935\n",
      "    115      353.0940      619.6302        0.0033  0.2164\n",
      "    116      335.4972      604.5008        0.0025  0.2987\n",
      "    117      332.3251      612.8002        0.0017  0.2022\n",
      "    118      \u001b[36m326.3862\u001b[0m      615.9964        0.0010  0.3014\n",
      "    119      \u001b[36m323.8369\u001b[0m      621.7798        0.0005  0.1930\n",
      "    120      \u001b[36m322.3705\u001b[0m      621.9836        0.0001  0.3069\n",
      "    121      345.9681      593.9392        0.0050  0.1968\n",
      "    122      363.0948      621.0359        0.0049  0.1998\n",
      "    123      378.3248      607.0111        0.0045  0.2854\n",
      "    124      380.8413      \u001b[32m581.8494\u001b[0m     +  0.0040  0.1907\n",
      "    125      349.2069      592.8013        0.0033  0.3010\n",
      "    126      328.9300      632.3051        0.0025  0.1944\n",
      "    127      325.2155      614.2960        0.0017  0.2927\n",
      "    128      \u001b[36m319.7706\u001b[0m      612.0081        0.0010  0.2003\n",
      "    129      \u001b[36m317.1226\u001b[0m      617.5452        0.0005  0.2986\n",
      "    130      \u001b[36m315.7242\u001b[0m      617.2314        0.0001  0.2016\n",
      "    131      338.0710      590.6239        0.0050  0.2019\n",
      "    132      352.6085      609.4847        0.0049  0.2925\n",
      "    133      367.2967      612.7461        0.0045  0.1980\n",
      "    134      374.0345      \u001b[32m578.2793\u001b[0m     +  0.0040  0.2935\n",
      "    135      348.2776      \u001b[32m578.0817\u001b[0m     +  0.0033  0.2168\n",
      "    136      324.8239      631.5309        0.0025  0.3288\n",
      "    137      318.3279      611.3496        0.0017  0.2183\n",
      "    138      \u001b[36m314.6010\u001b[0m      610.4718        0.0010  0.3043\n",
      "    139      \u001b[36m311.6133\u001b[0m      614.6969        0.0005  0.2053\n",
      "    140      \u001b[36m310.2440\u001b[0m      613.9684        0.0001  0.1982\n",
      "    141      332.9292      588.8475        0.0050  0.3115\n",
      "    142      344.3867      594.1701        0.0049  0.1982\n",
      "    143      358.9910      606.2339        0.0045  0.3212\n",
      "    144      368.9117      579.1660        0.0040  0.2029\n",
      "    145      345.2241      \u001b[32m566.0933\u001b[0m     +  0.0033  0.2910\n",
      "    146      321.8098      640.6719        0.0025  0.1984\n",
      "    147      313.0553      612.9633        0.0017  0.2993\n",
      "    148      \u001b[36m309.6528\u001b[0m      613.6168        0.0010  0.2131\n",
      "    149      \u001b[36m306.6602\u001b[0m      615.7617        0.0005  0.2173\n",
      "    150      \u001b[36m305.3422\u001b[0m      614.7434        0.0001  0.4324\n",
      "    151      326.6751      581.8150        0.0050  0.2004\n",
      "    152      337.5624      586.6720        0.0049  0.3042\n",
      "    153      350.7824      594.9535        0.0045  0.1986\n",
      "    154      361.7031      590.9711        0.0040  0.3142\n",
      "    155      342.8071      \u001b[32m555.7941\u001b[0m     +  0.0033  0.2256\n",
      "    156      319.5147      642.5410        0.0025  0.3060\n",
      "    157      307.9901      608.1089        0.0017  0.2009\n",
      "    158      305.9988      610.0429        0.0010  0.2030\n",
      "    159      \u001b[36m302.3303\u001b[0m      611.8855        0.0005  0.2965\n",
      "    160      \u001b[36m301.0349\u001b[0m      610.6496        0.0001  0.2043\n",
      "    161      321.2598      580.7855        0.0050  0.3156\n",
      "    162      329.9121      582.8308        0.0049  0.2033\n",
      "    163      342.8021      590.5634        0.0045  0.2947\n",
      "    164      354.5070      576.1758        0.0040  0.1988\n",
      "    165      337.8169      \u001b[32m545.6994\u001b[0m     +  0.0033  0.2962\n",
      "    166      316.3248      646.2079        0.0025  0.2023\n",
      "    167      302.6093      608.5809        0.0017  0.2082\n",
      "    168      301.0900      612.9416        0.0010  0.3052\n",
      "    169      \u001b[36m297.3494\u001b[0m      609.5745        0.0005  0.2030\n",
      "    170      \u001b[36m296.1156\u001b[0m      608.6269        0.0001  0.2981\n",
      "    171      315.6654      580.4701        0.0050  0.2047\n",
      "    172      323.4403      574.3866        0.0049  0.3031\n",
      "    173      337.0536      578.1710        0.0045  0.1999\n",
      "    174      346.6802      575.3206        0.0040  0.2960\n",
      "    175      338.3749      \u001b[32m536.8658\u001b[0m     +  0.0033  0.2099\n",
      "    176      317.8936      641.6622        0.0025  0.2347\n",
      "    177      299.6870      607.0418        0.0017  0.3063\n",
      "    178      297.5262      613.6251        0.0010  0.1996\n",
      "    179      \u001b[36m293.3822\u001b[0m      605.2264        0.0005  0.3050\n",
      "    180      \u001b[36m292.0907\u001b[0m      605.0732        0.0001  0.1991\n",
      "    181      309.7951      581.0316        0.0050  0.2921\n",
      "    182      319.3901      575.3535        0.0049  0.1957\n",
      "    183      331.7723      574.9247        0.0045  0.2958\n",
      "    184      340.4007      566.8563        0.0040  0.1952\n",
      "    185      335.9437      \u001b[32m530.7075\u001b[0m     +  0.0033  0.2158\n",
      "    186      319.9038      654.3532        0.0025  0.2979\n",
      "    187      297.2285      612.0124        0.0017  0.1984\n",
      "    188      295.4109      622.2214        0.0010  0.3234\n",
      "    189      \u001b[36m289.8187\u001b[0m      607.6029        0.0005  0.1966\n",
      "    190      \u001b[36m288.5104\u001b[0m      607.1611        0.0001  0.3063\n",
      "    191      304.4538      575.8939        0.0050  0.2003\n",
      "    192      316.6507      570.1609        0.0049  0.2989\n",
      "    193      327.1716      569.0743        0.0045  0.1974\n",
      "    194      330.3321      556.3154        0.0040  0.2132\n",
      "    195      336.3666      536.5648        0.0033  0.3088\n",
      "    196      320.6743      636.0257        0.0025  0.2162\n",
      "    197      295.4740      629.1378        0.0017  0.3112\n",
      "    198      293.2148      637.4945        0.0010  0.2054\n",
      "    199      \u001b[36m287.4885\u001b[0m      619.2652        0.0005  0.3007\n",
      "    200      \u001b[36m285.8496\u001b[0m      618.7778        0.0001  0.1989\n",
      "    201      299.7564      575.9826        0.0050  0.2975\n",
      "    202      311.1545      571.8359        0.0049  0.2059\n",
      "    203      319.6620      565.9995        0.0045  0.1997\n",
      "    204      325.8286      547.5764        0.0040  0.3139\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m879.7725\u001b[0m      \u001b[32m985.2080\u001b[0m     +  0.0050  0.3224\n",
      "      2      896.9922     1258.5069        0.0049  0.2096\n",
      "      3      \u001b[36m677.1241\u001b[0m      \u001b[32m935.5318\u001b[0m     +  0.0045  0.3108\n",
      "      4      704.2781     1044.5383        0.0040  0.1965\n",
      "      5      \u001b[36m621.0319\u001b[0m      \u001b[32m935.1127\u001b[0m     +  0.0033  0.2977\n",
      "      6      \u001b[36m587.4670\u001b[0m      936.3847        0.0025  0.2061\n",
      "      7      \u001b[36m550.8120\u001b[0m      \u001b[32m903.3604\u001b[0m     +  0.0017  0.2030\n",
      "      8      \u001b[36m527.2550\u001b[0m      \u001b[32m882.9289\u001b[0m     +  0.0010  0.3074\n",
      "      9      \u001b[36m511.5114\u001b[0m      \u001b[32m873.6204\u001b[0m     +  0.0005  0.1938\n",
      "     10      \u001b[36m504.1093\u001b[0m      \u001b[32m870.9223\u001b[0m     +  0.0001  0.2928\n",
      "     11      586.7464      \u001b[32m821.1804\u001b[0m     +  0.0050  0.1921\n",
      "     12      686.7790     1019.7536        0.0049  0.2946\n",
      "     13      558.3669      827.5322        0.0045  0.1966\n",
      "     14      \u001b[36m476.2172\u001b[0m      \u001b[32m803.7401\u001b[0m     +  0.0040  0.1938\n",
      "     15      \u001b[36m476.0270\u001b[0m      \u001b[32m801.7154\u001b[0m     +  0.0033  0.3016\n",
      "     16      \u001b[36m449.0526\u001b[0m      \u001b[32m772.8451\u001b[0m     +  0.0025  0.2211\n",
      "     17      \u001b[36m438.5358\u001b[0m      \u001b[32m763.5676\u001b[0m     +  0.0017  0.3556\n",
      "     18      \u001b[36m428.9188\u001b[0m      \u001b[32m758.7410\u001b[0m     +  0.0010  0.2077\n",
      "     19      \u001b[36m424.1449\u001b[0m      \u001b[32m756.5936\u001b[0m     +  0.0005  0.2947\n",
      "     20      \u001b[36m421.4972\u001b[0m      \u001b[32m756.0723\u001b[0m     +  0.0001  0.1996\n",
      "     21      462.8647      771.5027        0.0050  0.3091\n",
      "     22      521.5401      822.7490        0.0049  0.2040\n",
      "     23      511.8131      800.3513        0.0045  0.2028\n",
      "     24      450.2793      \u001b[32m738.4047\u001b[0m     +  0.0040  0.3049\n",
      "     25      425.6532      \u001b[32m734.8936\u001b[0m     +  0.0033  0.2005\n",
      "     26      \u001b[36m420.6756\u001b[0m      \u001b[32m727.4932\u001b[0m     +  0.0025  0.3095\n",
      "     27      \u001b[36m408.9237\u001b[0m      \u001b[32m722.4813\u001b[0m     +  0.0017  0.2071\n",
      "     28      \u001b[36m403.9128\u001b[0m      \u001b[32m721.1358\u001b[0m     +  0.0010  0.3026\n",
      "     29      \u001b[36m399.8499\u001b[0m      \u001b[32m720.6068\u001b[0m     +  0.0005  0.2026\n",
      "     30      \u001b[36m397.7903\u001b[0m      \u001b[32m720.5504\u001b[0m     +  0.0001  0.2048\n",
      "     31      429.6147      737.0772        0.0050  0.2999\n",
      "     32      480.7394      752.7752        0.0049  0.2050\n",
      "     33      486.7698      788.4621        0.0045  0.2963\n",
      "     34      449.2656      \u001b[32m704.9633\u001b[0m     +  0.0040  0.2035\n",
      "     35      405.0355      \u001b[32m702.7482\u001b[0m     +  0.0033  0.3083\n",
      "     36      405.8949      704.7724        0.0025  0.2016\n",
      "     37      \u001b[36m393.7635\u001b[0m      \u001b[32m700.2303\u001b[0m     +  0.0017  0.1954\n",
      "     38      \u001b[36m390.1281\u001b[0m      700.3755        0.0010  0.3041\n",
      "     39      \u001b[36m386.0375\u001b[0m      \u001b[32m700.0198\u001b[0m     +  0.0005  0.2049\n",
      "     40      \u001b[36m384.2289\u001b[0m      700.1624        0.0001  0.2994\n",
      "     41      411.4571      714.8962        0.0050  0.2009\n",
      "     42      453.2400      750.0955        0.0049  0.2972\n",
      "     43      459.7956      723.0100        0.0045  0.2172\n",
      "     44      417.1002      \u001b[32m684.2494\u001b[0m     +  0.0040  0.3132\n",
      "     45      395.5057      \u001b[32m680.1411\u001b[0m     +  0.0033  0.2272\n",
      "     46      392.3513      684.5198        0.0025  0.4047\n",
      "     47      \u001b[36m382.4386\u001b[0m      \u001b[32m677.5135\u001b[0m     +  0.0017  0.3051\n",
      "     48      \u001b[36m378.3991\u001b[0m      681.6571        0.0010  0.2128\n",
      "     49      \u001b[36m374.9515\u001b[0m      681.9690        0.0005  0.2971\n",
      "     50      \u001b[36m373.2518\u001b[0m      682.2565        0.0001  0.2019\n",
      "     51      399.4860      687.9384        0.0050  0.3078\n",
      "     52      439.6632      740.7400        0.0049  0.2062\n",
      "     53      452.2185      699.1434        0.0045  0.3068\n",
      "     54      412.3596      \u001b[32m665.8203\u001b[0m     +  0.0040  0.2044\n",
      "     55      385.7559      \u001b[32m661.9985\u001b[0m     +  0.0033  0.1942\n",
      "     56      383.3320      \u001b[32m661.5494\u001b[0m     +  0.0025  0.3118\n",
      "     57      374.0494      \u001b[32m660.9368\u001b[0m     +  0.0017  0.2061\n",
      "     58      \u001b[36m370.1141\u001b[0m      663.6794        0.0010  0.3105\n",
      "     59      \u001b[36m366.7740\u001b[0m      664.8688        0.0005  0.2016\n",
      "     60      \u001b[36m365.2247\u001b[0m      665.5352        0.0001  0.2969\n",
      "     61      390.5030      682.2992        0.0050  0.2000\n",
      "     62      427.1660      699.3737        0.0049  0.3084\n",
      "     63      440.9119      688.6949        0.0045  0.2136\n",
      "     64      407.2070      \u001b[32m640.4973\u001b[0m     +  0.0040  0.2288\n",
      "     65      378.6222      648.9120        0.0033  0.3151\n",
      "     66      375.4771      \u001b[32m637.8759\u001b[0m     +  0.0025  0.2002\n",
      "     67      367.2185      639.9066        0.0017  0.2957\n",
      "     68      \u001b[36m361.8030\u001b[0m      640.9637        0.0010  0.2050\n",
      "     69      \u001b[36m358.3523\u001b[0m      641.3901        0.0005  0.3116\n",
      "     70      \u001b[36m356.6884\u001b[0m      642.1705        0.0001  0.2054\n",
      "     71      384.1541      655.7026        0.0050  0.3048\n",
      "     72      415.6017      674.6119        0.0049  0.2038\n",
      "     73      431.1549      674.9501        0.0045  0.2051\n",
      "     74      410.9603      \u001b[32m628.2689\u001b[0m     +  0.0040  0.2976\n",
      "     75      368.2797      \u001b[32m610.2936\u001b[0m     +  0.0033  0.1955\n",
      "     76      366.9048      612.9607        0.0025  0.3236\n",
      "     77      358.9993      620.7935        0.0017  0.2229\n",
      "     78      \u001b[36m350.2167\u001b[0m      612.6048        0.0010  0.2957\n",
      "     79      \u001b[36m347.7978\u001b[0m      616.9158        0.0005  0.2191\n",
      "     80      \u001b[36m346.0400\u001b[0m      618.0443        0.0001  0.3019\n",
      "     81      372.8811      626.9013        0.0050  0.2082\n",
      "     82      398.6684      641.8551        0.0049  0.2124\n",
      "     83      413.0951      651.5944        0.0045  0.3633\n",
      "     84      401.8151      \u001b[32m584.0922\u001b[0m     +  0.0040  0.3494\n",
      "     85      367.7408      610.1474        0.0033  0.6393\n",
      "     86      350.8520      586.5382        0.0025  0.2010\n",
      "     87      347.9434      596.8121        0.0017  0.3219\n",
      "     88      \u001b[36m340.8854\u001b[0m      598.6133        0.0010  0.2087\n",
      "     89      \u001b[36m338.2321\u001b[0m      603.3524        0.0005  0.3004\n",
      "     90      \u001b[36m336.4826\u001b[0m      603.4340        0.0001  0.2143\n",
      "     91      362.8121      604.7997        0.0050  0.1980\n",
      "     92      382.6912      621.5498        0.0049  0.2992\n",
      "     93      400.9161      626.9157        0.0045  0.1987\n",
      "     94      394.4365      \u001b[32m576.9555\u001b[0m     +  0.0040  0.2880\n",
      "     95      357.6880      593.5168        0.0033  0.2053\n",
      "     96      342.7990      577.7072        0.0025  0.2937\n",
      "     97      338.1827      588.0696        0.0017  0.2019\n",
      "     98      \u001b[36m332.4687\u001b[0m      590.8865        0.0010  0.3011\n",
      "     99      \u001b[36m329.8059\u001b[0m      594.0798        0.0005  0.2089\n",
      "    100      \u001b[36m328.2646\u001b[0m      594.2864        0.0001  0.2062\n",
      "    101      352.9856      594.6270        0.0050  0.3369\n",
      "    102      370.8327      604.4117        0.0049  0.2242\n",
      "    103      388.7336      617.3068        0.0045  0.3067\n",
      "    104      391.2476      \u001b[32m575.5091\u001b[0m     +  0.0040  0.2033\n",
      "    105      355.5356      \u001b[32m572.9422\u001b[0m     +  0.0033  0.2987\n",
      "    106      334.1222      582.7002        0.0025  0.1993\n",
      "    107      329.8085      579.7654        0.0017  0.3098\n",
      "    108      \u001b[36m325.5295\u001b[0m      583.7177        0.0010  0.2222\n",
      "    109      \u001b[36m322.6312\u001b[0m      587.8352        0.0005  0.2038\n",
      "    110      \u001b[36m321.1254\u001b[0m      587.5152        0.0001  0.2980\n",
      "    111      345.0522      587.9731        0.0050  0.1960\n",
      "    112      358.7984      598.9185        0.0049  0.3072\n",
      "    113      373.9982      597.8581        0.0045  0.2111\n",
      "    114      383.4689      585.2174        0.0040  0.2957\n",
      "    115      354.0022      \u001b[32m561.1999\u001b[0m     +  0.0033  0.2075\n",
      "    116      329.8991      593.8452        0.0025  0.2980\n",
      "    117      323.2767      580.3103        0.0017  0.1974\n",
      "    118      \u001b[36m319.9102\u001b[0m      582.3402        0.0010  0.2024\n",
      "    119      \u001b[36m316.6789\u001b[0m      585.7667        0.0005  0.3139\n",
      "    120      \u001b[36m315.1903\u001b[0m      585.2407        0.0001  0.2004\n",
      "    121      337.3641      586.6713        0.0050  0.3141\n",
      "    122      348.2831      596.5234        0.0049  0.2155\n",
      "    123      363.7502      590.5987        0.0045  0.3017\n",
      "    124      375.4948      587.1097        0.0040  0.2043\n",
      "    125      352.4449      \u001b[32m549.5581\u001b[0m     +  0.0033  0.3055\n",
      "    126      326.9994      596.1005        0.0025  0.2011\n",
      "    127      316.9899      580.5571        0.0017  0.2066\n",
      "    128      \u001b[36m314.3698\u001b[0m      586.8888        0.0010  0.3064\n",
      "    129      \u001b[36m311.0592\u001b[0m      588.4937        0.0005  0.2005\n",
      "    130      \u001b[36m309.7245\u001b[0m      587.9320        0.0001  0.3044\n",
      "    131      331.4700      586.1293        0.0050  0.1998\n",
      "    132      341.8850      592.5352        0.0049  0.3685\n",
      "    133      354.1431      585.2318        0.0045  0.2475\n",
      "    134      366.3413      588.2072        0.0040  0.3118\n",
      "    135      350.1567      \u001b[32m545.8866\u001b[0m     +  0.0033  0.2041\n",
      "    136      327.6813      610.0620        0.0025  0.2001\n",
      "    137      313.2049      591.5614        0.0017  0.2857\n",
      "    138      310.2497      595.1057        0.0010  0.1987\n",
      "    139      \u001b[36m306.8711\u001b[0m      591.5117        0.0005  0.3034\n",
      "    140      \u001b[36m305.4971\u001b[0m      590.9899        0.0001  0.1950\n",
      "    141      325.6681      582.0748        0.0050  0.3094\n",
      "    142      336.0888      590.2581        0.0049  0.2051\n",
      "    143      347.5701      579.4141        0.0045  0.3101\n",
      "    144      360.8592      576.5540        0.0040  0.1947\n",
      "    145      344.1026      \u001b[32m543.9882\u001b[0m     +  0.0033  0.1943\n",
      "    146      324.3943      636.0126        0.0025  0.3049\n",
      "    147      309.4878      605.6959        0.0017  0.1995\n",
      "    148      306.9316      607.7273        0.0010  0.3031\n",
      "    149      \u001b[36m303.7412\u001b[0m      601.4448        0.0005  0.1947\n",
      "    150      \u001b[36m302.3092\u001b[0m      601.0948        0.0001  0.2932\n",
      "    151      320.7956      574.7968        0.0050  0.2007\n",
      "    152      329.5923      587.4754        0.0049  0.2840\n",
      "    153      343.4747      568.4753        0.0045  0.1967\n",
      "    154      349.1585      579.8216        0.0040  0.1973\n",
      "    155      348.5404      545.2442        0.0033  0.3026\n",
      "    156      327.4557      625.3357        0.0025  0.1970\n",
      "    157      307.3316      603.5014        0.0017  0.2937\n",
      "    158      304.4921      610.0201        0.0010  0.1984\n",
      "    159      \u001b[36m300.8340\u001b[0m      600.2670        0.0005  0.2986\n",
      "    160      \u001b[36m299.3981\u001b[0m      600.4475        0.0001  0.1898\n",
      "    161      318.0616      590.0836        0.0050  0.2973\n",
      "    162      329.8727      604.3833        0.0049  0.2115\n",
      "    163      336.8857      573.4362        0.0045  0.2057\n",
      "    164      348.5706      574.1927        0.0040  0.3025\n",
      "    165      347.5311      \u001b[32m542.8556\u001b[0m     +  0.0033  0.1970\n",
      "    166      326.0678      613.2238        0.0025  0.2993\n",
      "    167      304.5461      604.0287        0.0017  0.1974\n",
      "    168      302.6266      606.1385        0.0010  0.3030\n",
      "    169      \u001b[36m296.7525\u001b[0m      596.0009        0.0005  0.1951\n",
      "    170      \u001b[36m295.3596\u001b[0m      595.4172        0.0001  0.2933\n",
      "    171      313.2803      577.0162        0.0050  0.1936\n",
      "    172      325.0828      588.0279        0.0049  0.1971\n",
      "    173      334.2643      570.7690        0.0045  0.2981\n",
      "    174      344.5004      577.0525        0.0040  0.2001\n",
      "    175      341.8618      \u001b[32m539.5028\u001b[0m     +  0.0033  0.3038\n",
      "    176      319.1423      645.1687        0.0025  0.2034\n",
      "    177      298.8581      597.0937        0.0017  0.2973\n",
      "    178      298.1143      602.1022        0.0010  0.1998\n",
      "    179      \u001b[36m293.1040\u001b[0m      594.5350        0.0005  0.2950\n",
      "    180      \u001b[36m291.7433\u001b[0m      594.7036        0.0001  0.1979\n",
      "    181      307.0793      593.3443        0.0050  0.1957\n",
      "    182      320.3151      586.4221        0.0049  0.3179\n",
      "    183      325.9368      566.2093        0.0045  0.3125\n",
      "    184      334.7975      568.1421        0.0040  0.3203\n",
      "    185      337.1041      540.5578        0.0033  0.2417\n",
      "    186      318.3253      635.5092        0.0025  0.3326\n",
      "    187      296.1354      600.9060        0.0017  0.2236\n",
      "    188      294.6121      607.6996        0.0010  0.3068\n",
      "    189      \u001b[36m289.9183\u001b[0m      594.2446        0.0005  0.2005\n",
      "    190      \u001b[36m288.4352\u001b[0m      595.2097        0.0001  0.1918\n",
      "    191      302.3590      602.4044        0.0050  0.2937\n",
      "    192      314.5043      586.2387        0.0049  0.2009\n",
      "    193      319.7378      558.9557        0.0045  0.2920\n",
      "    194      328.3389      574.3196        0.0040  0.2065\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m868.0716\u001b[0m      \u001b[32m936.3187\u001b[0m     +  0.0050  0.2665\n",
      "      2      874.8824     1220.7207        0.0049  0.2901\n",
      "      3      \u001b[36m646.2220\u001b[0m      \u001b[32m912.5843\u001b[0m     +  0.0045  0.2057\n",
      "      4      678.0826      978.9656        0.0040  0.3275\n",
      "      5      \u001b[36m593.2223\u001b[0m      920.1602        0.0033  0.3061\n",
      "      6      \u001b[36m575.7476\u001b[0m      \u001b[32m900.9138\u001b[0m     +  0.0025  0.1989\n",
      "      7      \u001b[36m539.4337\u001b[0m      \u001b[32m880.0309\u001b[0m     +  0.0017  0.2973\n",
      "      8      \u001b[36m519.3163\u001b[0m      \u001b[32m863.6817\u001b[0m     +  0.0010  0.1940\n",
      "      9      \u001b[36m506.5134\u001b[0m      \u001b[32m857.1913\u001b[0m     +  0.0005  0.3047\n",
      "     10      \u001b[36m500.0676\u001b[0m      \u001b[32m855.4150\u001b[0m     +  0.0001  0.1969\n",
      "     11      578.7027      \u001b[32m832.2579\u001b[0m     +  0.0050  0.2087\n",
      "     12      644.2709      960.8808        0.0049  0.2867\n",
      "     13      530.8275      \u001b[32m820.6068\u001b[0m     +  0.0045  0.2010\n",
      "     14      \u001b[36m480.8869\u001b[0m      \u001b[32m806.8597\u001b[0m     +  0.0040  0.2885\n",
      "     15      \u001b[36m475.8920\u001b[0m      \u001b[32m794.2334\u001b[0m     +  0.0033  0.1973\n",
      "     16      \u001b[36m453.8091\u001b[0m      \u001b[32m774.0058\u001b[0m     +  0.0025  0.2921\n",
      "     17      \u001b[36m444.4068\u001b[0m      \u001b[32m766.8987\u001b[0m     +  0.0017  0.1979\n",
      "     18      \u001b[36m435.8638\u001b[0m      \u001b[32m762.9325\u001b[0m     +  0.0010  0.2915\n",
      "     19      \u001b[36m431.3990\u001b[0m      \u001b[32m761.1916\u001b[0m     +  0.0005  0.1923\n",
      "     20      \u001b[36m428.9274\u001b[0m      \u001b[32m760.7718\u001b[0m     +  0.0001  0.1938\n",
      "     21      467.7087      772.2748        0.0050  0.2937\n",
      "     22      512.4493      813.8061        0.0049  0.1922\n",
      "     23      494.5450      777.8345        0.0045  0.2978\n",
      "     24      448.0686      \u001b[32m743.2314\u001b[0m     +  0.0040  0.1916\n",
      "     25      432.1459      \u001b[32m740.8377\u001b[0m     +  0.0033  0.2952\n",
      "     26      \u001b[36m424.1965\u001b[0m      \u001b[32m730.8768\u001b[0m     +  0.0025  0.1936\n",
      "     27      \u001b[36m414.3575\u001b[0m      \u001b[32m726.6957\u001b[0m     +  0.0017  0.1959\n",
      "     28      \u001b[36m408.8789\u001b[0m      726.8053        0.0010  0.2960\n",
      "     29      \u001b[36m405.0964\u001b[0m      \u001b[32m725.9506\u001b[0m     +  0.0005  0.1984\n",
      "     30      \u001b[36m403.0347\u001b[0m      \u001b[32m725.9434\u001b[0m     +  0.0001  0.2984\n",
      "     31      433.4063      748.2781        0.0050  0.2016\n",
      "     32      475.2571      773.1766        0.0049  0.2936\n",
      "     33      472.6617      748.1838        0.0045  0.2000\n",
      "     34      431.4646      \u001b[32m716.1217\u001b[0m     +  0.0040  0.2012\n",
      "     35      412.3779      \u001b[32m711.2993\u001b[0m     +  0.0033  0.2903\n",
      "     36      407.3568      \u001b[32m710.4755\u001b[0m     +  0.0025  0.1926\n",
      "     37      \u001b[36m397.7408\u001b[0m      \u001b[32m709.8070\u001b[0m     +  0.0017  0.2943\n",
      "     38      \u001b[36m393.3876\u001b[0m      711.5004        0.0010  0.2049\n",
      "     39      \u001b[36m389.8187\u001b[0m      712.0788        0.0005  0.2972\n",
      "     40      \u001b[36m387.9998\u001b[0m      712.4514        0.0001  0.2003\n",
      "     41      414.7203      726.2172        0.0050  0.3006\n",
      "     42      454.8447      771.4542        0.0049  0.2172\n",
      "     43      463.3459      746.8472        0.0045  0.2359\n",
      "     44      428.7339      \u001b[32m691.6401\u001b[0m     +  0.0040  0.3432\n",
      "     45      397.5478      697.4791        0.0033  0.2001\n",
      "     46      396.6653      694.3229        0.0025  0.3008\n",
      "     47      \u001b[36m386.2074\u001b[0m      698.4715        0.0017  0.1992\n",
      "     48      \u001b[36m382.6969\u001b[0m      701.8037        0.0010  0.2945\n",
      "     49      \u001b[36m379.0988\u001b[0m      702.2691        0.0005  0.1954\n",
      "     50      \u001b[36m377.4170\u001b[0m      702.7918        0.0001  0.2943\n",
      "     51      402.3109      712.6305        0.0050  0.2003\n",
      "     52      439.4362      744.5663        0.0049  0.1887\n",
      "     53      443.6207      705.2449        0.0045  0.2920\n",
      "     54      406.3950      \u001b[32m682.6941\u001b[0m     +  0.0040  0.2059\n",
      "     55      389.8799      690.7650        0.0033  0.3034\n",
      "     56      386.8727      687.8136        0.0025  0.1907\n",
      "     57      \u001b[36m377.1449\u001b[0m      691.9887        0.0017  0.3015\n",
      "     58      \u001b[36m373.4768\u001b[0m      696.1543        0.0010  0.1968\n",
      "     59      \u001b[36m370.3018\u001b[0m      698.2497        0.0005  0.2870\n",
      "     60      \u001b[36m368.7388\u001b[0m      699.1809        0.0001  0.1948\n",
      "     61      392.7904      702.4991        0.0050  0.1971\n",
      "     62      430.5370      722.3306        0.0049  0.3168\n",
      "     63      437.8158      704.9605        0.0045  0.2237\n",
      "     64      402.2733      \u001b[32m670.0435\u001b[0m     +  0.0040  0.3105\n",
      "     65      381.2894      677.9403        0.0033  0.2212\n",
      "     66      379.7897      678.9621        0.0025  0.3430\n",
      "     67      370.0284      680.8929        0.0017  0.1973\n",
      "     68      \u001b[36m366.6189\u001b[0m      688.0159        0.0010  0.3034\n",
      "     69      \u001b[36m363.4941\u001b[0m      689.9659        0.0005  0.1951\n",
      "     70      \u001b[36m362.0237\u001b[0m      690.9022        0.0001  0.1981\n",
      "     71      388.6460      689.2006        0.0050  0.2892\n",
      "     72      422.4384      705.0735        0.0049  0.1907\n",
      "     73      437.2447      701.2278        0.0045  0.2901\n",
      "     74      403.6702      \u001b[32m654.5601\u001b[0m     +  0.0040  0.1994\n",
      "     75      374.6898      679.2016        0.0033  0.2958\n",
      "     76      374.5462      660.9444        0.0025  0.2010\n",
      "     77      364.9594      669.0498        0.0017  0.2952\n",
      "     78      \u001b[36m361.6331\u001b[0m      676.8836        0.0010  0.1990\n",
      "     79      \u001b[36m358.5303\u001b[0m      678.0118        0.0005  0.2017\n",
      "     80      \u001b[36m357.1586\u001b[0m      678.9486        0.0001  0.2948\n",
      "     81      379.3143      676.1105        0.0050  0.1909\n",
      "     82      412.1450      682.9037        0.0049  0.3007\n",
      "     83      425.4396      678.1592        0.0045  0.2155\n",
      "     84      395.2180      \u001b[32m643.2923\u001b[0m     +  0.0040  0.3896\n",
      "     85      369.4998      661.1472        0.0033  0.1991\n",
      "     86      367.9686      652.4619        0.0025  0.3123\n",
      "     87      359.8898      662.6606        0.0017  0.2105\n",
      "     88      \u001b[36m356.1839\u001b[0m      670.2402        0.0010  0.2010\n",
      "     89      \u001b[36m353.2627\u001b[0m      671.3402        0.0005  0.2953\n",
      "     90      \u001b[36m351.9263\u001b[0m      672.2739        0.0001  0.2074\n",
      "     91      374.5929      657.0618        0.0050  0.2983\n",
      "     92      404.6203      661.2038        0.0049  0.2143\n",
      "     93      420.6697      662.9813        0.0045  0.3067\n",
      "     94      395.9982      \u001b[32m624.2466\u001b[0m     +  0.0040  0.2035\n",
      "     95      366.1615      646.1119        0.0033  0.2923\n",
      "     96      361.7512      639.4704        0.0025  0.1956\n",
      "     97      355.6888      648.2605        0.0017  0.2012\n",
      "     98      \u001b[36m350.3243\u001b[0m      655.2992        0.0010  0.3009\n",
      "     99      \u001b[36m347.5066\u001b[0m      657.3353        0.0005  0.2080\n",
      "    100      \u001b[36m346.0197\u001b[0m      658.2018        0.0001  0.3001\n",
      "    101      371.0719      635.6043        0.0050  0.2048\n",
      "    102      399.1923      640.9200        0.0049  0.3103\n",
      "    103      416.9431      654.2436        0.0045  0.2209\n",
      "    104      393.0637      \u001b[32m602.3644\u001b[0m     +  0.0040  0.2949\n",
      "    105      362.3867      623.7759        0.0033  0.2024\n",
      "    106      353.2261      624.1363        0.0025  0.2071\n",
      "    107      348.0558      633.7410        0.0017  0.3125\n",
      "    108      \u001b[36m342.1700\u001b[0m      639.4472        0.0010  0.2076\n",
      "    109      \u001b[36m339.5121\u001b[0m      643.1341        0.0005  0.3016\n",
      "    110      \u001b[36m337.9802\u001b[0m      643.7270        0.0001  0.1973\n",
      "    111      363.0491      614.9887        0.0050  0.2998\n",
      "    112      386.6477      620.0668        0.0049  0.1969\n",
      "    113      407.6168      634.6385        0.0045  0.3074\n",
      "    114      388.9013      \u001b[32m575.5253\u001b[0m     +  0.0040  0.2036\n",
      "    115      356.4900      623.5406        0.0033  0.2088\n",
      "    116      343.2752      617.8045        0.0025  0.3123\n",
      "    117      340.1950      619.9572        0.0017  0.2025\n",
      "    118      \u001b[36m334.3407\u001b[0m      627.0192        0.0010  0.3119\n",
      "    119      \u001b[36m331.7671\u001b[0m      635.0863        0.0005  0.2060\n",
      "    120      \u001b[36m330.2135\u001b[0m      635.0800        0.0001  0.3082\n",
      "    121      354.7974      604.8718        0.0050  0.1915\n",
      "    122      374.3379      600.7320        0.0049  0.3033\n",
      "    123      394.6968      618.1482        0.0045  0.2219\n",
      "    124      387.6746      \u001b[32m571.3463\u001b[0m     +  0.0040  0.2061\n",
      "    125      352.5083      619.1164        0.0033  0.2949\n",
      "    126      335.0652      637.3684        0.0025  0.1962\n",
      "    127      332.0997      619.0925        0.0017  0.2962\n",
      "    128      \u001b[36m327.3482\u001b[0m      623.2452        0.0010  0.2003\n",
      "    129      \u001b[36m324.3620\u001b[0m      632.9667        0.0005  0.3053\n",
      "    130      \u001b[36m322.9582\u001b[0m      631.2186        0.0001  0.2060\n",
      "    131      347.2983      603.4831        0.0050  0.3109\n",
      "    132      358.8712      590.3511        0.0049  0.2054\n",
      "    133      380.6266      594.7089        0.0045  0.2139\n",
      "    134      382.5504      \u001b[32m570.0635\u001b[0m     +  0.0040  0.3030\n",
      "    135      349.7437      600.7408        0.0033  0.1977\n",
      "    136      330.2679      650.1701        0.0025  0.2976\n",
      "    137      325.9924      613.7250        0.0017  0.2158\n",
      "    138      \u001b[36m322.2169\u001b[0m      617.9754        0.0010  0.3022\n",
      "    139      \u001b[36m318.3033\u001b[0m      627.4302        0.0005  0.1930\n",
      "    140      \u001b[36m316.9752\u001b[0m      624.8231        0.0001  0.3011\n",
      "    141      339.0681      601.7011        0.0050  0.2000\n",
      "    142      348.4208      584.6281        0.0049  0.1980\n",
      "    143      364.1384      577.8990        0.0045  0.3175\n",
      "    144      373.2934      \u001b[32m567.1133\u001b[0m     +  0.0040  0.2488\n",
      "    145      347.2038      588.1422        0.0033  0.2951\n",
      "    146      326.5006      660.9509        0.0025  0.2025\n",
      "    147      320.5842      605.9076        0.0017  0.3045\n",
      "    148      317.8739      610.4274        0.0010  0.2039\n",
      "    149      \u001b[36m312.6013\u001b[0m      619.9606        0.0005  0.2965\n",
      "    150      \u001b[36m311.3832\u001b[0m      616.4982        0.0001  0.2066\n",
      "    151      331.5278      603.7699        0.0050  0.1943\n",
      "    152      337.5027      581.6235        0.0049  0.3284\n",
      "    153      347.8251      \u001b[32m565.1025\u001b[0m     +  0.0045  0.1957\n",
      "    154      359.9904      569.5475        0.0040  0.3041\n",
      "    155      346.4745      568.6185        0.0033  0.2377\n",
      "    156      324.6804      667.7595        0.0025  0.2985\n",
      "    157      315.3385      601.5123        0.0017  0.1990\n",
      "    158      312.8929      606.6022        0.0010  0.3040\n",
      "    159      \u001b[36m307.5962\u001b[0m      611.5522        0.0005  0.2270\n",
      "    160      \u001b[36m306.3994\u001b[0m      609.1826        0.0001  0.2059\n",
      "    161      325.9741      603.2039        0.0050  0.2998\n",
      "    162      330.8201      590.0493        0.0049  0.1998\n",
      "    163      340.6976      \u001b[32m557.6113\u001b[0m     +  0.0045  0.3227\n",
      "    164      348.8578      560.2040        0.0040  0.2363\n",
      "    165      340.8128      \u001b[32m546.6856\u001b[0m     +  0.0033  0.3052\n",
      "    166      324.6471      643.6055        0.0025  0.1969\n",
      "    167      308.6999      601.8406        0.0017  0.2969\n",
      "    168      \u001b[36m305.9292\u001b[0m      609.3789        0.0010  0.2047\n",
      "    169      \u001b[36m302.6071\u001b[0m      600.8682        0.0005  0.2029\n",
      "    170      \u001b[36m301.3115\u001b[0m      601.6856        0.0001  0.2992\n",
      "    171      319.9754      592.1961        0.0050  0.2078\n",
      "    172      329.4831      597.2018        0.0049  0.2992\n",
      "    173      346.9570      562.8252        0.0045  0.1985\n",
      "    174      354.3210      \u001b[32m542.6233\u001b[0m     +  0.0040  0.2985\n",
      "    175      335.5508      546.6702        0.0033  0.2046\n",
      "    176      324.8059      655.0914        0.0025  0.2988\n",
      "    177      307.3035      617.2989        0.0017  0.2134\n",
      "    178      304.3353      622.9136        0.0010  0.2225\n",
      "    179      \u001b[36m299.5991\u001b[0m      606.2597        0.0005  0.3583\n",
      "    180      \u001b[36m298.1408\u001b[0m      606.1339        0.0001  0.3086\n",
      "    181      315.3499      576.3913        0.0050  0.3943\n",
      "    182      326.9848      602.4867        0.0049  0.2119\n",
      "    183      339.3462      549.7344        0.0045  0.3093\n",
      "    184      344.6108      565.7534        0.0040  0.1986\n",
      "    185      337.3129      \u001b[32m540.5270\u001b[0m     +  0.0033  0.2960\n",
      "    186      321.3928      664.4024        0.0025  0.2035\n",
      "    187      303.1809      599.3277        0.0017  0.2083\n",
      "    188      300.7192      607.3061        0.0010  0.3027\n",
      "    189      \u001b[36m296.0274\u001b[0m      595.8186        0.0005  0.2155\n",
      "    190      \u001b[36m294.5495\u001b[0m      596.8088        0.0001  0.2889\n",
      "    191      311.6128      577.9954        0.0050  0.2674\n",
      "    192      320.3653      586.4957        0.0049  0.4675\n",
      "    193      332.2790      550.4670        0.0045  0.3462\n",
      "    194      336.0602      548.4070        0.0040  0.3044\n",
      "    195      335.6630      \u001b[32m536.9101\u001b[0m     +  0.0033  0.1997\n",
      "    196      317.4692      668.4733        0.0025  0.2018\n",
      "    197      300.9073      621.8904        0.0017  0.3134\n",
      "    198      296.7770      610.2650        0.0010  0.2003\n",
      "    199      \u001b[36m292.8815\u001b[0m      596.9000        0.0005  0.2967\n",
      "    200      \u001b[36m291.2817\u001b[0m      599.3173        0.0001  0.2036\n",
      "    201      307.0138      576.7036        0.0050  0.3181\n",
      "    202      316.0567      600.4474        0.0049  0.2089\n",
      "    203      326.8523      542.9638        0.0045  0.2942\n",
      "    204      332.2439      563.2707        0.0040  0.2212\n",
      "    205      329.9754      \u001b[32m531.6895\u001b[0m     +  0.0033  0.1972\n",
      "    206      316.0695      676.1155        0.0025  0.3057\n",
      "    207      297.1653      608.3991        0.0017  0.2035\n",
      "    208      294.0059      611.8073        0.0010  0.3115\n",
      "    209      \u001b[36m289.6493\u001b[0m      599.1355        0.0005  0.2056\n",
      "    210      \u001b[36m287.9291\u001b[0m      601.9194        0.0001  0.2981\n",
      "    211      302.8388      577.3652        0.0050  0.1961\n",
      "    212      311.8829      599.4715        0.0049  0.2980\n",
      "    213      324.9633      542.2666        0.0045  0.2015\n",
      "    214      331.3018      563.5278        0.0040  0.1975\n",
      "    215      324.1625      \u001b[32m530.1507\u001b[0m     +  0.0033  0.2943\n",
      "    216      311.3366      669.4748        0.0025  0.2026\n",
      "    217      295.8032      625.2922        0.0017  0.2981\n",
      "    218      289.6536      598.9932        0.0010  0.1979\n",
      "    219      \u001b[36m287.7834\u001b[0m      589.8335        0.0005  0.2943\n",
      "    220      \u001b[36m285.5091\u001b[0m      594.8554        0.0001  0.2450\n",
      "    221      298.6374      620.8355        0.0050  0.4954\n",
      "    222      310.2603      565.3182        0.0049  0.2859\n",
      "    223      320.1569      557.9129        0.0045  0.2070\n",
      "    224      326.1126      544.8869        0.0040  0.2915\n",
      "    225      326.1105      537.8777        0.0033  0.2140\n",
      "    226      310.7162      668.2029        0.0025  0.2927\n",
      "    227      292.2099      614.1243        0.0017  0.2081\n",
      "    228      289.3756      614.4521        0.0010  0.2932\n",
      "    229      \u001b[36m284.7527\u001b[0m      594.6714        0.0005  0.2140\n",
      "    230      \u001b[36m282.8867\u001b[0m      596.8205        0.0001  0.2953\n",
      "    231      294.6289      583.8920        0.0050  0.2080\n",
      "    232      304.4978      589.0397        0.0049  0.1969\n",
      "    233      318.9621      550.1527        0.0045  0.2986\n",
      "    234      321.5651      562.8521        0.0040  0.2026\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m894.0939\u001b[0m     \u001b[32m1129.9375\u001b[0m     +  0.0050  0.2259\n",
      "      2      \u001b[36m821.9758\u001b[0m     1133.0829        0.0049  0.3005\n",
      "      3      \u001b[36m684.1579\u001b[0m      \u001b[32m974.7987\u001b[0m     +  0.0045  0.2114\n",
      "      4      695.1314     1018.5683        0.0040  0.3007\n",
      "      5      \u001b[36m632.4064\u001b[0m      \u001b[32m949.0864\u001b[0m     +  0.0033  0.2049\n",
      "      6      \u001b[36m608.4240\u001b[0m      \u001b[32m925.7272\u001b[0m     +  0.0025  0.2978\n",
      "      7      \u001b[36m573.3171\u001b[0m      \u001b[32m900.0200\u001b[0m     +  0.0017  0.1961\n",
      "      8      \u001b[36m550.0296\u001b[0m      \u001b[32m883.3263\u001b[0m     +  0.0010  0.2985\n",
      "      9      \u001b[36m535.2365\u001b[0m      \u001b[32m874.3786\u001b[0m     +  0.0005  0.2019\n",
      "     10      \u001b[36m528.2080\u001b[0m      \u001b[32m871.7384\u001b[0m     +  0.0001  0.2005\n",
      "     11      612.9093      \u001b[32m837.9819\u001b[0m     +  0.0050  0.2930\n",
      "     12      662.6746     1004.9951        0.0049  0.1913\n",
      "     13      532.6718      \u001b[32m806.0933\u001b[0m     +  0.0045  0.2967\n",
      "     14      \u001b[36m500.6116\u001b[0m      \u001b[32m805.3344\u001b[0m     +  0.0040  0.2019\n",
      "     15      \u001b[36m485.9322\u001b[0m      \u001b[32m783.6962\u001b[0m     +  0.0033  0.1979\n",
      "     16      \u001b[36m463.7435\u001b[0m      \u001b[32m766.6462\u001b[0m     +  0.0025  0.3072\n",
      "     17      \u001b[36m454.1327\u001b[0m      \u001b[32m756.0034\u001b[0m     +  0.0017  0.1981\n",
      "     18      \u001b[36m445.5637\u001b[0m      \u001b[32m750.7374\u001b[0m     +  0.0010  0.3145\n",
      "     19      \u001b[36m440.8538\u001b[0m      \u001b[32m748.1676\u001b[0m     +  0.0005  0.1942\n",
      "     20      \u001b[36m438.3572\u001b[0m      \u001b[32m747.5077\u001b[0m     +  0.0001  0.2965\n",
      "     21      476.7837      770.1556        0.0050  0.2004\n",
      "     22      520.0609      818.2539        0.0049  0.3182\n",
      "     23      495.7189      770.0920        0.0045  0.1993\n",
      "     24      450.6113      \u001b[32m731.8393\u001b[0m     +  0.0040  0.1968\n",
      "     25      439.4059      \u001b[32m728.8844\u001b[0m     +  0.0033  0.2860\n",
      "     26      \u001b[36m430.1309\u001b[0m      \u001b[32m719.9074\u001b[0m     +  0.0025  0.1943\n",
      "     27      \u001b[36m421.0326\u001b[0m      \u001b[32m713.1610\u001b[0m     +  0.0017  0.2968\n",
      "     28      \u001b[36m415.4839\u001b[0m      \u001b[32m711.4338\u001b[0m     +  0.0010  0.1949\n",
      "     29      \u001b[36m411.8943\u001b[0m      \u001b[32m711.0977\u001b[0m     +  0.0005  0.2879\n",
      "     30      \u001b[36m409.9357\u001b[0m      \u001b[32m711.0721\u001b[0m     +  0.0001  0.1972\n",
      "     31      438.3827      736.5302        0.0050  0.1993\n",
      "     32      476.8819      770.9987        0.0049  0.3008\n",
      "     33      473.4943      735.1302        0.0045  0.1972\n",
      "     34      434.2255      \u001b[32m699.9610\u001b[0m     +  0.0040  0.3141\n",
      "     35      416.4854      \u001b[32m699.3361\u001b[0m     +  0.0033  0.2040\n",
      "     36      411.7970      \u001b[32m695.1204\u001b[0m     +  0.0025  0.2991\n",
      "     37      \u001b[36m402.6313\u001b[0m      \u001b[32m693.2840\u001b[0m     +  0.0017  0.2082\n",
      "     38      \u001b[36m398.3112\u001b[0m      693.4798        0.0010  0.2993\n",
      "     39      \u001b[36m394.9053\u001b[0m      693.6863        0.0005  0.2080\n",
      "     40      \u001b[36m393.1573\u001b[0m      693.8736        0.0001  0.1970\n",
      "     41      418.3106      715.6791        0.0050  0.3018\n",
      "     42      457.1276      757.3603        0.0049  0.2122\n",
      "     43      463.1414      715.6879        0.0045  0.4202\n",
      "     44      424.1431      \u001b[32m683.1680\u001b[0m     +  0.0040  0.2506\n",
      "     45      403.6211      684.5101        0.0033  0.2959\n",
      "     46      400.9582      684.4448        0.0025  0.2005\n",
      "     47      \u001b[36m392.0320\u001b[0m      683.7568        0.0017  0.2079\n",
      "     48      \u001b[36m388.2613\u001b[0m      685.5212        0.0010  0.2941\n",
      "     49      \u001b[36m385.0666\u001b[0m      686.3571        0.0005  0.2095\n",
      "     50      \u001b[36m383.4734\u001b[0m      686.7636        0.0001  0.3004\n",
      "     51      406.7338      706.7181        0.0050  0.2045\n",
      "     52      443.8485      744.9355        0.0049  0.2951\n",
      "     53      451.4896      702.5771        0.0045  0.1937\n",
      "     54      414.9900      \u001b[32m676.6602\u001b[0m     +  0.0040  0.2032\n",
      "     55      394.5886      \u001b[32m675.9640\u001b[0m     +  0.0033  0.2973\n",
      "     56      392.7834      676.3538        0.0025  0.1978\n",
      "     57      383.7329      \u001b[32m675.5469\u001b[0m     +  0.0017  0.2954\n",
      "     58      \u001b[36m380.1216\u001b[0m      679.6798        0.0010  0.1980\n",
      "     59      \u001b[36m376.8892\u001b[0m      681.1746        0.0005  0.2994\n",
      "     60      \u001b[36m375.3550\u001b[0m      681.8128        0.0001  0.1981\n",
      "     61      398.1446      694.3231        0.0050  0.2964\n",
      "     62      435.2618      721.9228        0.0049  0.2186\n",
      "     63      446.1586      698.0132        0.0045  0.2449\n",
      "     64      410.6369      \u001b[32m660.4976\u001b[0m     +  0.0040  0.3031\n",
      "     65      386.4550      675.3622        0.0033  0.1921\n",
      "     66      385.8582      661.2682        0.0025  0.2921\n",
      "     67      377.0158      670.9498        0.0017  0.2070\n",
      "     68      \u001b[36m373.5514\u001b[0m      675.7842        0.0010  0.2961\n",
      "     69      \u001b[36m370.3821\u001b[0m      676.6313        0.0005  0.1972\n",
      "     70      \u001b[36m368.9394\u001b[0m      677.3619        0.0001  0.2959\n",
      "     71      390.6266      685.9556        0.0050  0.1955\n",
      "     72      425.4965      713.9918        0.0049  0.1998\n",
      "     73      438.8604      679.6903        0.0045  0.2969\n",
      "     74      405.5444      \u001b[32m653.7727\u001b[0m     +  0.0040  0.1991\n",
      "     75      379.7909      665.2820        0.0033  0.2984\n",
      "     76      379.4278      661.8542        0.0025  0.2079\n",
      "     77      371.1185      665.6783        0.0017  0.3072\n",
      "     78      \u001b[36m367.5125\u001b[0m      674.3826        0.0010  0.1996\n",
      "     79      \u001b[36m364.4860\u001b[0m      675.9667        0.0005  0.3031\n",
      "     80      \u001b[36m363.1158\u001b[0m      676.7316        0.0001  0.2051\n",
      "     81      384.7162      677.2726        0.0050  0.1911\n",
      "     82      418.4090      700.3850        0.0049  0.3084\n",
      "     83      435.1315      680.4827        0.0045  0.2159\n",
      "     84      401.0696      \u001b[32m646.9127\u001b[0m     +  0.0040  0.2983\n",
      "     85      374.6252      667.3454        0.0033  0.1980\n",
      "     86      374.7851      654.1955        0.0025  0.3100\n",
      "     87      366.6032      665.8870        0.0017  0.2058\n",
      "     88      363.2423      673.5867        0.0010  0.2994\n",
      "     89      \u001b[36m360.2063\u001b[0m      673.9715        0.0005  0.1967\n",
      "     90      \u001b[36m358.9190\u001b[0m      674.7458        0.0001  0.2083\n",
      "     91      379.7357      664.0078        0.0050  0.3244\n",
      "     92      410.5670      684.9986        0.0049  0.2070\n",
      "     93      426.4075      662.0403        0.0045  0.3093\n",
      "     94      396.5546      \u001b[32m636.3420\u001b[0m     +  0.0040  0.1991\n",
      "     95      370.0702      663.0094        0.0033  0.3010\n",
      "     96      369.6951      645.5027        0.0025  0.2110\n",
      "     97      362.2194      658.3108        0.0017  0.3085\n",
      "     98      \u001b[36m358.4359\u001b[0m      664.7311        0.0010  0.2022\n",
      "     99      \u001b[36m355.4881\u001b[0m      664.5530        0.0005  0.1946\n",
      "    100      \u001b[36m354.1716\u001b[0m      665.2807        0.0001  0.3097\n",
      "    101      374.9851      645.7983        0.0050  0.1997\n",
      "    102      402.9229      657.7398        0.0049  0.3125\n",
      "    103      424.3758      659.8741        0.0045  0.2189\n",
      "    104      396.0825      \u001b[32m599.3945\u001b[0m     +  0.0040  0.2980\n",
      "    105      365.0049      636.6491        0.0033  0.1962\n",
      "    106      359.6766      607.2693        0.0025  0.2996\n",
      "    107      \u001b[36m353.5879\u001b[0m      631.3995        0.0017  0.2043\n",
      "    108      \u001b[36m346.7776\u001b[0m      628.0746        0.0010  0.2062\n",
      "    109      \u001b[36m344.1390\u001b[0m      632.1358        0.0005  0.3010\n",
      "    110      \u001b[36m342.4435\u001b[0m      633.4526        0.0001  0.1985\n",
      "    111      365.3515      622.2791        0.0050  0.3076\n",
      "    112      393.2730      643.7791        0.0049  0.2153\n",
      "    113      417.6047      660.3819        0.0045  0.2942\n",
      "    114      396.0498      \u001b[32m594.8451\u001b[0m     +  0.0040  0.1981\n",
      "    115      357.3033      625.1244        0.0033  0.2958\n",
      "    116      352.0531      608.0830        0.0025  0.1983\n",
      "    117      347.5126      620.9962        0.0017  0.1987\n",
      "    118      \u001b[36m340.5230\u001b[0m      624.4268        0.0010  0.2881\n",
      "    119      \u001b[36m337.8160\u001b[0m      627.0271        0.0005  0.1944\n",
      "    120      \u001b[36m336.3114\u001b[0m      628.0254        0.0001  0.3431\n",
      "    121      357.8754      609.8283        0.0050  0.5210\n",
      "    122      381.4485      633.5090        0.0049  0.5051\n",
      "    123      402.6904      613.2679        0.0045  0.2761\n",
      "    124      386.8792      \u001b[32m571.6986\u001b[0m     +  0.0040  0.3333\n",
      "    125      351.5596      614.2198        0.0033  0.1948\n",
      "    126      340.9595      602.9880        0.0025  0.2033\n",
      "    127      337.5963      608.9540        0.0017  0.2973\n",
      "    128      \u001b[36m331.6574\u001b[0m      614.9423        0.0010  0.1999\n",
      "    129      \u001b[36m329.2163\u001b[0m      620.4781        0.0005  0.2945\n",
      "    130      \u001b[36m327.6200\u001b[0m      620.9810        0.0001  0.2076\n",
      "    131      350.1946      603.8922        0.0050  0.2924\n",
      "    132      372.4293      616.6829        0.0049  0.1920\n",
      "    133      395.5479      613.9957        0.0045  0.2926\n",
      "    134      382.8703      \u001b[32m562.4359\u001b[0m     +  0.0040  0.1986\n",
      "    135      345.4515      614.7353        0.0033  0.1976\n",
      "    136      333.7396      601.0008        0.0025  0.3283\n",
      "    137      330.9049      607.0071        0.0017  0.3479\n",
      "    138      \u001b[36m325.1891\u001b[0m      614.1054        0.0010  0.3971\n",
      "    139      \u001b[36m322.5576\u001b[0m      619.3840        0.0005  0.2636\n",
      "    140      \u001b[36m321.0599\u001b[0m      619.2205        0.0001  0.3958\n",
      "    141      343.2897      596.4788        0.0050  0.5316\n",
      "    142      363.8282      610.8489        0.0049  0.4365\n",
      "    143      383.9533      595.4406        0.0045  0.2100\n",
      "    144      379.6239      565.8181        0.0040  0.2161\n",
      "    145      345.7320      611.4656        0.0033  0.3112\n",
      "    146      328.2697      626.2130        0.0025  0.2001\n",
      "    147      324.6149      610.1565        0.0017  0.2914\n",
      "    148      \u001b[36m319.6404\u001b[0m      612.8877        0.0010  0.1999\n",
      "    149      \u001b[36m316.8946\u001b[0m      619.2575        0.0005  0.2995\n",
      "    150      \u001b[36m315.4894\u001b[0m      618.6291        0.0001  0.2019\n",
      "    151      337.0184      593.0147        0.0050  0.3107\n",
      "    152      354.8359      597.9299        0.0049  0.2052\n",
      "    153      374.9359      596.1198        0.0045  0.2012\n",
      "    154      377.2292      \u001b[32m561.3457\u001b[0m     +  0.0040  0.2960\n",
      "    155      344.2186      608.2740        0.0033  0.1998\n",
      "    156      323.7923      642.5233        0.0025  0.3089\n",
      "    157      319.4695      613.7364        0.0017  0.2080\n",
      "    158      \u001b[36m315.4413\u001b[0m      617.8259        0.0010  0.3002\n",
      "    159      \u001b[36m312.3356\u001b[0m      624.3799        0.0005  0.2124\n",
      "    160      \u001b[36m311.0010\u001b[0m      622.8453        0.0001  0.3061\n",
      "    161      331.6865      588.4114        0.0050  0.2103\n",
      "    162      345.4698      585.4975        0.0049  0.2123\n",
      "    163      362.3567      581.1532        0.0045  0.2979\n",
      "    164      365.7139      568.3110        0.0040  0.1997\n",
      "    165      343.9390      590.4861        0.0033  0.3001\n",
      "    166      321.8108      668.7678        0.0025  0.2064\n",
      "    167      314.6742      632.5788        0.0017  0.2977\n",
      "    168      311.7922      635.8577        0.0010  0.1981\n",
      "    169      \u001b[36m307.7983\u001b[0m      638.0793        0.0005  0.2989\n",
      "    170      \u001b[36m306.5097\u001b[0m      635.5447        0.0001  0.1912\n",
      "    171      326.3248      589.2855        0.0050  0.2085\n",
      "    172      337.5487      588.6768        0.0049  0.3275\n",
      "    173      351.1423      565.6878        0.0045  0.2006\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m886.7168\u001b[0m     \u001b[32m1024.5234\u001b[0m     +  0.0050  0.3526\n",
      "      2      \u001b[36m869.6568\u001b[0m     1222.2506        0.0049  0.6589\n",
      "      3      \u001b[36m671.6248\u001b[0m      \u001b[32m935.5546\u001b[0m     +  0.0045  0.3270\n",
      "      4      699.9129     1050.0088        0.0040  0.3041\n",
      "      5      \u001b[36m607.8704\u001b[0m      \u001b[32m926.1559\u001b[0m     +  0.0033  0.2062\n",
      "      6      \u001b[36m585.6294\u001b[0m      \u001b[32m924.6611\u001b[0m     +  0.0025  0.3008\n",
      "      7      \u001b[36m544.4594\u001b[0m      \u001b[32m890.7974\u001b[0m     +  0.0017  0.1969\n",
      "      8      \u001b[36m523.8073\u001b[0m      \u001b[32m870.3273\u001b[0m     +  0.0010  0.3004\n",
      "      9      \u001b[36m509.4596\u001b[0m      \u001b[32m861.8204\u001b[0m     +  0.0005  0.2048\n",
      "     10      \u001b[36m502.7112\u001b[0m      \u001b[32m859.2593\u001b[0m     +  0.0001  0.2008\n",
      "     11      586.5797      \u001b[32m830.7301\u001b[0m     +  0.0050  0.3091\n",
      "     12      686.8693     1030.3817        0.0049  0.2038\n",
      "     13      560.6541      834.3651        0.0045  0.2943\n",
      "     14      \u001b[36m493.3438\u001b[0m      \u001b[32m824.8563\u001b[0m     +  0.0040  0.1988\n",
      "     15      \u001b[36m491.0407\u001b[0m      \u001b[32m813.3166\u001b[0m     +  0.0033  0.2047\n",
      "     16      \u001b[36m466.9589\u001b[0m      \u001b[32m789.7009\u001b[0m     +  0.0025  0.2972\n",
      "     17      \u001b[36m457.9540\u001b[0m      \u001b[32m781.0625\u001b[0m     +  0.0017  0.1980\n",
      "     18      \u001b[36m448.9377\u001b[0m      \u001b[32m776.9399\u001b[0m     +  0.0010  0.2954\n",
      "     19      \u001b[36m444.3706\u001b[0m      \u001b[32m775.0119\u001b[0m     +  0.0005  0.1979\n",
      "     20      \u001b[36m441.8529\u001b[0m      \u001b[32m774.5412\u001b[0m     +  0.0001  0.3034\n",
      "     21      482.5682      794.2104        0.0050  0.1987\n",
      "     22      531.9921      841.6908        0.0049  0.2967\n",
      "     23      506.5822      796.6430        0.0045  0.2064\n",
      "     24      457.3084      \u001b[32m759.9499\u001b[0m     +  0.0040  0.1964\n",
      "     25      446.5721      \u001b[32m749.5370\u001b[0m     +  0.0033  0.2930\n",
      "     26      \u001b[36m436.2922\u001b[0m      753.2718        0.0025  0.2032\n",
      "     27      \u001b[36m426.7411\u001b[0m      \u001b[32m741.5046\u001b[0m     +  0.0017  0.2929\n",
      "     28      \u001b[36m420.3950\u001b[0m      \u001b[32m737.6747\u001b[0m     +  0.0010  0.2069\n",
      "     29      \u001b[36m416.5384\u001b[0m      \u001b[32m736.9904\u001b[0m     +  0.0005  0.3094\n",
      "     30      \u001b[36m414.4686\u001b[0m      \u001b[32m736.9762\u001b[0m     +  0.0001  0.1972\n",
      "     31      446.5954      755.1547        0.0050  0.2032\n",
      "     32      491.9333      790.0225        0.0049  0.3078\n",
      "     33      483.9453      770.4123        0.0045  0.2095\n",
      "     34      441.0641      \u001b[32m727.5479\u001b[0m     +  0.0040  0.3066\n",
      "     35      422.9777      \u001b[32m725.9077\u001b[0m     +  0.0033  0.2037\n",
      "     36      417.3170      \u001b[32m717.1563\u001b[0m     +  0.0025  0.2957\n",
      "     37      \u001b[36m407.2327\u001b[0m      \u001b[32m715.2626\u001b[0m     +  0.0017  0.2022\n",
      "     38      \u001b[36m402.3356\u001b[0m      715.3612        0.0010  0.2896\n",
      "     39      \u001b[36m398.7805\u001b[0m      715.8686        0.0005  0.1998\n",
      "     40      \u001b[36m396.9130\u001b[0m      716.1793        0.0001  0.1999\n",
      "     41      425.3501      737.1677        0.0050  0.3069\n",
      "     42      469.0871      765.5454        0.0049  0.1994\n",
      "     43      469.0820      740.9981        0.0045  0.3953\n",
      "     44      427.9395      \u001b[32m706.0086\u001b[0m     +  0.0040  0.2318\n",
      "     45      407.2615      \u001b[32m698.6677\u001b[0m     +  0.0033  0.2936\n",
      "     46      403.7135      \u001b[32m696.8512\u001b[0m     +  0.0025  0.1982\n",
      "     47      \u001b[36m393.5753\u001b[0m      \u001b[32m695.4748\u001b[0m     +  0.0017  0.2109\n",
      "     48      \u001b[36m389.4335\u001b[0m      698.6922        0.0010  0.2920\n",
      "     49      \u001b[36m385.8870\u001b[0m      699.7965        0.0005  0.1992\n",
      "     50      \u001b[36m384.1424\u001b[0m      700.2428        0.0001  0.3151\n",
      "     51      410.9688      713.2432        0.0050  0.1985\n",
      "     52      452.7040      748.6357        0.0049  0.3012\n",
      "     53      459.3277      727.0859        0.0045  0.2043\n",
      "     54      418.7308      \u001b[32m686.9665\u001b[0m     +  0.0040  0.2244\n",
      "     55      395.7302      687.3168        0.0033  0.2887\n",
      "     56      394.4179      \u001b[32m682.7141\u001b[0m     +  0.0025  0.1965\n",
      "     57      \u001b[36m384.0680\u001b[0m      685.6073        0.0017  0.2997\n",
      "     58      \u001b[36m380.1432\u001b[0m      689.6800        0.0010  0.1979\n",
      "     59      \u001b[36m376.6638\u001b[0m      690.7531        0.0005  0.2968\n",
      "     60      \u001b[36m375.0390\u001b[0m      691.4310        0.0001  0.2000\n",
      "     61      400.2148      697.7889        0.0050  0.2992\n",
      "     62      440.0387      724.5609        0.0049  0.2085\n",
      "     63      450.1718      713.5085        0.0045  0.3044\n",
      "     64      412.9744      \u001b[32m671.3102\u001b[0m     +  0.0040  0.2990\n",
      "     65      386.5299      676.9628        0.0033  0.1971\n",
      "     66      386.5028      673.1071        0.0025  0.2984\n",
      "     67      376.4637      677.3791        0.0017  0.1993\n",
      "     68      \u001b[36m372.5798\u001b[0m      684.3506        0.0010  0.3082\n",
      "     69      \u001b[36m369.1439\u001b[0m      685.5541        0.0005  0.2058\n",
      "     70      \u001b[36m367.6577\u001b[0m      686.2956        0.0001  0.2891\n",
      "     71      391.7908      687.0188        0.0050  0.2255\n",
      "     72      428.2300      706.3673        0.0049  0.2011\n",
      "     73      440.9455      694.6989        0.0045  0.3003\n",
      "     74      407.4942      \u001b[32m659.8806\u001b[0m     +  0.0040  0.1962\n",
      "     75      379.0192      666.5840        0.0033  0.3208\n",
      "     76      378.2671      663.8543        0.0025  0.2573\n",
      "     77      369.7562      671.5175        0.0017  0.3142\n",
      "     78      \u001b[36m365.4364\u001b[0m      676.8124        0.0010  0.1912\n",
      "     79      \u001b[36m362.2303\u001b[0m      678.0499        0.0005  0.2894\n",
      "     80      \u001b[36m360.7829\u001b[0m      678.9613        0.0001  0.1983\n",
      "     81      384.5423      675.9790        0.0050  0.1925\n",
      "     82      417.1025      690.0430        0.0049  0.3070\n",
      "     83      432.1802      681.8424        0.0045  0.2187\n",
      "     84      405.5062      \u001b[32m647.2126\u001b[0m     +  0.0040  0.3180\n",
      "     85      372.5824      660.1569        0.0033  0.2036\n",
      "     86      369.8777      654.1639        0.0025  0.3005\n",
      "     87      363.2232      665.4121        0.0017  0.2071\n",
      "     88      \u001b[36m358.2189\u001b[0m      668.7940        0.0010  0.2902\n",
      "     89      \u001b[36m355.4030\u001b[0m      670.3822        0.0005  0.2027\n",
      "     90      \u001b[36m353.9397\u001b[0m      671.3657        0.0001  0.1988\n",
      "     91      377.9269      664.0544        0.0050  0.3023\n",
      "     92      406.3665      683.7886        0.0049  0.2095\n",
      "     93      424.5726      661.7615        0.0045  0.2968\n",
      "     94      403.3512      \u001b[32m629.5346\u001b[0m     +  0.0040  0.2080\n",
      "     95      367.2958      641.4103        0.0033  0.2965\n",
      "     96      362.1159      630.3796        0.0025  0.1998\n",
      "     97      357.3006      647.2824        0.0017  0.2926\n",
      "     98      \u001b[36m350.9438\u001b[0m      640.6383        0.0010  0.2442\n",
      "     99      \u001b[36m348.1581\u001b[0m      645.9738        0.0005  0.2141\n",
      "    100      \u001b[36m346.3524\u001b[0m      646.8054        0.0001  0.2942\n",
      "    101      371.7066      632.3161        0.0050  0.2006\n",
      "    102      396.5275      653.6510        0.0049  0.3114\n",
      "    103      409.9924      652.5623        0.0045  0.2041\n",
      "    104      407.7804      652.9362        0.0040  0.3201\n",
      "    105      370.7734      661.5201        0.0033  0.2057\n",
      "    106      359.8092      661.1127        0.0025  0.2895\n",
      "    107      357.8004      669.9107        0.0017  0.1932\n",
      "    108      350.7634      665.7627        0.0010  0.1990\n",
      "    109      348.2768      669.3395        0.0005  0.2912\n",
      "    110      346.7408      670.4363        0.0001  0.2003\n",
      "    111      368.4342      639.0429        0.0050  0.3042\n",
      "    112      388.3028      633.8254        0.0049  0.1989\n",
      "    113      406.1044      \u001b[32m627.7157\u001b[0m     +  0.0045  0.2976\n",
      "    114      390.5369      \u001b[32m582.7602\u001b[0m     +  0.0040  0.2066\n",
      "    115      358.8506      622.7128        0.0033  0.3153\n",
      "    116      \u001b[36m345.8938\u001b[0m      603.3435        0.0025  0.2009\n",
      "    117      \u001b[36m342.2098\u001b[0m      610.1927        0.0017  0.2062\n",
      "    118      \u001b[36m334.4240\u001b[0m      613.9878        0.0010  0.2971\n",
      "    119      \u001b[36m331.4180\u001b[0m      617.7230        0.0005  0.2036\n",
      "    120      \u001b[36m329.6920\u001b[0m      618.2805        0.0001  0.3024\n",
      "    121      358.2351      606.0840        0.0050  0.2076\n",
      "    122      378.4514      627.2653        0.0049  0.2995\n",
      "    123      395.0576      617.8678        0.0045  0.2345\n",
      "    124      386.8856      \u001b[32m582.1122\u001b[0m     +  0.0040  0.3037\n",
      "    125      354.8417      611.9522        0.0033  0.1908\n",
      "    126      340.0552      604.2724        0.0025  0.2002\n",
      "    127      333.7601      598.4656        0.0017  0.2973\n",
      "    128      \u001b[36m326.6021\u001b[0m      607.2498        0.0010  0.2216\n",
      "    129      \u001b[36m323.6412\u001b[0m      610.2339        0.0005  0.3047\n",
      "    130      \u001b[36m321.9577\u001b[0m      610.4392        0.0001  0.2041\n",
      "    131      350.0538      602.9845        0.0050  0.3117\n",
      "    132      368.8506      607.7791        0.0049  0.1998\n",
      "    133      385.1672      608.9573        0.0045  0.2971\n",
      "    134      384.4784      \u001b[32m574.6124\u001b[0m     +  0.0040  0.2065\n",
      "    135      356.0507      598.2792        0.0033  0.1989\n",
      "    136      331.8125      629.0956        0.0025  0.3080\n",
      "    137      326.6862      608.6732        0.0017  0.1980\n",
      "    138      \u001b[36m320.6937\u001b[0m      608.0677        0.0010  0.2999\n",
      "    139      \u001b[36m317.5307\u001b[0m      613.8701        0.0005  0.2038\n",
      "    140      \u001b[36m315.9412\u001b[0m      613.4960        0.0001  0.3062\n",
      "    141      341.5739      593.5966        0.0050  0.2130\n",
      "    142      357.4878      595.5304        0.0049  0.3368\n",
      "    143      373.5078      590.1407        0.0045  0.2231\n",
      "    144      376.8880      575.2312        0.0040  0.2566\n",
      "    145      348.0483      592.0670        0.0033  0.3175\n",
      "    146      329.8827      640.4533        0.0025  0.2073\n",
      "    147      319.9101      613.5484        0.0017  0.4267\n",
      "    148      \u001b[36m315.1059\u001b[0m      613.8450        0.0010  0.2625\n",
      "    149      \u001b[36m311.8395\u001b[0m      615.3651        0.0005  0.6271\n",
      "    150      \u001b[36m310.3983\u001b[0m      614.5249        0.0001  0.3660\n",
      "    151      335.0488      595.5067        0.0050  0.5641\n",
      "    152      347.6300      585.0006        0.0049  0.1998\n",
      "    153      360.6031      586.1383        0.0045  0.1939\n",
      "Stopping since valid_loss has not improved in the last 20 epochs.\n",
      "Training ridge\n",
      "Training rf\n",
      "Training xgb\n",
      "Training mlp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss    cp      lr     dur\n",
      "-------  ------------  ------------  ----  ------  ------\n",
      "      1      \u001b[36m854.0749\u001b[0m     \u001b[32m1053.2990\u001b[0m     +  0.0050  0.4416\n",
      "      2      \u001b[36m820.4166\u001b[0m     1133.6939        0.0049  0.3479\n",
      "      3      \u001b[36m648.8961\u001b[0m      \u001b[32m929.2133\u001b[0m     +  0.0045  0.4662\n",
      "      4      668.4168      993.6787        0.0040  0.5671\n",
      "      5      \u001b[36m603.2477\u001b[0m      \u001b[32m922.2552\u001b[0m     +  0.0033  0.4467\n",
      "      6      \u001b[36m581.7209\u001b[0m      \u001b[32m899.8526\u001b[0m     +  0.0025  0.4093\n",
      "      7      \u001b[36m547.8443\u001b[0m      \u001b[32m879.4504\u001b[0m     +  0.0017  0.3063\n",
      "      8      \u001b[36m527.2588\u001b[0m      \u001b[32m861.8316\u001b[0m     +  0.0010  0.6419\n",
      "      9      \u001b[36m514.6077\u001b[0m      \u001b[32m854.2328\u001b[0m     +  0.0005  0.2910\n",
      "     10      \u001b[36m508.3729\u001b[0m      \u001b[32m852.1529\u001b[0m     +  0.0001  0.4044\n",
      "     11      582.7976      \u001b[32m851.3311\u001b[0m     +  0.0050  0.5965\n",
      "     12      633.0474      955.8697        0.0049  0.3769\n",
      "     13      537.2811      \u001b[32m849.4272\u001b[0m     +  0.0045  0.4491\n",
      "     14      \u001b[36m499.9467\u001b[0m      \u001b[32m816.0404\u001b[0m     +  0.0040  0.5221\n",
      "     15      \u001b[36m480.9287\u001b[0m      \u001b[32m788.7302\u001b[0m     +  0.0033  0.6152\n",
      "     16      \u001b[36m459.7814\u001b[0m      \u001b[32m768.2985\u001b[0m     +  0.0025  0.4191\n",
      "     17      \u001b[36m449.2250\u001b[0m      \u001b[32m760.7062\u001b[0m     +  0.0017  0.4161\n",
      "     18      \u001b[36m441.1021\u001b[0m      \u001b[32m756.6250\u001b[0m     +  0.0010  0.6270\n",
      "     19      \u001b[36m436.4799\u001b[0m      \u001b[32m754.5176\u001b[0m     +  0.0005  0.6956\n",
      "     20      \u001b[36m433.9970\u001b[0m      \u001b[32m753.9768\u001b[0m     +  0.0001  0.6990\n",
      "     21      472.8838      785.5123        0.0050  0.5146\n",
      "     22      521.5992      837.3791        0.0049  0.5459\n",
      "     23      501.7533      787.2880        0.0045  0.3129\n",
      "     24      451.9790      \u001b[32m744.8742\u001b[0m     +  0.0040  0.4007\n",
      "     25      438.7358      744.9596        0.0033  0.2308\n",
      "     26      \u001b[36m429.9273\u001b[0m      \u001b[32m731.1399\u001b[0m     +  0.0025  0.2706\n",
      "     27      \u001b[36m419.9235\u001b[0m      \u001b[32m727.1429\u001b[0m     +  0.0017  0.4073\n",
      "     28      \u001b[36m414.3962\u001b[0m      \u001b[32m726.3703\u001b[0m     +  0.0010  0.3576\n",
      "     29      \u001b[36m410.7027\u001b[0m      \u001b[32m726.0370\u001b[0m     +  0.0005  0.4186\n",
      "     30      \u001b[36m408.6749\u001b[0m      \u001b[32m725.9583\u001b[0m     +  0.0001  0.3106\n",
      "     31      438.2064      763.0799        0.0050  0.3979\n",
      "     32      481.0438      797.1577        0.0049  0.2966\n",
      "     33      475.8019      750.9743        0.0045  0.3928\n",
      "     34      433.4056      \u001b[32m716.8328\u001b[0m     +  0.0040  0.7691\n",
      "     35      417.7992      \u001b[32m715.4120\u001b[0m     +  0.0033  0.4998\n",
      "     36      412.3403      \u001b[32m706.4322\u001b[0m     +  0.0025  0.4320\n",
      "     37      \u001b[36m402.4405\u001b[0m      \u001b[32m705.4401\u001b[0m     +  0.0017  0.2919\n",
      "     38      \u001b[36m397.9026\u001b[0m      706.6929        0.0010  0.3758\n",
      "     39      \u001b[36m394.3890\u001b[0m      707.1866        0.0005  0.2580\n",
      "     40      \u001b[36m392.5325\u001b[0m      707.4419        0.0001  0.4093\n",
      "     41      419.6423      751.2787        0.0050  0.2469\n",
      "     42      462.6149      781.1189        0.0049  0.2813\n",
      "     43      466.0304      734.6289        0.0045  0.3808\n",
      "     44      421.3509      \u001b[32m701.5421\u001b[0m     +  0.0040  0.2562\n",
      "     45      404.5816      702.4303        0.0033  0.3416\n",
      "     46      400.8126      \u001b[32m699.1358\u001b[0m     +  0.0025  0.2804\n",
      "     47      \u001b[36m390.9780\u001b[0m      \u001b[32m697.2402\u001b[0m     +  0.0017  0.3990\n",
      "     48      \u001b[36m386.8677\u001b[0m      700.7293        0.0010  0.2473\n",
      "     49      \u001b[36m383.5451\u001b[0m      703.0988        0.0005  0.2392\n",
      "     50      \u001b[36m381.8215\u001b[0m      703.5974        0.0001  0.4102\n",
      "     51      406.9769      743.1931        0.0050  0.3088\n",
      "     52      446.9120      763.3896        0.0049  0.3995\n",
      "     53      451.3826      716.3515        0.0045  0.2416\n",
      "     54      411.5850      \u001b[32m692.8049\u001b[0m     +  0.0040  0.4294\n",
      "     55      394.4563      693.5757        0.0033  0.2482\n",
      "     56      391.4130      \u001b[32m690.2939\u001b[0m     +  0.0025  0.2678\n",
      "     57      382.0833      693.7227        0.0017  0.3938\n",
      "     58      \u001b[36m378.5305\u001b[0m      700.0504        0.0010  0.3434\n",
      "     59      \u001b[36m375.4418\u001b[0m      701.8352        0.0005  0.5236\n",
      "     60      \u001b[36m373.8737\u001b[0m      702.5123        0.0001  0.3238\n",
      "     61      397.4782      721.4073        0.0050  0.3713\n",
      "     62      434.4936      745.6723        0.0049  0.3044\n",
      "     63      444.1736      703.8951        0.0045  0.4327\n",
      "     64      406.1866      690.3917        0.0040  0.2750\n",
      "     65      386.5700      \u001b[32m687.5278\u001b[0m     +  0.0033  0.2590\n",
      "     66      384.5105      689.3853        0.0025  0.3468\n",
      "     67      375.5333      693.6973        0.0017  0.2385\n",
      "     68      \u001b[36m372.1689\u001b[0m      701.3225        0.0010  0.4412\n",
      "     69      \u001b[36m369.2477\u001b[0m      702.6560        0.0005  0.3253\n",
      "     70      \u001b[36m367.8293\u001b[0m      703.4763        0.0001  0.3750\n",
      "     71      390.5535      707.0374        0.0050  0.2604\n",
      "     72      423.7696      734.0412        0.0049  0.4571\n",
      "     73      435.6427      \u001b[32m686.5435\u001b[0m     +  0.0045  0.2930\n",
      "     74      404.1667      \u001b[32m685.1056\u001b[0m     +  0.0040  0.2865\n",
      "     75      379.4986      \u001b[32m670.7634\u001b[0m     +  0.0033  0.4118\n",
      "     76      376.9175      680.9561        0.0025  0.2682\n",
      "     77      369.3065      680.8665        0.0017  0.4031\n",
      "     78      \u001b[36m365.3865\u001b[0m      690.7380        0.0010  0.2781\n",
      "     79      \u001b[36m362.2907\u001b[0m      691.5785        0.0005  0.3975\n",
      "     80      \u001b[36m360.8121\u001b[0m      692.1370        0.0001  0.2818\n",
      "     81      384.7292      688.6428        0.0050  0.4064\n",
      "     82      414.0141      715.1122        0.0049  0.3481\n",
      "     83      429.7737      683.6087        0.0045  0.2591\n",
      "     84      400.6043      \u001b[32m656.9777\u001b[0m     +  0.0040  0.3974\n",
      "     85      374.3846      \u001b[32m654.5776\u001b[0m     +  0.0033  0.2739\n",
      "     86      367.6235      656.0653        0.0025  0.3775\n",
      "     87      361.1732      670.5500        0.0017  0.2578\n",
      "     88      \u001b[36m356.1452\u001b[0m      675.7070        0.0010  0.3724\n",
      "     89      \u001b[36m353.3615\u001b[0m      677.9665        0.0005  0.2417\n",
      "     90      \u001b[36m351.9003\u001b[0m      679.0169        0.0001  0.4231\n",
      "     91      375.4817      669.9461        0.0050  0.3057\n",
      "     92      401.2940      697.2839        0.0049  0.2673\n",
      "     93      420.5659      659.2683        0.0045  0.3649\n",
      "     94      400.1422      \u001b[32m644.5735\u001b[0m     +  0.0040  0.2742\n",
      "     95      366.5141      646.9937        0.0033  0.4371\n",
      "     96      358.0347      657.7078        0.0025  0.2816\n",
      "     97      353.7299      660.9255        0.0017  0.3744\n",
      "     98      \u001b[36m348.2677\u001b[0m      667.1419        0.0010  0.3315\n",
      "     99      \u001b[36m345.9649\u001b[0m      672.4236        0.0005  0.4476\n",
      "    100      \u001b[36m344.5059\u001b[0m      673.0979        0.0001  0.2340\n",
      "    101      367.5741      650.9015        0.0050  0.2514\n",
      "    102      389.2109      682.3172        0.0049  0.3682\n",
      "    103      408.3772      651.1501        0.0045  0.3169\n",
      "    104      395.2458      \u001b[32m627.9400\u001b[0m     +  0.0040  0.4270\n",
      "    105      362.9296      635.4615        0.0033  0.2608\n",
      "    106      350.9666      653.7189        0.0025  0.3572\n",
      "    107      346.2800      654.4600        0.0017  0.2787\n",
      "    108      \u001b[36m341.6260\u001b[0m      660.4869        0.0010  0.4581\n",
      "    109      \u001b[36m339.2398\u001b[0m      664.9779        0.0005  0.3009\n",
      "    110      \u001b[36m337.8627\u001b[0m      665.4315        0.0001  0.2755\n",
      "    111      360.6309      640.7385        0.0050  0.4556\n",
      "    112      377.4087      661.6813        0.0049  0.2397\n",
      "    113      398.7699      656.8702        0.0045  0.5255\n",
      "    114      395.0496      \u001b[32m615.4364\u001b[0m     +  0.0040  0.2606\n",
      "    115      358.5525      639.0998        0.0033  0.3468\n",
      "    116      344.1889      662.2881        0.0025  0.3524\n",
      "    117      340.0882      652.2166        0.0017  0.3514\n",
      "    118      \u001b[36m335.9500\u001b[0m      658.2465        0.0010  0.2120\n",
      "    119      \u001b[36m333.5978\u001b[0m      664.8718        0.0005  0.2488\n",
      "    120      \u001b[36m332.2450\u001b[0m      664.9636        0.0001  0.3638\n",
      "    121      353.7993      634.7757        0.0050  0.3514\n",
      "    122      367.5435      643.0670        0.0049  0.3940\n",
      "    123      386.0814      650.2554        0.0045  0.2421\n",
      "    124      388.1377      \u001b[32m610.9904\u001b[0m     +  0.0040  0.3684\n",
      "    125      358.0410      631.3074        0.0033  0.2396\n",
      "    126      339.8193      666.0888        0.0025  0.4817\n",
      "    127      334.1017      651.5157        0.0017  0.3492\n",
      "    128      \u001b[36m331.0395\u001b[0m      656.9194        0.0010  0.2855\n",
      "    129      \u001b[36m328.4073\u001b[0m      662.1398        0.0005  0.3337\n",
      "    130      \u001b[36m327.0992\u001b[0m      661.6839        0.0001  0.2796\n",
      "    131      348.9218      625.1317        0.0050  0.3624\n",
      "    132      359.7472      630.0357        0.0049  0.2323\n",
      "    133      374.3409      646.7131        0.0045  0.4801\n",
      "    134      382.8460      \u001b[32m606.9710\u001b[0m     +  0.0040  0.2810\n",
      "    135      356.9699      626.1040        0.0033  0.4408\n",
      "    136      335.8169      672.4747        0.0025  0.2325\n",
      "    137      328.6201      649.2186        0.0017  0.2182\n",
      "    138      \u001b[36m326.1119\u001b[0m      653.4120        0.0010  0.3936\n",
      "    139      \u001b[36m323.3373\u001b[0m      658.1879        0.0005  0.3051\n",
      "    140      \u001b[36m322.0466\u001b[0m      657.4575        0.0001  0.4141\n",
      "    141      343.7940      619.8906        0.0050  0.2860\n",
      "    142      351.7144      622.0537        0.0049  0.3839\n",
      "    143      362.7260      633.3605        0.0045  0.2383\n",
      "    144      374.3962      609.0245        0.0040  0.3539\n",
      "    145      354.7353      \u001b[32m603.6863\u001b[0m     +  0.0033  0.2451\n",
      "    146      333.7763      674.9988        0.0025  0.2377\n",
      "    147      323.5118      645.1503        0.0017  0.5415\n",
      "    148      \u001b[36m320.9873\u001b[0m      650.3532        0.0010  0.2859\n",
      "    149      \u001b[36m318.2470\u001b[0m      651.3898        0.0005  0.3385\n",
      "    150      \u001b[36m316.9777\u001b[0m      650.9771        0.0001  0.2300\n",
      "    151      338.0992      615.6707        0.0050  0.3392\n",
      "    152      347.1509      616.2934        0.0049  0.2539\n",
      "    153      357.8510      618.4671        0.0045  0.3768\n",
      "    154      368.0845      607.3359        0.0040  0.2414\n",
      "    155      355.6947      \u001b[32m586.2933\u001b[0m     +  0.0033  0.2401\n",
      "    156      333.1920      693.5144        0.0025  0.3316\n",
      "    157      319.5639      650.6907        0.0017  0.2703\n",
      "    158      317.2961      656.6735        0.0010  0.3490\n",
      "    159      \u001b[36m313.9187\u001b[0m      656.0833        0.0005  0.2543\n",
      "    160      \u001b[36m312.6089\u001b[0m      654.5607        0.0001  0.4225\n",
      "    161      334.0969      614.6718        0.0050  0.2210\n",
      "    162      340.0806      607.0807        0.0049  0.3472\n",
      "    163      352.9187      610.6770        0.0045  0.2364\n",
      "    164      359.8307      600.2545        0.0040  0.2321\n",
      "    165      357.6159      \u001b[32m582.1664\u001b[0m     +  0.0033  0.3215\n",
      "    166      333.3399      681.4104        0.0025  0.4014\n",
      "    167      317.1877      648.4196        0.0017  0.5682\n",
      "    168      314.9475      648.7400        0.0010  0.5280\n",
      "    169      \u001b[36m311.1152\u001b[0m      645.9576        0.0005  0.4389\n",
      "    170      \u001b[36m309.8295\u001b[0m      644.7255        0.0001  0.1991\n",
      "    171      328.1284      607.5483        0.0050  0.3059\n",
      "    172      335.7996      604.8396        0.0049  0.2209\n",
      "    173      346.8357      622.6371        0.0045  0.2723\n",
      "    174      353.0357      586.3794        0.0040  0.3725\n",
      "    175      349.8206      \u001b[32m577.3251\u001b[0m     +  0.0033  0.3200\n",
      "    176      326.9886      681.8304        0.0025  0.3553\n",
      "    177      311.9849      649.3755        0.0017  0.2433\n",
      "    178      \u001b[36m309.6247\u001b[0m      648.8929        0.0010  0.3293\n",
      "    179      \u001b[36m306.5550\u001b[0m      642.7046        0.0005  0.2580\n",
      "    180      \u001b[36m305.3421\u001b[0m      641.9379        0.0001  0.3220\n",
      "    181      323.8095      606.3853        0.0050  0.2083\n",
      "    182      331.4181      598.8192        0.0049  0.2418\n",
      "    183      340.0284      597.8922        0.0045  0.3405\n",
      "    184      346.3170      590.2186        0.0040  0.2248\n",
      "    185      343.2345      \u001b[32m567.0396\u001b[0m     +  0.0033  0.3239\n",
      "    186      329.6163      696.2568        0.0025  0.2253\n",
      "    187      309.6041      652.8044        0.0017  0.3446\n",
      "    188      \u001b[36m304.3905\u001b[0m      658.0012        0.0010  0.2336\n",
      "    189      \u001b[36m302.2528\u001b[0m      642.2343        0.0005  0.3933\n",
      "    190      \u001b[36m300.6048\u001b[0m      643.9648        0.0001  0.2423\n",
      "    191      317.1260      609.3422        0.0050  0.2332\n",
      "    192      327.3298      604.3603        0.0049  0.3475\n",
      "    193      338.2526      586.0012        0.0045  0.2309\n",
      "    194      344.3661      589.0661        0.0040  0.3435\n",
      "    195      349.8335      \u001b[32m563.7915\u001b[0m     +  0.0033  0.2301\n",
      "    196      334.3326      700.4005        0.0025  0.3309\n",
      "    197      309.5762      650.6773        0.0017  0.2318\n",
      "    198      303.4009      656.8703        0.0010  0.3321\n",
      "    199      \u001b[36m299.7399\u001b[0m      638.2285        0.0005  0.2329\n",
      "    200      \u001b[36m297.8214\u001b[0m      639.4356        0.0001  0.2180\n",
      "    201      312.6118      607.1040        0.0050  0.3036\n",
      "    202      324.6877      595.4448        0.0049  0.2058\n",
      "    203      333.0113      582.9067        0.0045  0.3105\n",
      "    204      339.4675      586.1970        0.0040  0.2040\n",
      "    205      350.2384      \u001b[32m561.0117\u001b[0m     +  0.0033  0.3060\n",
      "    206      333.1682      714.4151        0.0025  0.2043\n",
      "    207      307.8884      656.1666        0.0017  0.2952\n",
      "    208      304.0315      661.2718        0.0010  0.2037\n",
      "    209      \u001b[36m297.6448\u001b[0m      643.4869        0.0005  0.2242\n",
      "    210      \u001b[36m295.9046\u001b[0m      642.4174        0.0001  0.3129\n",
      "    211      308.9467      612.6605        0.0050  0.2058\n",
      "    212      319.4278      593.0409        0.0049  0.2960\n",
      "    213      321.6736      586.2616        0.0045  0.2164\n",
      "    214      328.8557      579.2334        0.0040  0.3316\n",
      "    215      333.7753      \u001b[32m559.9924\u001b[0m     +  0.0033  0.2910\n",
      "    216      319.7071      688.9692        0.0025  0.5598\n",
      "    217      298.7038      644.9594        0.0017  0.2103\n",
      "    218      \u001b[36m294.4999\u001b[0m      653.2428        0.0010  0.1987\n",
      "    219      \u001b[36m292.5763\u001b[0m      631.8082        0.0005  0.3153\n",
      "    220      \u001b[36m290.4921\u001b[0m      634.2816        0.0001  0.2052\n",
      "    221      301.5884      629.6215        0.0050  0.2969\n",
      "    222      313.1591      588.5828        0.0049  0.1971\n",
      "    223      318.9987      600.0476        0.0045  0.2937\n",
      "    224      324.6115      575.6075        0.0040  0.2019\n",
      "    225      331.6149      563.2465        0.0033  0.2928\n",
      "    226      319.7610      657.5263        0.0025  0.1960\n",
      "    227      300.1614      660.6655        0.0017  0.2073\n",
      "    228      293.7582      655.3201        0.0010  0.3083\n",
      "    229      291.5075      624.7480        0.0005  0.2016\n",
      "    230      \u001b[36m288.2339\u001b[0m      629.1036        0.0001  0.2894\n",
      "    231      297.3180      631.0023        0.0050  0.1946\n",
      "    232      308.6595      595.1133        0.0049  0.3035\n",
      "    233      319.5052      587.3883        0.0045  0.1937\n",
      "    234      323.5506      577.1424        0.0040  0.2986\n",
      "    235      331.9811      \u001b[32m559.8960\u001b[0m     +  0.0033  0.1973\n",
      "    236      317.7181      700.6417        0.0025  0.1936\n",
      "    237      297.4486      651.1111        0.0017  0.3070\n",
      "    238      290.9557      653.9681        0.0010  0.2019\n",
      "    239      288.5664      625.7927        0.0005  0.2955\n",
      "    240      \u001b[36m285.8156\u001b[0m      629.1482        0.0001  0.2021\n",
      "    241      293.9881      630.5398        0.0050  0.3058\n",
      "    242      306.8664      595.1954        0.0049  0.1991\n",
      "    243      314.6127      574.1680        0.0045  0.2988\n",
      "    244      319.3653      599.1674        0.0040  0.2004\n",
      "    245      323.3191      \u001b[32m558.1996\u001b[0m     +  0.0033  0.1930\n",
      "    246      309.1902      716.4026        0.0025  0.3172\n",
      "    247      293.1952      661.4059        0.0017  0.2001\n",
      "    248      287.1004      658.8286        0.0010  0.3975\n",
      "    249      \u001b[36m285.2150\u001b[0m      636.4628        0.0005  0.2871\n",
      "    250      \u001b[36m282.8496\u001b[0m      639.5511        0.0001  0.3043\n",
      "    251      291.4607      612.9289        0.0050  0.1923\n",
      "    252      303.5402      596.2143        0.0049  0.2980\n",
      "    253      311.1292      579.1544        0.0045  0.2018\n",
      "    254      315.9045      580.8831        0.0040  0.1962\n",
      "    255      316.9274      561.2293        0.0033  0.3371\n",
      "    256      305.5491      737.4803        0.0025  0.2018\n",
      "    257      291.1512      664.6518        0.0017  0.2926\n",
      "    258      285.4397      660.5418        0.0010  0.2146\n",
      "    259      \u001b[36m282.5350\u001b[0m      634.8198        0.0005  0.3147\n",
      "    260      \u001b[36m280.3267\u001b[0m      638.3230        0.0001  0.2329\n",
      "    261      288.0853      615.4346        0.0050  0.3673\n",
      "    262      298.1159      593.8370        0.0049  0.1992\n",
      "    263      308.6491      594.8911        0.0045  0.1970\n",
      "    264      310.6052      575.8044        0.0040  0.2984\n",
      "    265      315.2214      \u001b[32m556.1606\u001b[0m     +  0.0033  0.2082\n",
      "    266      304.7417      733.1551        0.0025  0.3361\n",
      "    267      290.0437      668.4646        0.0017  0.2362\n",
      "    268      284.0904      664.1334        0.0010  0.3405\n",
      "    269      281.2950      637.0871        0.0005  0.2141\n",
      "    270      \u001b[36m278.4500\u001b[0m      641.3888        0.0001  0.2994\n",
      "    271      284.7083      631.6792        0.0050  0.3472\n",
      "    272      295.7004      595.8862        0.0049  0.2807\n",
      "    273      310.0416      593.9550        0.0045  0.5353\n",
      "    274      309.4157      571.3126        0.0040  0.3552\n",
      "    275      313.9330      564.2447        0.0033  0.3735\n",
      "    276      302.3487      717.3419        0.0025  0.3003\n",
      "    277      288.7539      660.7482        0.0017  0.4533\n",
      "    278      282.5093      647.4740        0.0010  0.2524\n",
      "    279      279.0956      620.2993        0.0005  0.5534\n",
      "    280      \u001b[36m276.5131\u001b[0m      625.2492        0.0001  0.3308\n",
      "    281      283.1141      604.6977        0.0050  0.3227\n",
      "    282      292.1080      592.4133        0.0049  0.5142\n",
      "    283      309.7827      589.1489        0.0045  0.3021\n",
      "    284      306.2474      595.2635        0.0040  0.4007\n",
      "    285      316.1961      \u001b[32m553.1395\u001b[0m     +  0.0033  0.3290\n",
      "    286      303.7583      763.0471        0.0025  0.5322\n",
      "    287      288.2253      687.1743        0.0017  0.3624\n",
      "    288      281.6995      678.5025        0.0010  0.4731\n",
      "    289      278.3112      652.6526        0.0005  0.3352\n",
      "    290      \u001b[36m275.2974\u001b[0m      658.2765        0.0001  0.3203\n",
      "    291      280.5677      642.9570        0.0050  0.5470\n",
      "    292      290.9518      598.3501        0.0049  0.2549\n",
      "    293      310.4792      580.6468        0.0045  0.5861\n",
      "    294      308.4355      600.4143        0.0040  0.5491\n",
      "    295      313.9092      559.6845        0.0033  0.4579\n",
      "    296      302.5799      751.0655        0.0025  0.3056\n",
      "    297      285.5498      668.8816        0.0017  0.5275\n",
      "    298      278.9781      662.3956        0.0010  0.3662\n",
      "    299      275.6401      638.7659        0.0005  0.3836\n",
      "    300      \u001b[36m273.4490\u001b[0m      642.8342        0.0001  0.5655\n",
      "Training ridge\n",
      "Training rf\n",
      "Power: 3, Threshold: 0.05, Pearson: 0.84008155510705, Spearman: 0.8633479432337051\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.05, Pearson: 0.8396980294735792, Spearman: 0.8624711488925892\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.05, Pearson: 0.8396980294735792, Spearman: 0.8624711488925892\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.1, Pearson: 0.8398366466232412, Spearman: 0.8637589521877084\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.1, Pearson: 0.8398366466232412, Spearman: 0.8637589521877084\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.1, Pearson: 0.8398366466232412, Spearman: 0.8637589521877084\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.2, Pearson: 0.8326991277761862, Spearman: 0.8589246714679611\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.2, Pearson: 0.8326991277761862, Spearman: 0.8589246714679611\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.2, Pearson: 0.8326991277761862, Spearman: 0.8589246714679611\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.3, Pearson: 0.8289404790348779, Spearman: 0.8548833234285481\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.3, Pearson: 0.8289404790348779, Spearman: 0.8548833234285481\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.3, Pearson: 0.8289404790348779, Spearman: 0.8548833234285481\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.5, Pearson: 0.8154599225267752, Spearman: 0.8440367150633179\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.5, Pearson: 0.8154599225267752, Spearman: 0.8440367150633179\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.5, Pearson: 0.8154599225267752, Spearman: 0.8440367150633179\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.7, Pearson: 0.7634543959545924, Spearman: 0.816400030289573\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.7, Pearson: 0.7634543959545924, Spearman: 0.816400030289573\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Training xgb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peiheng/anaconda3/envs/dl/lib/python3.11/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ridge\n",
      "Power: 3, Threshold: 0.7, Pearson: 0.7634543959545924, Spearman: 0.816400030289573\n"
     ]
    }
   ],
   "source": [
    "# tune adaboost models\n",
    "from models.ensemble_adaboost import EnsembleAdaBoost\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "ensemble_adaboost = EnsembleAdaBoost()\n",
    "params = ensemble_adaboost.tune(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power</th>\n",
       "      <th>threshold</th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.8398065582845152, 0.8385486172887398, 0.838...</td>\n",
       "      <td>[0.8622335355572311, 0.8628196500038711, 0.862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.836776286095227, 0.8377383047612055, 0.8377...</td>\n",
       "      <td>[0.8608451823548661, 0.8624779123298237, 0.862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.8364770263527057, 0.8364770263527057, 0.836...</td>\n",
       "      <td>[0.8600144124948627, 0.8600144124948627, 0.860...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[0.8270531705142207, 0.8270531705142207, 0.827...</td>\n",
       "      <td>[0.8537847021498851, 0.8537847021498851, 0.853...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[0.7913981453339598, 0.7913981453339598, 0.791...</td>\n",
       "      <td>[0.8340509190993921, 0.8340509190993921, 0.834...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.8389153969126968, 0.8380750873969691, 0.838...</td>\n",
       "      <td>[0.8625507318549118, 0.8621492998532895, 0.862...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.8354857345099183, 0.8360095442251252, 0.836...</td>\n",
       "      <td>[0.8595192984394988, 0.8599120339540993, 0.859...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.8292202659907597, 0.8292202659907597, 0.829...</td>\n",
       "      <td>[0.8546178923356027, 0.8546178923356027, 0.854...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[0.8238660879912972, 0.8238660879912972, 0.823...</td>\n",
       "      <td>[0.8495597155649753, 0.8495597155649753, 0.849...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[0.7888153465342139, 0.7888153465342139, 0.788...</td>\n",
       "      <td>[0.8324461193252513, 0.8324461193252513, 0.832...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>[0.8393913754560325, 0.8398366466232412, 0.839...</td>\n",
       "      <td>[0.8620458488580833, 0.8637589521877084, 0.863...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>[0.8326321185064405, 0.8326991277761862, 0.832...</td>\n",
       "      <td>[0.8572284870611978, 0.8589246714679611, 0.858...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.8289404790348779, 0.8289404790348779, 0.828...</td>\n",
       "      <td>[0.8548833234285481, 0.8548833234285481, 0.854...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[0.8154599225267752, 0.8154599225267752, 0.815...</td>\n",
       "      <td>[0.8440367150633179, 0.8440367150633179, 0.844...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>[0.7634543959545924, 0.7634543959545924, 0.763...</td>\n",
       "      <td>[0.816400030289573, 0.816400030289573, 0.81640...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    power  threshold                                            pearson  \\\n",
       "0       1        0.1  [0.8398065582845152, 0.8385486172887398, 0.838...   \n",
       "1       1        0.2  [0.836776286095227, 0.8377383047612055, 0.8377...   \n",
       "2       1        0.3  [0.8364770263527057, 0.8364770263527057, 0.836...   \n",
       "3       1        0.5  [0.8270531705142207, 0.8270531705142207, 0.827...   \n",
       "4       1        0.7  [0.7913981453339598, 0.7913981453339598, 0.791...   \n",
       "5       2        0.1  [0.8389153969126968, 0.8380750873969691, 0.838...   \n",
       "6       2        0.2  [0.8354857345099183, 0.8360095442251252, 0.836...   \n",
       "7       2        0.3  [0.8292202659907597, 0.8292202659907597, 0.829...   \n",
       "8       2        0.5  [0.8238660879912972, 0.8238660879912972, 0.823...   \n",
       "9       2        0.7  [0.7888153465342139, 0.7888153465342139, 0.788...   \n",
       "10      3        0.1  [0.8393913754560325, 0.8398366466232412, 0.839...   \n",
       "11      3        0.2  [0.8326321185064405, 0.8326991277761862, 0.832...   \n",
       "12      3        0.3  [0.8289404790348779, 0.8289404790348779, 0.828...   \n",
       "13      3        0.5  [0.8154599225267752, 0.8154599225267752, 0.815...   \n",
       "14      3        0.7  [0.7634543959545924, 0.7634543959545924, 0.763...   \n",
       "\n",
       "                                             spearman  \n",
       "0   [0.8622335355572311, 0.8628196500038711, 0.862...  \n",
       "1   [0.8608451823548661, 0.8624779123298237, 0.862...  \n",
       "2   [0.8600144124948627, 0.8600144124948627, 0.860...  \n",
       "3   [0.8537847021498851, 0.8537847021498851, 0.853...  \n",
       "4   [0.8340509190993921, 0.8340509190993921, 0.834...  \n",
       "5   [0.8625507318549118, 0.8621492998532895, 0.862...  \n",
       "6   [0.8595192984394988, 0.8599120339540993, 0.859...  \n",
       "7   [0.8546178923356027, 0.8546178923356027, 0.854...  \n",
       "8   [0.8495597155649753, 0.8495597155649753, 0.849...  \n",
       "9   [0.8324461193252513, 0.8324461193252513, 0.832...  \n",
       "10  [0.8620458488580833, 0.8637589521877084, 0.863...  \n",
       "11  [0.8572284870611978, 0.8589246714679611, 0.858...  \n",
       "12  [0.8548833234285481, 0.8548833234285481, 0.854...  \n",
       "13  [0.8440367150633179, 0.8440367150633179, 0.844...  \n",
       "14  [0.816400030289573, 0.816400030289573, 0.81640...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# convert params grid to dictionary\n",
    "pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_adaboost import EnsembleAdaBoost\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "ensemble_adaboost_performances_pearson = {}\n",
    "ensemble_adaboost_performances_spearman = {}\n",
    "\n",
    "rounds = [1, 2, 3, 5, 10, 15]\n",
    "\n",
    "for round in rounds:  \n",
    "    ensemble_adaboost = EnsembleAdaBoost(n_rounds=round)\n",
    "    ensemble_adaboost.fit(data)\n",
    "    ensemble_adaboost_performance_pearson, ensemble_adaboost_performance_spearman = ensemble_adaboost.test(data)\n",
    "    # rename the keys to include the round number\n",
    "    ensemble_adaboost_performance_pearson[f'ada-{round}'] = ensemble_adaboost_performance_pearson.pop('ada')\n",
    "    ensemble_adaboost_performance_spearman[f'ada-{round}'] = ensemble_adaboost_performance_spearman.pop('ada')\n",
    "\n",
    "    ensemble_adaboost_performances_pearson.update(ensemble_adaboost_performance_pearson)\n",
    "    ensemble_adaboost_performances_spearman.update(ensemble_adaboost_performance_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from scipy.stats import ttest_ind\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [ensemble_adaboost_performances_pearson, ensemble_adaboost_performances_spearman]):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=len(rounds)))\n",
    "    colours = ['gray' if 'ada' not in model else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Model', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for adaboost model\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'ada' in model:\n",
    "            ax.axhline(y=np.mean(performance[model]), color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    plt.show()\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'ada' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if 'ada' not in model}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
