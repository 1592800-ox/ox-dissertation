{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Mean Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_weighted_mean import EnsembleWeightedMean\n",
    "\n",
    "ensemble_direct_optimization = EnsembleWeightedMean(optimization=True)\n",
    "ensemble_direct_optimization_with_features = EnsembleWeightedMean(optimization=True, with_features=True)\n",
    "ensemble_weigthed_mean = EnsembleWeightedMean(optimization=False)\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "ensemble_direct_optimization.fit(data)\n",
    "direct_optimization_performance = ensemble_direct_optimization.test(data) \n",
    "\n",
    "ensemble_weigthed_mean.fit(data)\n",
    "weighted_mean_performance = ensemble_weigthed_mean.test(data)\n",
    "\n",
    "ensemble_direct_optimization_with_features.fit(data)\n",
    "with_features_performance = ensemble_direct_optimization_with_features.test(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "\n",
    "direct_op_pearson, direct_op_spearman = direct_optimization_performance\n",
    "performance_weighted_pearson, performance_weighted_spearman = weighted_mean_performance\n",
    "performance_with_features_pearson, performance_with_features_spearman = with_features_performance\n",
    "\n",
    "# join the performance values, ignore the common keys\n",
    "direct_op_pearson.update(performance_weighted_pearson)\n",
    "direct_op_spearman.update(performance_weighted_spearman)\n",
    "\n",
    "direct_op_pearson.update(performance_with_features_pearson)\n",
    "direct_op_spearman.update(performance_with_features_spearman)\n",
    "\n",
    "performance_pearson = direct_op_pearson\n",
    "performance_spearman = direct_op_spearman\n",
    "\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "# plot the bar plot on top of the strip plot\n",
    "# bar plot should be shortened to emphasize the difference in values\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [performance_pearson, performance_spearman]):\n",
    "    # performance = pd.DataFrame({'Models': list(performance.keys()), 'Performance': list(performance.values()), 'Category': [0 if 'op' in model or 'pwm' in model else 1 for model in performance.keys()]})\n",
    "    # print(performance)\n",
    "    # add a category column\n",
    "    print(name)\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=3))\n",
    "    colours = ['gray' if not ('opt' in model or 'pwm' in model) else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Ensemble', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for 'opt', 'pwm' models of matching color\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'opt' in model or 'pwm' in model:\n",
    "            ax.axhline(y=performance[model], color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    plt.show()\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'opt' in model or 'pwm' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if not ('opt' in model or 'pwm' in model)}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')\n",
    "                \n",
    "    # save the figure\n",
    "    fig.savefig(pjoin('dissertation', 'figures', f'ensemble_{name.lower()}.pdf'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_bagging import EnsembleBagging\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "n_rounds = [1, 2, 3, 5, 10, 15]\n",
    "\n",
    "performances_pearson = {}\n",
    "performances_spearman = {}\n",
    "for i in n_rounds:\n",
    "    print(f'Bagging with {i} rounds')\n",
    "    ensemble_bagging = EnsembleBagging(n_rounds=i)\n",
    "    ensemble_bagging.fit(data)\n",
    "    performance_pearson, performance_spearman = ensemble_bagging.test(data)\n",
    "    performance_pearson[f'bag-{i}'] = performance_pearson.pop('bag')\n",
    "    performance_spearman[f'bag-{i}'] = performance_spearman.pop('bag')\n",
    "    performances_pearson.update(performance_pearson)\n",
    "    performances_spearman.update(performance_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [performances_pearson, performances_spearman]):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=len(n_rounds)))\n",
    "    colours = ['gray' if 'bag' not in model else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Model', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for adaboost model\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'bag' in model:\n",
    "            ax.axhline(y=np.mean(performance[model]), color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, horizontalalignment='right')\n",
    "    plt.show()\n",
    "\n",
    "    # save the figure\n",
    "    fig.savefig(pjoin('dissertation', 'figures', f'ensemble_bagging_{name.lower()}_round.png'), bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'bag' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if 'bag' not in model}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_bagging import EnsembleBagging\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "percentages = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "performances_pearson = {}\n",
    "performances_spearman = {}\n",
    "for i in percentages:\n",
    "    ensemble_bagging = EnsembleBagging(n_rounds=3, sample_percentage=i)\n",
    "    ensemble_bagging.fit(data)\n",
    "    performance_pearson, performance_spearman = ensemble_bagging.test(data)\n",
    "    performance_pearson[f'bag-{i}'] = performance_pearson.pop('bag')\n",
    "    performance_spearman[f'bag-{i}'] = performance_spearman.pop('bag')\n",
    "    performances_pearson.update(performance_pearson)\n",
    "    performances_spearman.update(performance_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [performances_pearson, performances_spearman]):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=len(percentages)))\n",
    "    colours = ['gray' if 'bag' not in model else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Model', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for adaboost model\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'bag' in model:\n",
    "            ax.axhline(y=np.mean(performance[model]), color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, horizontalalignment='right')\n",
    "    plt.show()\n",
    "\n",
    "    # save the figure\n",
    "    fig.savefig(pjoin('dissertation', 'figures', f'ensemble_{name.lower()}_bagging_percentage.pdf'), bbox_inches='tight', dpi=300)\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'bag' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if 'bag' not in model}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ensemble_adaboost import EnsembleAdaBoost\n",
    "\n",
    "data = 'ensemble-pd-hek293t-pe2.csv'\n",
    "\n",
    "ensemble_adaboost_performances_pearson = {}\n",
    "ensemble_adaboost_performances_spearman = {}\n",
    "\n",
    "rounds = [1, 2, 3, 5, 10, 15]\n",
    "\n",
    "for round in rounds:  \n",
    "    ensemble_adaboost = EnsembleAdaBoost(n_rounds=round)\n",
    "    ensemble_adaboost.fit(data)\n",
    "    ensemble_adaboost_performance_pearson, ensemble_adaboost_performance_spearman = ensemble_adaboost.test(data)\n",
    "    # rename the keys to include the round number\n",
    "    ensemble_adaboost_performance_pearson[f'ada-{round}'] = ensemble_adaboost_performance_pearson.pop('ada')\n",
    "    ensemble_adaboost_performance_spearman[f'ada-{round}'] = ensemble_adaboost_performance_spearman.pop('ada')\n",
    "\n",
    "    ensemble_adaboost_performances_pearson.update(ensemble_adaboost_performance_pearson)\n",
    "    ensemble_adaboost_performances_spearman.update(ensemble_adaboost_performance_spearman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "import pandas as pd\n",
    "from os.path import join as pjoin\n",
    "from scipy.stats import ttest_ind\n",
    "# plot the performance as bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "alpha = 0.5\n",
    "f_size = 12\n",
    "\n",
    "for name, performance in zip(['Pearson', 'Spearman'], [ensemble_adaboost_performances_pearson, ensemble_adaboost_performances_spearman]):\n",
    "    fig, ax = plt.subplots(figsize=(5, 2.5))\n",
    "    ax.set_ylim(0.65, 0.9)\n",
    "    colour_palette = iter(sns.color_palette('icefire', n_colors=len(rounds)))\n",
    "    colours = ['gray' if 'ada' not in model else next(colour_palette) for model in performance.keys()]\n",
    "    sns.stripplot(data=performance, ax=ax, alpha=1, jitter=0.1, size=3, palette=colours)\n",
    "    sns.barplot(data=performance, ax=ax, alpha=alpha, palette=colours, errorbar=None)\n",
    "    ax.set_xlabel('Model', fontsize=f_size)\n",
    "    ax.set_ylabel(f'{name} correlation', fontsize=f_size)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=f_size)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=f_size)\n",
    "    # remove top and right spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    # show a horizontal line at the mean for adaboost model\n",
    "    for ind, model in enumerate(performance.keys()):\n",
    "        if 'ada' in model:\n",
    "            ax.axhline(y=np.mean(performance[model]), color=colours[ind], linestyle='--', linewidth=0.5)\n",
    "    # rotate the x tick labels\n",
    "    plt.show()\n",
    "    \n",
    "    # perform paired t-test between opt pwm models and the rest\n",
    "    from scipy.stats import ttest_ind\n",
    "    adaboost_values = {model: performance[model] for model in performance.keys() if 'ada' in model}\n",
    "    rest_values = {model: performance[model] for model in performance.keys() if 'ada' not in model}\n",
    "\n",
    "    for ensemble, performance_ensemble in zip(adaboost_values.keys(), adaboost_values.values()):\n",
    "        for rest, performance_rest in zip(rest_values.keys(), rest_values.values()):\n",
    "            t_stat, p_value = ttest_ind(performance_ensemble, performance_rest)\n",
    "            print(f'{ensemble} vs {rest} t-statistic: {t_stat}, p-value: {p_value}')\n",
    "            if p_value < 0.05:\n",
    "                print('Significant')\n",
    "            else:\n",
    "                print('Not significant')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
